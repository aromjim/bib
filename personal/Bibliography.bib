@String{AAAI = {Association for the Advancement of Artificial Intelligence}}
@String{ACM = {Association for Computing Machinery}}
@String{Adaptive_Computation = {Adaptive Computation and Machine Learning}}
@String{Addison-Wesley = {Addison-Wesley}}
@String{Alianza = {Alianza editorial}}
@String{Apress = {Apress}}
@String{Ariel = {Editorial Ariel}}
@String{Birkhäuser = {Birkhäuser Basel}}
@String{CRC = {{CRC} Press}}
@String{CRC_Computer_Science = {Chapman \& Hall/{CRC} Computer Science and Data Analysis}}
@String{CRC_Modern_Statistical_Methods = {Chapman \& Hall/{CRC} Handbooks of Modern Statistical Methods}}
@String{CRC_R_Series = {Chapman \& Hall/{CRC} The R Series}}
@String{CRC_Statistical_Science = {Chapman \& Hall/{CRC} Texts in Statistical Science}}
@String{Cambridge = {Cambridge University Press}}
@String{Díaz_de_Santos = {Editorial Díaz de Santos}}
@String{Elsevier = {Elsevier}}
@String{Kronos = {Editorial Kronos}}
@String{LNCS = {Lecture Notes in Computer Science}}
@String{MIT_Press = {The {MIT} Press}}
@String{Modern_Birkhäuser_Classics = {Modern Birkhäuser Classics}}
@String{Morgan-Kaufmann = {Morgan-Kaufmann}}
@String{No_Starch = {No Starch Press}}
@String{OReilly = {O'Reilly}}
@String{Oxford = {Oxford University Press}}
@String{Oxford_Statistical_Science = {Oxford Statistical Science Series}}
@String{Packt = {Packt Publishing}}
@String{Prentice_Hall = {Prentice Hall}}
@String{Prentice_Hall_Artificial_Intelligence = {Prentice Hall Series in Artificial Intelligence}}
@String{RCLibros = {RC Libros}}
@String{Springer = {Springer}}
@String{Springer_AI_Foundations = {Artificial Intelligence: Foundations, Theory, and Algorithms}}
@String{Springer_Computational_Intelligence = {Studies in Computational Intelligence}}
@String{Springer_Computer_Science = {Graduate Texts in Computer Science}}
@String{Springer_Computer_Vision = {Advances in Computer Vision and Pattern Recognition}}
@String{Springer_Decision_Engineering = {Decision Engineering}}
@String{Springer_Information_Systems = {Integrated Series in Information Systems}}
@String{Springer_Natural_Computing = {Natural Computing Series}}
@String{Springer_Operations_Financial = {Springer Series in Operations Research and Financial Engineering}}
@String{Springer_Operations_Management = {International Series in Operations Research \& Management Science}}
@String{Springer_Simulation_Foundations = {Simulation Foundations, Methods and Applications}}
@String{Springer_Statistics = {Springer Series in Statistics}}
@String{Springer_Statistics_Computing = {Statistics and Computing}}
@String{Springer_Stochastic_Modelling = {Stochastic Modelling and Applied Probability}}
@String{Springer_Studies_Big_Data = {Studies in Big Data}}
@String{Springer_Text_Statistics = {Springer Texts in Statistics}}
@String{Springer_Undergraduate_Mathematics = {Springer Undergraduate Mathematics Series}}
@String{Springer_Undergraduate_Topics = {Undergraduate Topics in Computer Science}}
@String{Springer_Use_R = {Use R!}}
@String{Statistics_Practice = {Statistics in Practice}}
@String{Wiley = {Wiley}}
@String{Wiley_Probability_Statistics = {Wiley Series in Probability and Statistics}}
@String{Springer_Computational_Statistics = {Springer Handbooks of Computational Statistics}}
@String{Springer_Scientific_Computation = {Scientific Computation}}
@String{Pragmatic_Bookshelf = {The Pragmatic Bookshelf}}
@String{Hobart = {Hobart Press}}
@String{Princeton = {Princeton University Press}}
@String{Princeton_Applied_Mathematics = {Princeton Series in Applied Mathematics}}
@String{Springer_Combinatorial_Optimization = {Combinatorial Optimization}}
@String{Elsevier_Annals_Discrete_Mathematics = {Annals of Discrete Mathematics}}
@String{SIAM = {Society for Industrial and Applied Mathematics}}
@String{SIAM_Software_Environments_Tools = {Software, Environments and Tools}}
@String{IBM_Press = {IBM Press}}
@String{Intelligent_Systems_Library = {Intelligent Systems Reference Library}}
@String{Cengage = {Cengage}}

@InCollection{romero-jimenez_et_al:twelve_years_sevilla_carpets,
	abstract = {In the membrane computing community, efficiency and universality of multiple models have been
deeply studied, while descriptive complexity of the computations has not usually attracted so much
attention. Sevilla carpets are a tool to analyze in detail the computations of P systems, beyond of
just taking into consideration the time and space resources spent by them. This paper is a survey
of the variants of Sevilla carpets and associated parameters available in the literature up to now.
A simple case study is included, to illustrate the possible use of Sevilla carpets to help
comparing different cellular models solving the same task.},
	keywords = {Computación bioinspirada, Computación con membranas},
	pages = {141-152},
	author = {Romero-Jiménez, Álvaro and Riscos-Núñez, Agustín and Macías-Ramos, Luis Felipe and Graciani, Carmen and Pérez-Jiménez, Mario J. and Valencia-Cabrera, Luis},
	title = {Twelve Years of Sevilla Carpets: a Survey},
	crossref = {gheorghe_et_al:multidisciplinary_creativity}
}

@InProceedings{romero-jimenez_et_al:generating_diophantine_sets_virus_machines,
	date = {2015-12-24},
	abstract = {Virus Machines are a computational paradigm inspired by the manner in which viruses replicate and
transmit from one host cell to another. This paradigm provides non-deterministic sequential
devices. Non-restricted virus machines are unbounded virus machines, in the sense that no
restriction on the number of hosts, the number of instructions and the number of viruses contained
in any host along any computation is placed on them. The computational completeness of these
machines has been obtained by simulating register machines. In this paper, virus machines as set
generating devices are considered. Then, the universality of non-restricted virus machines is
proved by showing that they can compute all diophantine sets, which the MRDP theorem proves that
coincide with the recursively enumerable sets.},
	enlaces = {Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-3-662-49014-3_30
},
	file = {Romero-Jiménez et al - 2015 - Generating Diophantine Sets by Virus Machines.pdf},
	keywords = {Computación bioinspirada, Máquinas de virus},
	doi = {10.1007/978-3-662-49014-3_30},
	pages = {331-341},
	crossref = {gong_et_al:bio_inspired_computing_theories_applications},
	title = {Generating Diophantine Sets by Virus Machines},
	author = {Romero-Jiménez, Álvaro and Valencia-Cabrera, Luis and Pérez-Jiménez, Mario de Jesús}
}

@InProceedings{romero-jimenez_et_al:computing_partial_recursive_functions_virus_machines,
	date = {2015-12-30},
	author = {Romero-Jiménez, Álvaro and Valencia-Cabrera, Luis and Riscos-Núñez, Agustín and Pérez-Jiménez, Mario J.},
	title = {Computing Partial Recursive Functions by Virus Machines},
	pages = {353-368},
	doi = {10.1007/978-3-319-28475-0_24},
	keywords = {Computación bioinspirada, Máquinas de virus},
	file = {Romero-Jiménez et al - 2015 - Computing Partial Recursive Functions by Virus Machines.pdf},
	enlaces = {Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-3-319-28475-0_24},
	abstract = {Virus Machines are a computational paradigm inspired by the manner in which viruses replicate and
transmit from one host cell to another. This paradigm provides non-deterministic sequential
devices. Non-restricted Virus Machines are unbounded Virus Machines, in the sense that no
restriction on the number of hosts, the number of instructions and the number of viruses contained
in any host along any computation is placed on them. The computational completeness of these
machines has been obtained by simulating register machines. In this paper, Virus Machines as
function computing devices are considered. Then, the universality of non-restricted virus machines
is proved by showing that they can compute all partial recursive functions.},
	crossref = {rozenberg_et_al:membrane_computing}
}

@Online{Kaggle_webpage,
	langid = {spanish},
	url = {https://www.kaggle.com/},
	title = {Página web de Kaggle}
}

@XData{acm_computing_surveys,
	journaltitle = {ACM Computing Surveys},
	issn = {0360-0300},
	publisher = ACM
}

@Book{aggarwal:outlier_analysis,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2672716
Recurso electrónico (SpringerLink): http://www.us.debiblio.com/login?url=https://doi.org/10.1007/978-1-4614-6396-2
},
	file = {Aggarwal - 2013 - Outlier Analysis.pdf},
	keywords = {Análisis de valores atípicos},
	abstract = {With the increasing advances in hardware technology for data collection, and
advances in software technology (databases) for data organization, computer
scientists have increasingly participated in the latest advancements of the
outlier analysis field. Computer scientists, specifically, approach this field
based on their practical experiences in managing large amounts of data, and
with far fewer assumptions– the data can be of any type, structured or
unstructured, and may be extremely large. Outlier Analysis is a comprehensive
exposition, as understood by data mining experts, statisticians and computer
scientists. The book has been organized carefully, and emphasis was placed on
simplifying the content, so that students and practitioners can also benefit.
Chapters will typically cover one of three areas: methods and techniques
commonly used in outlier analysis, such as linear methods, proximity-based
methods, subspace methods, and supervised methods; data domains, such as, text,
categorical, mixed-attribute, time-series, streaming, discrete sequence,
spatial and network data; and key applications of these methods as applied to
diverse domains such as credit card fraud detection, intrusion detection,
medical diagnosis, earth science, web log analytics, and social network
analysis are covered.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9781461463955},
	doi = {10.1007/978-1-4614-6396-2},
	pagetotal = {446},
	isbn = {9781461463955},
	publisher = Springer,
	language = {english},
	date = {2013},
	title = {Outlier Analysis},
	author = {Aggarwal, Charu C.}
}

@XData{ai_magazine,
	journaltitle = {AI Magazine},
	issn = {0738-4602},
	publisher = AAAI
}

@Article{aleti_moser:adaptive_parameter_evolutionary_algorithms,
	pagetotal = {35},
	xdata = {acm_computing_surveys},
	file = {Aleti _ Moser - 2016 - A Systematic Literature Review of Adaptive Parameter Control Methods for Evolutionary Algorithms.pdf},
	keywords = {Algoritmos evolutivos, Inteligencia artificial},
	abstract = {Evolutionary algorithms (EAs) are robust stochastic optimisers that perform well over a wide range
of problems. Their robustness, however, may be affected by several adjustable parameters, such as
mutation rate, crossover rate, and population size. Algorithm parameters are usually
problem-specific, and often have to be tuned not only to the problem but even the problem instance
at hand to achieve ideal performance. In addition, research has shown that different parameter
values may be optimal at different stages of the optimisation process. To address these issues,
researchers have shifted their focus to adaptive parameter control, in which parameter values are
adjusted during the optimisation process based on the performance of the algorithm. These methods
redefine parameter values repeatedly based on implicit or explicit rules that decide how to make
the best use of feedback from the optimisation algorithm.

In this survey, we systematically investigate the state of the art in adaptive parameter control.
The approaches are classified using a new conceptual model that subdivides the process of adapting
parameter values into four steps that are present explicitly or implicitly in all existing
approaches that tune param- eters dynamically during the optimisation process. The analysis reveals
the major focus areas of adaptive parameter control research as well as gaps and potential
directions for further development in this area.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1145/2996355},
	number = {3},
	volume = {49},
	language = {english},
	date = {2016},
	title = {A Systematic Literature Review of Adaptive Parameter Control Methods for Evolutionary Algorithms},
	author = {Aleti, Aldeida and Moser, Irene}
}

@Book{alonso_borrego:deduccion_automática,
	keywords = {Lógica matemática},
	langid = {spanish},
	pagetotal = {98},
	isbn = {9788486273583},
	publisher = Kronos,
	language = {spanish},
	subtitle = {Vol. 1: Construcción lógica de sistemas lógicos},
	date = {2002},
	title = {Deducción automática},
	author = {Alonso Jiménez, José Antonio and Borrego Díaz, Joaquín}
}

@Book{applegate_et_al:traveling_salesman_problem,
	series = Princeton_Applied_Mathematics,
	publisher = Princeton,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1918794
Recurso electrónico (E-Libro): http://www.us.debiblio.com/login?url=http://site.ebrary.com/lib/unisev/Doc?id=10496632
},
	file = {Applegate et al - 2007 - The Traveling Salesman Problem.pdf},
	keywords = {NP-completitud},
	abstract = {This book presents the latest findings on one of the most intensely
investigated subjects in computational mathematics--the traveling salesman
problem. It sounds simple enough: given a set of cities and the cost of travel
between each pair of them, the problem challenges you to find the cheapest
route by which to visit all the cities and return home to where you began.
Though seemingly modest, this exercise has inspired studies by mathematicians,
chemists, and physicists. Teachers use it in the classroom. It has practical
applications in genetics, telecommunications, and neuroscience.

The authors of this book are the same pioneers who for nearly two decades have
led the investigation into the traveling salesman problem. They have derived
solutions to almost eighty-six thousand cities, yet a general solution to the
problem has yet to be discovered. Here they describe the method and computer
code they used to solve a broad range of large-scale problems, and along the
way they demonstrate the interplay of applied mathematics with increasingly
powerful computing platforms. They also give the fascinating history of the
problem--how it developed, and why it continues to intrigue us.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://press.princeton.edu/titles/8451.html},
	pagetotal = {608},
	isbn = { 9780691129938},
	language = {english},
	subtitle = {A Computational Study},
	date = {2007},
	title = {The Traveling Salesman Problem},
	author = {Applegate, David L. and Bixby, Robert E. and Chvátal, Vasek and Cook, William John}
}

@Book{arenas:logica_formal_informaticos,
	keywords = {Lógica matemática},
	langid = {spanish},
	pagetotal = {331},
	isbn = {9788479782404},
	publisher = Díaz_de_Santos,
	language = {spanish},
	date = {1996},
	title = {Lógica formal para informáticos},
	author = {Arenas Alegría, Lourdes}
}

@book{asmussen_glynn:stochastic_simulation,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1929163
Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-0-387-69033-9},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780387306797},
	doi = {10.1007/978-0-387-69033-9},
	language = {english},
	subtitle = {Algorithms and Analysis},
	title = {Stochastic Simulation},
	isbn = {9780387306797},
	series = Springer_Stochastic_Modelling,
	abstract = {Sampling-based computational methods have become a fundamental part of the numerical toolset of
practitioners and researchers across an enormous number of different applied domains and academic
disciplines. This book provides a broad treatment of such sampling-based methods, as well as
accompanying mathematical analysis of the convergence properties of the methods discussed. The
reach of the ideas is illustrated by discussing a wide range of applications and the models that
have found wide usage. The first half of the book focuses on general methods, whereas the second
half discusses model-specific algorithms.

Given the wide range of examples, exercises and applications students, practitioners and
researchers in probability, statistics, operations research, economics, finance, engineering as
well as biology and chemistry and physics will find the book of value.},
	pagetotal = {476},
	number = {57},
	publisher = Springer,
	author = {Asmussen, Søren and Glynn, Peter W.},
	date = {2007},
	keywords = {Métodos de Monte Carlo, Simulación estocástica},
	file = {Asmussen _ Glynn - 2007 - Stochastic Simulation.pdf}
}

@Book{ausiello_et_al:complexity_approximation,
	file = {Ausiello et al - 1999 - Complexity and Approximation.pdf},
	keywords = {Algoritmia, Complejidad computacional, Problemas de optimización},
	abstract = {IN COMPUTER applications we are used to live with approximation. Various
notions of approximation appear, in fact, in many circumstances. One notable
example is the type of approximation that arises in numerical analysis or in
computational geometry from the fact that we cannot perform computations with
arbitrary precision and we have to truncate the representation of real numbers.
In other cases, we use to approximate complex mathematical objects by simpler
ones: for example, we sometimes represent non-linear functions by means of
piecewise linear ones. The need to solve difficult optimization problems is
another reason that forces us to deal with approximation. In particular, when a
problem is computationally hard (i. e., the only way we know to solve it is by
making use of an algorithm that runs in exponential time), it may be
practically unfeasible to try to compute the exact solution, because it might
require months or years of machine time, even with the help of powerful
parallel computers. In such cases, we may decide to restrict ourselves to
compute a solution that, though not being an optimal one, nevertheless is close
to the optimum and may be determined in polynomial time. We call this type of
solution an approximate solution and the corresponding algorithm a
polynomial-time approximation algorithm. Most combinatorial optimization
problems of great practical relevance are, indeed, computationally intractable
in the above sense. In formal terms, they are classified as Np-hard
optimization problems.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9783540654315},
	doi = {10.1007/978-3-642-58412-1},
	pagetotal = {524},
	isbn = {9783642635816},
	publisher = Springer,
	language = {english},
	subtitle = {Combinatorial Optimization Problems and Their Approximability Properties},
	date = {1999},
	title = {Complexity and Approximation},
	author = {Ausiello, Giorgio and Crescenzi, Pierluigi and Gambosi, Giorgio and Kann, Viggo and Marchetti-Spaccamela, Alberto and Protasi, Marco}
}

@Book{badenhorst:practical_python_design_patterns,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2835339
},
	keywords = {Lenguaje de programación Python},
	abstract = {Become a better, more productive programmer through a series of projects that
will help you deeply understand and master each of the design patterns covered.
In this book you will learn to write elegant "Pythonic" code to solve common
programming problems. You will also experience design thinking, by identifying
design patterns that would be helpful given a specific problem or situation.

Python is eating the world. In recent years it has become so much more than a
mere object-oriented, scripting language. Design patterns help you think of and
solve problems in chunks. They help you to stand on the shoulders of the giants
who have come before, instead of having to reinvent the wheel.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781484226797},
	doi = {10.1007/978-1-4842-2680-3},
	pagetotal = {350},
	isbn = {9781484226797},
	publisher = Apress,
	language = {english},
	subtitle = {Pythonic Solutions to Common Problems},
	date = {2017},
	title = {Practical Python Design Patterns},
	author = {Badenhorst, Wessel}
}

@Book{badesa_et_al:elementos_logica_formal,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2048812},
	keywords = {Lógica matemática},
	abstract = {La Filosofía se ha interesado prácticamente desde sus orígenes por los aspectos formales del
razonamiento. Aristóteles fue el primero en desarrollar una teoría de la argumentación deductiva,
por lo que se le considera con justicia el creador de la lógica como disciplina. La lógica
permaneció esencialmente en el mismo estado en que la dejó Aristóteles hasta mediados del siglo
xix, cuando inició un nuevo desarrollo, basado en gran medida en su capacidad para analizar con
ayuda de métodos matemáticos formas de razonamiento de las que la lógica aristotélica no podía dar
cuenta, en particular, aquellas en que intervienen expresiones cuantificacionales múltiples y
expresiones relacionales. Para el tratamiento sistemático de estas formas de razonamiento, se
desarrollaron a finales del siglo xix y principios del xx la teoría de las relaciones y la de la
cuantificación. Estas dos teorías, junto con el cálculo proposicional, cuyo estudio iniciaron los
lógicos megáricos y estoicos, constituyen el cuerpo básico de conocimientos de la lógica, una
disciplina que a lo largo del siglo xx se ha desarrollado considerablemente y que está todavía en
expansión. Elementos de lógica formal es un manual de introducción a la lógica, escrito
especialmente para estudiantes de filosofía, pero también para aquellas personas con formación
humanística interesadas en materias que requieran conocimientos lógicos. En él se exponen los
conceptos y resultados básicos de la lógica contemporánea sin presuponer ningún conocimiento
técnico especial por parte del lector. Los elementos de teoría de conjuntos necesarios para
presentar con rigor la lógica proposicional y, sobre todo, la cuantificacional se introducen de
forma pausada en los primeros capítulos del libro. El concepto de infinitud, que tradicionalmente
ha sido objeto de reflexión filosófica, es un concepto propio de la teoría de conjuntos que el
lector también encontrará caracterizado con rigor en estos capítulos.},
	langid = {spanish},
	pagetotal = {381},
	isbn = {9788434487772},
	publisher = Ariel,
	edition = {2},
	language = {spanish},
	date = {2007},
	title = {Elementos de lógica formal},
	author = {Badesa, Calixto and Jané, Ignacio and Jansana, Ramón}
}

@Book{ben-ari:mathematical_logic_computer_science,
	enlaces = {Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-1-4471-4129-7
Springer: http://www.springer.com/gp/book/9781447141280
},
	file = {Ben-Ari - 2012 - Mathematical Logic for Computer Science.pdf},
	keywords = {Lógica matemática},
	language = {english},
	langidopts = {variant=british},
	langid = {english},
	abstract = {_Mathematical Logic for Computer Science_ is a mathematics textbook with theorems and proofs, but
the choice of topics has been guided by the needs of students of computer science. The method of
semantic tableaux provides an elegant way to teach logic that is both theoretically sound and easy
to understand. The uniform use of tableaux-based techniques facilitates learning advanced logical
systems based on what the student has learned from elementary systems.

The logical systems presented are: propositional logic, first-order logic, resolution and its
application to logic programming, Hoare logic for the verification of sequential programs, and
linear temporal logic for the verification of concurrent programs.

The third edition has been entirely rewritten and includes new chapters on central topics of modern
computer science: SAT solvers and model checking.},
	doi = {10.1007/978-1-4471-4129-7},
	author = {Ben-Ari, Mordechai},
	date = {2012},
	edition = {3},
	isbn = {9781447141280},
	pagetotal = {346},
	publisher = Springer,
	title = {Mathematical Logic for Computer Science}
}

@Article{bianchi_et_al:survey_metaheuristics_stochastic_combinatorial_optimization,
	file = {Bianchi at al - 2009 - A survey on metaheuristics for stochastic combinatorial optimization.pdf},
	keywords = {Metaheurísticas, Optimización estocástica},
	abstract = {Metaheuristics are general algorithmic frameworks, often nature-inspired,
designed to solve complex optimization problems, and they are a growing
research area since a few decades. In recent years, metaheuristics are emerging
as successful alternatives to more classical approaches also for solving
optimization problems that include in their mathematical formulation uncertain,
stochastic, and dynamic information. In this paper metaheuristics such as Ant
Colony Optimization, Evolutionary Computation, Simulated Annealing, Tabu Search
and others are introduced, and their applications to the class of Stochastic
Combinatorial Optimization Problems (SCOPs) is thoroughly reviewed. Issues
common to all metaheuristics, open problems, and possible directions of
research are proposed and discussed. In this survey, the reader familiar to
metaheuristics finds also pointers to classical algorithmic approaches to
optimization under uncertainty, and useful informations to start working on
this problem domain, while the reader new to metaheuristics should find a good
tutorial in those metaheuristics that are currently being applied to
optimization under uncertainty, and motivations for interest in this field.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1007/s11047-008-9098-4},
	pages = {239-287},
	number = {2},
	volume = {8},
	xdata = {natural_computing},
	language = {english},
	date = {2009},
	title = {A survey on metaheuristics for stochastic combinatorial optimization},
	author = {Bianchi, Leonora and Dorigo, Marco and Gambardella, Luca Maria and Gutjahr, Walter J.}
}

@Book{birge_louveaux:introduction_stochastic_programming,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2604642
Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-1-4614-0237-4
},
	file = {Birge _ Louveaux - 2011 - Introduction to Stochastic Programming.pdf},
	keywords = {Investigación operativa, Optimización estocástica, Programación matemática},
	abstract = {The aim of stochastic programming is to find optimal decisions in problems
which involve uncertain data. This field is currently developing rapidly with
contributions from many disciplines including operations research, mathematics,
and probability. At the same time, it is now being applied in a wide variety of
subjects ranging from agriculture to financial planning and from industrial
engineering to computer networks. This textbook provides a first course in
stochastic programming suitable for students with a basic knowledge of linear
programming, elementary analysis, and probability. The authors aim to present a
broad overview of the main themes and methods of the subject. Its prime goal is
to help students develop an intuition on how to model uncertainty into
mathematical problems, what uncertainty changes bring to the decision process,
and what techniques help to manage uncertainty in solving the problems.

In this extensively updated new edition there is more material on methods and
examples including several new approaches for discrete variables, new results
on risk measures in modeling and Monte Carlo sampling methods, a new chapter on
relationships to other methods including approximate dynamic programming,
robust optimization and online methods.

The book is highly illustrated with chapter summaries and many examples and
exercises. Students, researchers and practitioners in operations research and
the optimization area will find it particularly of interest.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9781461402367},
	doi = {10.1007/978-1-4614-0237-4},
	pagetotal = {485},
	isbn = {9781461402367},
	publisher = Springer,
	series = Springer_Operations_Financial,
	edition = {2},
	language = {english},
	date = {2011},
	title = {Introduction to Stochastic Programming},
	author = {Birge, John R. and Louveaux, François}
}

@Book{bivand_et_al:applied_spatial_data_analysis_r,
	enlaces = {Recurso electrónico (SpringerLink): http://www.us.debiblio.com/login?url=http://dx.doi.org/10.1007/978-1-4614-7618-4
},
	file = {Bivand et al - 2013 - Applied Spatial Data Analysis with R.pdf},
	keywords = {Análisis de datos, Lenguaje de programación R},
	abstract = {Applied Spatial Data Analysis with R, second edition, is divided into two basic
parts, the first presenting R packages, functions, classes and methods for
handling spatial data. This part is of interest to users who need to access and
visualise spatial data. Data import and export for many file formats for
spatial data are covered in detail, as is the interface between R and the open
source GRASS GIS and the handling of spatio-temporal data. The second part
showcases more specialised kinds of spatial data analysis, including spatial
point pattern analysis, interpolation and geostatistics, areal data analysis
and disease mapping. The coverage of methods of spatial data analysis ranges
from standard techniques to new developments, and the examples used are largely
taken from the spatial statistics literature. All the examples can be run using
R contributed packages available from the CRAN website, with code and
additional data sets from the book's own website. Compared to the first
edition, the second edition covers the more systematic approach towards
handling spatial data in R, as well as a number of important and widely used
CRAN packages that have appeared since the first edition.

This book will be of interest to researchers who intend to use R to handle,
visualise, and analyse spatial data. It will also be of interest to spatial
data analysts who do not use R, but who are interested in practical aspects of
implementing software for spatial data analysis. It is a suitable companion
book for introductory spatial statistics courses and for applied methods
courses in a wide range of subjects using spatial data, including human and
physical geography, geographical information science and geoinformatics, the
environmental sciences, ecology, public health and disease control, economics,
public administration and political science.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9781461476177
http://www.asdar-book.org},
	doi = {10.1007/978-1-4614-7618-4},
	pagetotal = {405},
	isbn = {9781461476177},
	publisher = Springer,
	series = Springer_Use_R,
	edition = {2},
	language = {english},
	date = {2013},
	title = {Applied Spatial Data Analysis with R},
	author = {Bivand, Roger S. and Pebesma, Edzer and Gómez-Rubio, Virgilio}
}

@Book{bolon-canedo_alonso-betanzos:recent_advances_ensembles_feature_selection,
	series = Intelligent_Systems_Library,
	keywords = {Aprendizaje automático, No disponible en la BUS},
	abstract = {This book offers a comprehensive overview of ensemble learning in the field of
feature selection (FS), which consists of combining the output of multiple
methods to obtain better results than any single method. It reviews various
techniques for combining partial results, measuring diversity and evaluating
ensemble performance.

With the advent of Big Data, feature selection (FS) has become more necessary
than ever to achieve dimensionality reduction. With so many methods available,
it is difficult to choose the most appropriate one for a given setting, thus
making the ensemble paradigm an interesting alternative.

The authors first focus on the foundations of ensemble learning and classical
approaches, before diving into the specific aspects of ensembles for FS, such
as combining partial results, measuring diversity and evaluating ensemble
performance. Lastly, the book shows examples of successful applications of
ensembles for FS and introduces the new challenges that researchers now face.
As such, the book offers a valuable guide for all practitioners, researchers
and graduate students in the areas of machine learning and data mining.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9783319900797},
	doi = {10.1007/978-3-319-90080-3},
	pagetotal = {205},
	isbn = {978-3-319-90079-7},
	publisher = Springer,
	number = {147},
	language = {english},
	date = {2018},
	title = {Recent Advances in Ensembles for Feature Selection},
	author = {Bolón-Canedo, Verónica and Alonso-Betanzos, Amparo}
}

@Book{bolon-canedo_et_al:feature_selection_high_dimensional_data,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2714872},
	series = Springer_AI_Foundations,
	keywords = {Aprendizaje automático, Inteligencia artificial},
	abstract = {This book offers a coherent and comprehensive approach to feature subset selection in the scope of
classification problems, explaining the foundations, real application problems and the challenges
of feature selection for high-dimensional data.

The authors first focus on the analysis and synthesis of feature selection algorithms, presenting a
comprehensive review of basic concepts and experimental results of the most well-known algorithms.

They then address different real scenarios with high-dimensional data, showing the use of feature
selection algorithms in different contexts with different requirements and information: microarray
data, intrusion detection, tear film lipid layer classification and cost-based features. The book
then delves into the scenario of big dimension, paying attention to important problems under
high-dimensional spaces, such as scalability, distributed processing and real-time processing,
scenarios that open up new and interesting challenges for researchers.

The book is useful for practitioners, researchers and graduate students in the areas of machine
learning and data mining.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/gp/book/9783319218571},
	doi = {10.1007/978-3-319-21858-8},
	pagetotal = {147},
	isbn = {9783319218571},
	publisher = Springer,
	language = {english},
	date = {2015},
	title = {Feature Selection for High-Dimensional Data},
	author = {Bolón-Canedo, Verónica and Sánchez-Maroño, Noelia and Alonso-Betanzos, Amparo}
}

@Article{branco_et_al:survey_predictive_modeling_imbalanced_domains,
	xdata = {acm_computing_surveys},
	pagetotal = {50},
	file = {Branco et al - 2016 - A Survey of Predictive Modeling on Imbalanced Domains.pdf},
	keywords = {Aprendizaje automático, Inteligencia artificial},
	abstract = {Many real-world data-mining applications involve obtaining predictive models using datasets with
strongly imbalanced distributions of the target variable. Frequently, the least-common values of
this target variable are associated with events that are highly relevant for end users (e.g., fraud
detection, unusual returns on stock markets, anticipation of catastrophes, etc.). Moreover, the
events may have different costs and benefits, which, when associated with the rarity of some of
them on the available training data, creates serious problems to predictive modeling techniques.
This article presents a survey of existing techniques for handling these important applications of
predictive analytics. Although most of the existing work addresses classification tasks (nominal
target variables), we also describe methods designed to handle similar problems within regression
tasks (numeric target variables). In this survey, we discuss the main challenges raised by
imbalanced domains, propose a definition of the problem, describe the main approaches to these
tasks, propose a taxonomy of the methods, summarize the conclusions of existing comparative studies
as well as some theoretical analyses of some methods, and refer to some related problems within
predictive modeling.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1145/2907070},
	number = {2},
	volume = {49},
	language = {english},
	date = {2016},
	title = {A Survey of Predictive Modeling on Imbalanced Domains},
	author = {Branco, Paula and Torgo, Luís and Ribeiro, Rita P.}
}

@Book{bratko:prolog_programming_artificial_intelligence,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2495400},
	keywords = {Inteligencia artificial, Lenguaje de programación Prolog},
	abstract = {The fourth edition of this best-selling guide to Prolog and Artificial Intelligence has been
updated to include key developments in the field while retaining its lucid approach to these
topics. New and extended topics include Constraint Logic Programming, abductive reasoning and
partial order planning.

Divided into two parts, the first part of the book introduces the programming language Prolog,
while the second part teaches Artificial Intelligence using Prolog as a tool for the implementation
of AI techniques.

This textbook is meant to teach Prolog as a practical programming tool and so it concentrates on
the art of using the basic mechanisms of Prolog to solve interesting problems. The fourth edition
has been fully revised and extended to provide an even greater range of applications, making it a
self-contained guide to Prolog, AI or AI Programming for students and professional programmers.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://catalogue.pearsoned.co.uk/educator/product/Prolog-Programming-for-Artificial-Intelligence/9780321417466.page},
	pagetotal = {696},
	isbn = {9780321417466},
	publisher = Addison-Wesley,
	edition = {4},
	language = {english},
	date = {2012},
	title = {Prolog Programming for Artificial Intelligence},
	author = {Bratko, Ivan}
}

@Book{breiman_et_al:classification_regression_trees,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1461888},
	keywords = {Aprendizaje automático, Inteligencia artificial},
	abstract = {The methodology used to construct tree structured rules is the focus of this monograph. Unlike many
other statistical procedures, which moved from pencil and paper to calculators, this text's use of
trees was unthinkable before computers. Both the practical and theoretical sides have been
developed in the authors' study of tree methods. Classification and Regression Trees reflects these
two sides, covering the use of trees as a data analysis method, and in a more mathematical
framework, proving some of their fundamental properties.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.crcpress.com/Classification-and-Regression-Trees/Breiman-Friedman-Stone-Olshen/p/book/9780412048418},
	pagetotal = {368},
	isbn = {9780412048418},
	publisher = CRC,
	language = {english},
	date = {1984},
	title = {Classification and Regression Trees},
	author = {Breiman, Leo and Friedman, Jerome H. and Olshen, Richard A. and Stone, Charles J.}
}

@Collection{brooks_et_al:handbook_markov_chain_monte_carlo,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2560735
Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2649734},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.crcpress.com/Handbook-of-Markov-Chain-Monte-Carlo/Brooks-Gelman-Jones-Meng/p/book/9781420079418},
	language = {english},
	editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin L. and Meng, Xiao-Ling},
	title = {Handbook of Markov Chain Monte Carlo},
	isbn = {9781420079418},
	series = CRC_Modern_Statistical_Methods,
	abstract = {Since their popularization in the 1990s, Markov chain Monte Carlo (MCMC) methods have
revolutionized statistical computing and have had an especially profound impact on the practice of
Bayesian statistics. Furthermore, MCMC methods have enabled the development and use of intricate
models in an astonishing array of disciplines as diverse as fisheries science and economics. The
wide-ranging practical importance of MCMC has sparked an expansive and deep investigation into
fundamental Markov chain theory.

The **Handbook of Markov Chain Monte Carlo** provides a reference for the broad audience of
developers and users of MCMC methodology interested in keeping up with cutting-edge theory and
applications. The first half of the book covers MCMC foundations, methodology, and algorithms. The
second half considers the use of MCMC in a variety of practical applications including in
educational research, astrophysics, brain imaging, ecology, and sociology.

The in-depth introductory section of the book allows graduate students and practicing scientists
new to MCMC to become thoroughly acquainted with the basic theory, algorithms, and applications.
The book supplies detailed examples and case studies of realistic scientific problems presenting
the diversity of methods used by the wide-ranging MCMC community. Those familiar with MCMC
methods will find this book a useful refresher of current theory and recent developments.},
	pagetotal = {619},
	publisher = CRC,
	date = {2011},
	keywords = {Estadística computacional, Métodos de Monte Carlo, Modelos de Markov}
}

@Article{bryce_kambhampati:tutorial_planning_graph_based_reachability_heuristics,
	enlaces = {Recurso electrónico (ProQuest): http://0-search.proquest.com.fama.us.es/docview/208135127/602D16260C344B34PQ/8},
	xdata = {ai_magazine},
	file = {Bryce _ Kambhampati - 2007 - A Tutorial on Planning Graph-Based Reachability Heuristics.pdf},
	keywords = {Inteligencia artificial, Planificación automática},
	abstract = {The primary revolution in automated planning in the last decade has been the very impressive
scale-up in planner performance. A large part of the credit for this can be attributed squarely to
the invention and deployment of powerful reachability heuristics. Most, if not all, modern
reachability heuristics are based on a remarkably extensible data structure called the planning
graph, which made its debut as a bit player in the success of GraphPlan, but quickly grew in
prominence to occupy the center stage. Planning graphs are a cheap means to obtain informative
look-ahead heuristics for search and have become ubiquitous in state-of-the-art heuristic search
planners. We present the foundations of planning graph heuristics in classical planning and explain
how their flexibility lets them adapt to more expressive scenarios that consider action costs, goal
utility, numeric resources, time, and uncertainty.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.aaai.org/ojs/index.php/aimagazine/article/view/2028},
	pages = {47-83},
	number = {1},
	volume = {28},
	language = {english},
	date = {2007},
	title = {A Tutorial on Planning Graph–Based Reachability Heuristics},
	author = {Bryce, Daniel and Kambhampati, Subbarao}
}

@Book{cappe_et_al:inference_hidden_markov_models,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/0-387-28982-8},
	file = {Cappé et al - 2005 - Inference in Hidden Markov Models.pdf},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/978-0-387-40264-2},
	doi = {10.1007/0-387-28982-8},
	language = {english},
	title = {Inference in Hidden Markov Models},
	isbn = {9780387402642},
	series = {Springer Series in Statistics},
	abstract = {Hidden Markov models have become a widely used class of statistical models with applications in
diverse areas such as communications engineering, bioinformatics, finance and many more. This book
is a comprehensive treatment of inference for hidden Markov models, including both algorithms and
statistical theory. Topics range from filtering and smoothing of the hidden Markov chain to
parameter estimation, Bayesian methods and estimation of the number of states.

In a unified way the book covers both models with finite state spaces, which allow for exact
algorithms for filtering, estimation etc. and models with continuous state spaces (also called
state-space models) requiring approximate simulation-based algorithms that are also described in
detail. Simulation in hidden Markov models is addressed in five different chapters that cover both
Markov chain Monte Carlo and sequential Monte Carlo approaches. Many examples illustrate the
algorithms and theory. The book also carefully treats Gaussian linear state-space models and their
extensions and it contains a chapter on general Markov chain theory and probabilistic aspects of
hidden Markov models.

This volume will suit anybody with an interest in inference for stochastic processes, and it will
be useful for researchers and practitioners in areas such as statistics, signal processing,
communications engineering, control theory, econometrics, finance and more. The algorithmic parts
of the book do not require an advanced mathematical background, while the more theoretical parts
require knowledge of probability theory at the measure-theoretical level.},
	pagetotal = {653},
	publisher = Springer,
	author = {Cappé, Olivier and Moulines, Eric and Rydén, Tobias},
	date = {2005},
	keywords = {Modelos de Markov}
}

@book{castillo_et_al:sistemas_expertos_modelos_redes_probabilisticas,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2692134
Recurso electrónico (ebrary): http://0-site.ebrary.com.fama.us.es/lib/unisev/Doc?id=10467096},
	langid = {spanish},
	publisher = {Academia Española de Ingeniería},
	language = {spanish},
	date = {1996},
	title = {Sistemas Expertos y Modelos de Redes Probabilísticas},
	isbn = {9788460093954},
	pagetotal = {627},
	author = {Castillo, Enrique and Gutiérrez, José Manuel and Hadi, Ali S.},
	keywords = {Inteligencia artificial, Redes bayesianas},
	file = {Castillo et al - 1996 - Sistemas Expertos y Modelos de Redes Probabilísticas.pdf}
}

@Book{chambers:extending_R,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2793838
},
	keywords = {Lenguaje de programación R},
	abstract = {Written by John M. Chambers, the leading developer of the original S software,
__Extending R__ covers key concepts and techniques in R to support analysis and
research projects. It presents the core ideas of R, provides programming
guidance for projects of all scales, and introduces new, valuable techniques
that extend R.

The book first describes the fundamental characteristics and background of R,
giving readers a foundation for the remainder of the text. It next discusses
topics relevant to programming with R, including the apparatus that supports
extensions. The book then extends R’s data structures through object-oriented
programming, which is the key technique for coping with complexity. The book
also incorporates a new structure for interfaces applicable to a variety of
languages.

A reflection of what R is today, this guide explains how to design and organize
extensions to R by correctly using objects, functions, and interfaces. It
enables current and future users to add their own contributions and packages to
R.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.crcpress.com/Extending-R/Chambers/p/book/9781498775717},
	pagetotal = {364},
	isbn = {9781498775717},
	publisher = CRC,
	series = CRC_R_Series,
	language = {english},
	date = {2016},
	author = {Chambers, John M.},
	title = {Extending R}
}

@Collection{clarke_et_al:handbook_model_checking,
	keywords = {Libro solicitado, Lógica matemática, No disponible en la BUS, Verificación de modelos},
	abstract = {Model checking is a computer-assisted method for the analysis of dynamical
systems that can be modeled by state-transition systems. Drawing from research
traditions in mathematical logic, programming languages, hardware design, and
theoretical computer science, model checking is now widely used for the
verification of hardware and software in industry.

The editors and authors of this handbook are among the world's leading
researchers in this domain, and the 32 contributed chapters present a thorough
view of the origin, theory, and application of model checking. In particular,
the editors classify the advances in this domain and the chapters of the
handbook in terms of two recurrent themes that have driven much of the research
agenda: the algorithmic challenge, that is, designing model-checking algorithms
that scale to real-life problems; and the modeling challenge, that is,
extending the formalism beyond Kripke structures and temporal logic.

The book will be valuable for researchers and graduate students engaged with
the development of formal methods and verification tools.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9783319105741},
	doi = {10.1007/978-3-319-10575-8},
	pagetotal = {1210},
	isbn = {9783319105741},
	publisher = Springer,
	language = {english},
	date = {2018},
	title = {Handbook of Model Checking},
	editor = {Clarke, Edmund Melson and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick}
}

@Book{cleveland:elements_graphing_data,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1496987
},
	keywords = {Visualización de datos},
	langidopts = {variant=british},
	langid = {english},
	pagetotal = {297},
	isbn = {9780963488411},
	publisher = Hobart,
	edition = "Revised Edition",
	language = {english},
	date = {1994},
	title = {The Elements of Graphing Data},
	author = {Cleveland, William Swain}
}

@Book{cleveland:visualizing_data,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1504807
},
	keywords = {Visualización de datos},
	langidopts = {variant=british},
	langid = {english},
	pagetotal = {360},
	isbn = {9780963488404},
	publisher = Hobart,
	language = {english},
	date = {1993},
	title = {Visualizing Data},
	author = {Cleveland, William Swain}
}

@XData{computers_communications_control,
	journaltitle = {International Journal of Computers Communications \& Control},
	journalsubtitle = {With Emphasis on the Integration of Three Technologies},
	issn = {1841-9836}
}

@Book{cook_swayne:interactive_dynamic_graphics_data_analysis,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1987556
Recurso electrónico (SpringerLink): http://www.us.debiblio.com/login?url=http://dx.doi.org/10.1007/978-0-387-71762-3
},
	file = {Cook _ Swayne - 2007 - Interactive and Dynamic Graphics for Data Analysis.pdf},
	keywords = {Gráficos interactivos, Visualización de datos},
	abstract = {This richly illustrated book describes the use of interactive and dynamic
graphics as part of multidimensional data analysis. Chapters include
clustering, supervised classification, and working with missing values. A
variety of plots and interaction methods are used in each analysis, often
starting with brushing linked low-dimensional views and working up to manual
manipulation of tours of several variables. The role of graphical methods is
shown at each step of the analysis, not only in the early exploratory phase,
but in the later stages, too, when comparing and evaluating models.

All examples are based on freely available software: GGobi for interactive
graphics and R for static graphics, modeling, and programming. The printed book
is augmented by a wealth of material on the web, encouraging readers follow the
examples themselves. The web site has all the data and code necessary to
reproduce the analyses in the book, along with movies demonstrating the
examples.

The book may be used as a text in a class on statistical graphics or
exploratory data analysis, for example, or as a guide for the independent
learner. Each chapter ends with a set of exercises.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780387717616},
	doi = {10.1007/978-0-387-71762-3},
	pagetotal = {188},
	isbn = {9780387717616},
	publisher = Springer,
	series = Springer_Use_R,
	language = {english},
	subtitle = {With R and GGobi},
	date = {2007},
	title = {Interactive and Dynamic Graphics for Data Analysis},
	author = {Cook, Dianne and Swayne, Deborah F.}
}

@Book{cortez:modern_optimization_r,
	date = {2014},
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2667273
Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-3-319-08263-9},
	file = {Cortez - 2014 - Modern Optimization with R.pdf},
	keywords = {Inteligencia artificial, Lenguaje de programación R, Metaheurísticas},
	abstract = {The goal of this book is to gather in a single document the most relevant concepts related to
modern optimization methods, showing how such concepts and methods can be addressed using the open
source, multi-platform R tool. Modern optimization methods, also known as metaheuristics, are
particularly useful for solving complex problems for which no specialized optimization algorithm
has been developed. These methods often yield high quality solutions with a more reasonable use of
computational resources (e.g. memory and processing effort). Examples of popular modern methods
discussed in this book are: simulated annealing; tabu search; genetic algorithms; differential
evolution; and particle swarm optimization. This book is suitable for undergraduate and graduate
students in Computer Science, Information Technology, and related areas, as well as data analysts
interested in exploring modern optimization methods using R.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783319082622},
	doi = {10.1007/978-3-319-08263-9},
	pagetotal = {188},
	isbn = {9783319082622},
	publisher = Springer,
	series = Springer_Use_R,
	language = {english},
	title = {Modern Optimization with R},
	author = {Cortez, Paulo}
}

@Book{cotton:testing_R_code,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2757658},
	keywords = {Lenguaje de programación R},
	abstract = {The problem with programming is that you are always one typo away from writing
something silly. Likewise with data analysis, a small mistake in your model can
lead to a big mistake in your results. Combining the two disciplines means that
it is all too easy for a missed minus sign to generate a false prediction that
you don’t spot until it’s too late. Testing is the only way to be sure that
your code, and your results, are correct.

__Testing R Code__ teaches you how to perform development-time testing using
the testthat package, allowing you to ensure that your code works as intended.
The book also teaches run-time testing using the assertive package; enabling
your users to correctly run your code.

After beginning with an introduction to testing in R, the book explores more
advanced cases such as integrating tests into R packages; testing code that
accesses databases; testing C++ code with Rcpp; and testing graphics. Each
topic is explained with real-world examples, and has accompanying exercises for
readers to practise their skills — only a small amount of experience with R is
needed to get started!},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.crcpress.com/Testing-R-Code/Cotton/p/book/9781498763653},
	pagetotal = {178},
	isbn = {9781498763653},
	publisher = CRC,
	series = CRC_R_Series,
	language = {english},
	date = {2017},
	title = {Testing R Code},
	author = {Cotton, Richard}
}

@Book{cuena:logica_informatica,
	keywords = {Lógica matemática},
	langid = {spanish},
	pagetotal = {552},
	isbn = {9788420686018},
	publisher = Alianza,
	language = {spanish},
	date = {1985},
	title = {Lógica informática},
	author = {Cuena Bartolomé, José}
}

@Book{cuevas_et_al:evolutionary_computation_techniques,
	file = {Cuevas et al - 2017 - Evolutionary Computation Techniques: A Comparative Perspective.pdf},
	keywords = {Computación evolutiva, No disponible en la BUS},
	abstract = {This book compares the performance of various evolutionary computation (EC)
techniques when they are faced with complex optimization problems extracted
from different engineering domains. Particularly focusing on recently developed
algorithms, it is designed so that each chapter can be read independently.
Several comparisons among EC techniques have been reported in the literature,
however, they all suffer from one limitation: their conclusions are based on
the performance of popular evolutionary approaches over a set of synthetic
functions with exact solutions and well-known behaviors, without considering
the application context or including recent developments. In each chapter, a
complex engineering optimization problem is posed, and then a particular EC
technique is presented as the best choice, according to its search
characteristics. Lastly, a set of experiments is conducted in order to compare
its performance to other popular EC methods.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783319511092},
	doi = {10.1007/978-3-319-51109-2},
	pagetotal = {222},
	isbn = {9783319511085},
	publisher = Springer,
	number = {686},
	series = Springer_Computational_Intelligence,
	language = {english},
	date = {2017},
	title = {Evolutionary Computation Techniques: A Comparative Perspective},
	author = {Cuevas, Erik and Osuna, Valentín and Oliva, Diego Alberto}
}

@InProceedings{daly_shen:accelerate_learning_bayesian_network,
	file = {Daly _ Shen - 2007 - Methods to Accelerate the Learning of Bayesian Network Structures.pdf},
	keywords = {Redes bayesianas},
	abstract = {Bayesian networks have become a standard technique in the representation of uncertain knowledge.
This paper proposes methods that can accelerate the learning of a Bayesian network structure from a
data set. These methods are applicable when learning an equivalence class of Bayesian network
structures whilst using a score and search strategy. They work by constraining the number of
validity tests that need to be done and by caching the results of validity tests. The results of
experiments show that the methods improve the performance of algorithms that search through the
space of equivalence classes multiple times and that operate on wide data sets. The experiments
were performed by sampling data from six standard Bayesian networks and running an ant colony
optimization algorithm designed to learn a Bayesian network equivalence class.},
	langidopts = {variant=british},
	langid = {english},
	language = {english},
	booktitle = {Proceedings of the 2007 UK Workshop on Computational Intelligence},
	date = {2007},
	title = {Methods to Accelerate the Learning of Bayesian Network Structures},
	author = {Daly, Rónán and Shen, Qiang}
}

@book{darwiche:modeling_reasoning_bayesian_networks,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2068386},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.cambridge.org/core/books/modeling-and-reasoning-with-bayesian-networks/8A3769B81540EA93B525C4C2700C9DE6},
	doi = {10.1017/CBO9780511811357},
	language = {english},
	title = {Modeling and Reasoning with Bayesian Networks},
	isbn = {9780521884389},
	abstract = {This book is a thorough introduction to the formal foundations and practical applications of
Bayesian networks. It provides an extensive discussion of techniques for building Bayesian networks
that model real-world situations, including techniques for synthesizing models from design,
learning models from data, and debugging models using sensitivity analysis. It also treats exact
and approximate inference algorithms at both theoretical and practical levels. The treatment of
exact algorithms covers the main inference paradigms based on elimination and conditioning and
includes advanced methods for compiling Bayesian networks, time-space tradeoffs, and exploiting
local structure of massively connected networks. The treatment of approximate algorithms covers the
main inference paradigms based on sampling and optimization and includes influential algorithms
such as importance sampling, MCMC, and belief propagation. The author assumes very little
background on the covered subjects, supplying in-depth discussions for theoretically inclined
readers and enough practical details to provide an algorithmic cookbook for the system developer.},
	pagetotal = {548},
	publisher = Cambridge,
	author = {Darwiche, Adnan},
	date = {2009},
	keywords = {Inteligencia artificial, Redes bayesianas}
}

@Book{dathan_ramnath:object_oriented_analysis_design_implementation,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2705307},
	keywords = {Programación orientada a objetos},
	abstract = {The second edition of this textbook includes revisions based on the feedback on the first edition.
In a new chapter the authors provide a concise introduction to the remainder of UML diagrams,
adopting the same holistic approach as the first edition.

Using a case-study-based approach for providing a comprehensive introduction to the principles of
object-oriented design, it includes:

* A sound footing on object-oriented concepts such as classes, objects, interfaces, inheritance,
  polymorphism, dynamic linking, etc.
* A good introduction to the stage of requirements analysis
* Use of UML to document user requirements and design
* An extensive treatment of the design process
* Coverage of implementation issues
* Appropriate use of design and architectural patterns
* Introduction to the art and craft of refactoring
* Pointers to resources that further the reader's knowledge

The focus of the book is on implementation aspects, without which the learning is incomplete. This
is achieved through the use of case studies for introducing the various concepts of analysis and
design, ensuring that the theory is never separate from the implementation aspects.

All the main case studies used in this book have been implemented by the authors using Java. An
appendix on Java provides a useful short tutorial on the language.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/978-3-319-24278-1},
	doi = {10.1007/978-3-319-24280-4},
	pagetotal = {471},
	isbn = {9783319242781},
	publisher = Springer,
	series = Springer_Undergraduate_Topics,
	edition = {2},
	language = {english},
	date = {2015},
	subtitle = {An Integrated Approach},
	title = {Object-Oriented Analysis, Design and Implementation},
	author = {Dathan, Brahma and Ramnath, Sarnath}
}

@Book{de:api_management,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2793819
},
	keywords = {Programación},
	abstract = {Maximize the impact of your assets and business services by providing APIs for
developers and other users. The journey described in this book starts with
identifying business assets. As part of the API team, you then need to identify
and define the requirements of traffic management, security, mediation, and
orchestration. You also must define metrics for the analytics to measure the
success of the overall API program. API documentation and the ease of developer
onboarding also determine the success of the APIs. Finally, monetization of
these APIs leads to revenue generation for the enterprise.

Author De — an expert in building and managing API solutions — provides
enterprise architects, designers, and technologists with insight into the world
of APIs and the various technical aspects of building and managing an effective
API management solution. _API Management: Developing and Managing APIs for your
Organization_:

* Introduces the basics of APIs and highlights their value
* Provides an overview of technologies for building an API management solution
  and defines the requirements, including how to build a RESTful API
* Offers design principles for building developer-friendly APIs
* Explains how to secure your APIs
* Shows how to use API analytics to measure the success of your APIs
* Demonstrates how to monetize APIs 

Finally, _API Management_ touches on various technical nuances of creating,
distributing, and managing an API. This book will not only help you learn how
to design, build, deploy, and manage an API for an enterprise scale, but also
generate revenue for your organization.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781484213063},
	doi = {10.1007/978-1-4842-1305-6},
	pagetotal = {195},
	isbn = {9781484213063},
	publisher = Apress,
	language = {english},
	subtitle = {An Architect's Guide to Developing and Managing APIs for Your Organization},
	date = {2017},
	title = {API Management},
	author = {De, Brajesh}
}

@Book{diez:iniciación_logica,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1575263},
	keywords = {Lógica matemática},
	langid = {spanish},
	pagetotal = {301},
	isbn = {9788434487640},
	publisher = Ariel,
	language = {spanish},
	date = {2002},
	title = {Iniciación a la lógica},
	author = {Díez Calzada, José A.}
}

@Book{doglio:mastering_python_high_performance,
	enlaces = {Recurso electrónico: http://0-proquest.safaribooksonline.com.fama.us.es//?uiCode=sevil&xmlId=9781783989300},
	keywords = {Lenguaje de programación Python},
	abstract = {Simply knowing how to code is not enough; on mission-critical pieces of code, every bit of memory
and every CPU cycle counts, and knowing how to squish every bit of processing power out of your
code is a crucial and sought-after skill. Nowadays, Python is used for many scientific projects,
and sometimes the calculations done in those projects require some serious fine-tuning. Profilers
are tools designed to help you measure the performance of your code and help you during the
optimization process, so knowing how to use them and read their output is very handy.

This book starts from the basics and progressively moves on to more advanced topics. You’ll learn
everything from profiling all the way up to writing a real-life application and applying a full set
of tools designed to improve it in different ways. In the middle, you’ll stop to learn about the
major profilers used in Python and about some graphic tools to help you make sense of their output.
You’ll then move from generic optimization techniques onto Python-specific ones, going over the
main constructs of the language that will help you improve your speed without much of a change.
Finally, the book covers some number-crunching-specific libraries and how to use them properly to
get the best speed out of them.

After reading this book, you will know how to take any Python code, profile it, find out where the
bottlenecks are, and apply different techniques to remove them.
},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.packtpub.com/application-development/mastering-python-high-performance},
	pagetotal = {260},
	isbn = {9781783989300},
	publisher = Packt,
	language = {english},
	date = {2015},
	subtitle = {Measure, optimize, and improve the performance of your Python code with this easy-to-follow guide},
	title = {Mastering Python High Performance},
	author = {Doglio, Fernando}
}

@Book{dooley:software_development_design_coding,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2835340
},
	keywords = {Programación},
	abstract = {Learn the principles of good software design, and how to turn those principles
into great code. This book introduces you to software engineering — from the
application of engineering principles to the development of software. You'll
see how to run a software development project, examine the different phases of
a project, and learn how to design and implement programs that solve specific
problems. It's also about code construction — how to write great programs and
make them work.

Whether you're new to programming or have written hundreds of applications, in
this book you'll re-examine what you already do, and you'll investigate ways to
improve. Using the Java language, you'll look deeply into coding standards,
debugging, unit testing, modularity, and other characteristics of good
programs. With Software Development, Design and Coding, author and professor
John Dooley distills his years of teaching and development experience to
demonstrate practical techniques for great coding.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781484231524},
	doi = {10.1007/978-1-4842-3153-1},
	pagetotal = {320},
	isbn = {9781484231524},
	publisher = Apress,
	edition = {2},
	language = {english},
	subtitle = {With Patterns, Debugging, Unit Testing, and Refactoring},
	date = {2017},
	title = {Software Development, Design and Coding},
	author = {Dooley, John F.}
}

@Book{dreo_et_al:metaheuristics_hard_optimization,
	subtitle = {Methods and Case Studies},
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1690625
Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/3-540-30966-7},
	file = {Dréo et al - 2006 - Metaheuristics for Hard Optimization.pdf},
	keywords = {Inteligencia artificial, Metaheurísticas},
	abstract = {Metaheuristics for Hard Optimization comprises of three parts. The first part is devoted to the
detailed presentation of the four most widely known metaheuristics:

* the simulated annealing method,
* tabu search,
* the evolutionary algorithms,
* ant colony algorithms.

Each one of these metaheuristics is actually a family of methods, of which the essential elements
are discussed. In the second part, the book presents some other less widespread metaheuristics,
then, extensions of metaheuristics and some ways of research are described . The problem of the
choice of a metaheuristic is posed and solution methods are discussed. The last part concentrates
on three case studies from telecommunications, air traffic control, and vehicle routing.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783540230229},
	doi = {10.1007/3-540-30966-7},
	pagetotal = {372},
	isbn = {9783540230229},
	publisher = Springer,
	language = {english},
	date = {2006},
	title = {Metaheuristics for Hard Optimization},
	author = {Dréo, Johann and Pétrowski, Alain and Siarry, Patrick and Taillard, Eric}
}

@Book{du_swamy:neural_networks_statistical_learning,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-1-4471-5571-3},
	langidopts = {variant=english},
	langid = {english},
	url = {http://www.springer.com/978-1-4471-5570-6},
	doi = {10.1007/978-1-4471-5571-3},
	language = {english},
	title = {Neural Networks and Statistical Learning},
	isbn = {9781447155706},
	abstract = {Providing a broad but in-depth introduction to neural network and machine learning in a statistical
framework, this book provides a single, comprehensive resource for study and further research. All
the major popular neural network models and statistical learning approaches are covered with
examples and exercises in every chapter to develop a practical working understanding of the
content.

Each of the twenty-five chapters includes state-of-the-art descriptions and important research
results on the respective topics. The broad coverage includes the multilayer perceptron, the
Hopfield network, associative memory models, clustering models and algorithms, the radial basis
function network, recurrent neural networks, principal component analysis, nonnegative matrix
factorization, independent component analysis, discriminant analysis, support vector machines,
kernel methods, reinforcement learning, probabilistic and Bayesian networks, data fusion and
ensemble learning, fuzzy sets and logic, neurofuzzy models, hardware implementations, and some
machine learning topics. Applications to biometric/bioinformatics and data mining are also
included.

Focusing on the prominent accomplishments and their practical aspects, academic and technical
staff, graduate students and researchers will find that this provides a solid foundation and
encompassing reference for the fields of neural networks, pattern recognition, signal processing,
machine learning, computational intelligence, and data mining.},
	pagetotal = {824},
	publisher = Springer,
	author = {Du, Ke-Lin and Swamy, M. N. S.},
	date = {2014},
	keywords = {Aprendizaje automático, Redes neuronales},
	file = {Du _ Swamy - 2014 - Neural Networks and Statistical Learning.pdf}
}

@Book{edelkamp_schroedl:heuristic_search,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2705304},
	isbn = {9780123725127},
	publisher = Elsevier,
	keywords = {Búsqueda heurística, Inteligencia artificial},
	abstract = {Search has been vital to artificial intelligence from the very beginning as a core technique in
problem solving. The authors present a thorough overview of heuristic search with a balance of
discussion between theoretical analysis and efficient implementation and application to real-world
problems. Current developments in search such as pattern databases and search with efficient use of
external memory and parallel processing units on main boards and graphics cards are detailed.

Heuristic search as a problem solving tool is demonstrated in applications for puzzle solving, game
playing, constraint satisfaction and machine learning. While no previous familiarity with heuristic
search is necessary the reader should have a basic knowledge of algorithms, data structures, and
calculus. Real-world case studies and chapter ending exercises help to create a full and realized
picture of how search fits into the world of artificial intelligence and the one around us.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://store.elsevier.com/Heuristic-Search/Stefan-Edelkamp/isbn-9780123725127/},
	pagetotal = {712},
	language = {english},
	date = {2011},
	subtitle = {Theory and Applications},
	title = {Heuristic Search},
	author = {Edelkamp, Stefan and Schroedl, Stefan}
}

@Book{eiben_smith:introduction_evolutionary_computing,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2646429},
	keywords = {Computación evolutiva},
	abstract = {The overall structure of this new edition is three-tier: Part I presents the basics, Part II is
concerned with methodological issues, and Part III discusses advanced topics. In the second edition
the authors have reorganized the material to focus on problems, how to represent them, and then how
to choose and design algorithms for different representations. They also added a chapter on
problems, reflecting the overall book focus on problem-solvers, a chapter on parameter tuning,
which they combined with the parameter control and "how-to" chapters into a methodological part,
and finally a chapter on evolutionary robotics with an outlook on possible exciting developments in
this field.

The book is suitable for undergraduate and graduate courses in artificial intelligence and
computational intelligence, and for self-study by practitioners and researchers engaged with all
aspects of bioinspired design and optimization.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/gp/book/9783662448731},
	doi = {10.1007/978-3-662-44874-8},
	pagetotal = {287},
	isbn = {9783662448731},
	publisher = Springer,
	series = Springer_Natural_Computing,
	edition = {2},
	language = {english},
	date = {2015},
	title = {Introduction to Evolutionary Computing},
	author = {Eiben, A.E. and Smith, James E.}
}

@Book{einarsson:accuracy_reliability_scientific_computing,
	publisher = SIAM,
	series = SIAM_Software_Environments_Tools,
	file = {Einarsson - 2005 - Accuracy and Reliability in Scientific Computing.pdf},
	keywords = {Algoritmia, Ciencias de la computación},
	abstract = {Numerical software is used to test scientific theories, design airplanes and
bridges, operate manufacturing lines, control power plants and refineries,
analyze financial derivatives, identify genomes, and provide the understanding
necessary to derive and analyze cancer treatments. Because of the high stakes
involved, it is essential that results computed using software be accurate,
reliable, and robust. Unfortunately, developing accurate and reliable
scientific software is notoriously difficult. This book investigates some of
the difficulties related to scientific computing and provides insight into how
to overcome them and obtain dependable results. The tools to assess existing
scientific applications are described, and a variety of techniques that can
improve the accuracy and reliability of newly developed applications is
discussed.

_Accuracy and Reliability in Scientific Computing_ can be considered a handbook
for improving the quality of scientific computing. It will help computer
scientists address the problems that affect software in general as well as the
particular challenges of numerical computation: approximations occurring at all
levels, continuous functions replaced by discretized versions, infinite
processes replaced by finite ones, and real numbers replaced by finite
precision numbers. Divided into three parts, it starts by illustrating some of
the difficulties in producing robust and reliable scientific software.
Well-known cases of failure are reviewed and the what and why of numerical
computations are considered. The second section describes diagnostic tools that
can be used to assess the accuracy and reliability of existing scientific
applications. In the last section, the authors describe a variety of techniques
that can be employed to improve the accuracy and reliability of newly developed
scientific applications. The authors of the individual chapters are
international experts, many of them members of the IFIP Working Group on
Numerical Software.

_Accuracy and Reliability in Scientific Computing_ contains condensed
information on the main features of six major programming languages -- Ada, C,
C++, Fortran, Java, and Python -- and the INTLAB toolbox of the MATLAB software
and the PRECISE toolbox of Fortran are discussed in detail. This book has an
accompanying website, http://www.nsc.liu.se/wg25/book/, with codes, links,
color versions of some illustrations, and additional material.},
	url = {https://www.nsc.liu.se/wg25/book/},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1137/1.9780898718157},
	pagetotal = {327},
	isbn = {978-0-89871-584-2},
	language = {english},
	editor = {Einarsson, Bo},
	date = {2005},
	title = {Accuracy and Reliability in Scientific Computing}
}

@book{evans_swartz:approximating_integrals_monte_carlo_deterministic_methods,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2523312
Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2649726},
	langidopts = {variant=british},
	langid = {english},
	url = {https://global.oup.com/academic/product/approximating-integrals-via-monte-carlo-and-deterministic-methods-9780198502784},
	language = {english},
	title = {Approximating Integrals via Monte Carlo and Deterministic Methods},
	isbn = {9780198502784},
	series = Oxford_Statistical_Science,
	abstract = {This book is designed to introduce graduate students and researchers to the primary methods useful
for approximating integrals. The emphasis is on those methods that have been found to be of
practical use, and although the focus is on approximating higher- dimensional integrals the
lower-dimensional case is also covered. Included in the book are asymptotic techniques, multiple
quadrature and quasi-random techniques as well as a complete development of Monte Carlo algorithms.
For the Monte Carlo section importance sampling methods, variance reduction techniques and the
primary Markov Chain Monte Carlo algorithms are covered. This book brings these various techniques
together for the first time, and hence provides an accessible textbook and reference for
researchers in a wide variety of disciplines.},
	pagetotal = {298},
	number = {20},
	publisher = Oxford,
	author = {Evans, Michael and Swartz, Timothy},
	date = {2000},
	keywords = {Estadística computacional, Métodos de Monte Carlo, Métodos numéricos}
}

@Book{fernandez-montoro:python_3_descubierto,
	publisher = RCLibros,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2455210},
	keywords = {Lenguaje de programación Python},
	langid = {spanish},
	url = {http://rclibros.es/producto/python-3/},
	pagetotal = {262},
	isbn = {9788493945046},
	language = {spanish},
	date = {2012},
	title = {Python 3 al descubierto},
	author = {Fernández Montoro, Arturo}
}

@Book{fernandez_et_al:learning_imbalanced_data_sets,
	keywords = {Aprendizaje automático, Ciencia del dato, No disponible en la BUS},
	abstract = {This book provides a general and comprehensible overview of imbalanced
learning. It contains a formal description of a problem, and focuses on its
main features, and the most relevant proposed solutions. Additionally, it
considers the different scenarios in Data Science for which the imbalanced
classification can create a real challenge.

This book stresses the gap with standard classification tasks by reviewing the
case studies and ad-hoc performance metrics that are applied in this area. It
also covers the different approaches that have been traditionally applied to
address the binary skewed class distribution. Specifically, it reviews
cost-sensitive learning, data-level preprocessing methods and algorithm-level
solutions, taking also into account those ensemble-learning solutions that
embed any of the former alternatives. Furthermore, it focuses on the extension
of the problem for multi-class problems, where the former classical methods are
no longer to be applied in a straightforward way.

This book also focuses on the data intrinsic characteristics that are the main
causes which, added to the uneven class distribution, truly hinders the
performance of classification algorithms in this scenario. Then, some notes on
data reduction are provided in order to understand the advantages related to
the use of this type of approaches.

Finally this book introduces some novel areas of study that are gathering a
deeper attention on the imbalanced data issue. Specifically, it considers the
classification of data streams, non-classical classification problems, and the
scalability related to Big Data. Examples of software libraries and modules to
address imbalanced classification are provided.

This book is highly suitable for technical professionals, senior undergraduate
and graduate students in the areas of data science, computer science and
engineering. It will also be useful for scientists and researchers to gain
insight on the current developments in this area of study, as well as future
research directions.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9783319980737},
	doi = {10.1007/978-3-319-98074-4},
	pagetotal = {377},
	isbn = {9783319980737},
	publisher = Springer,
	language = {english},
	date = {2018},
	title = {Learning from Imbalanced Data Sets},
	author = {Fernández, Alberto and García, Salvador and Galar, Mikel and Prati, Ronaldo C. and Krawczyk, Bartosz and Herrera, Francisco

}
}

@Article{filippone_et_al:survey_kernel_spectral_methods_clustering,
	xdata = {pattern_recognition},
	file = {Filippone et al - 2008 - A survey of kernel and spectral methods for clustering.pdf},
	keywords = {Análisis de grupos, Aprendizaje automático},
	abstract = {Clustering algorithms are a useful tool to explore data structures and have
been employed in many disciplines. The focus of this paper is the partitioning
clustering problem with a special interest in two recent approaches: kernel and
spectral methods. The aim of this paper is to present a survey of kernel and
spectral clustering methods, two approaches able to produce nonlinear
separating hypersurfaces between clusters. The presented kernel clustering
methods are the kernel version of many classical clustering algorithms, e.g.,
*K*-means, SOM and neural gas. Spectral clustering arise from concepts in
spectral graph theory and the clustering problem is configured as a graph cut
problem where an appropriate objective function has to be optimized. An
explicit proof of the fact that these two paradigms have the same objective is
reported since it has been proven that these two seemingly different approaches
have the same mathematical foundation. Besides, fuzzy kernel clustering methods
are presented as extensions of kernel *K*-means clustering algorithm.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1016/j.patcog.2007.05.018},
	pages = {176-190},
	number = {1},
	volume = {41},
	language = {english},
	date = {2008},
	title = {A survey of kernel and spectral methods for clustering},
	author = {Filippone, Maurizio and Camastra, Francesco and Masulli, Francesco and Rovetta, Stefano}
}

@Book{fitting:first_order_logic_automated_theorem_proving,
	isbn = {9781461275152},
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1286179},
	keywords = {Lógica matemática},
	abstract = {There are many kinds of books on formal logic. Some have philosophers as their intended audience,
some mathematicians, some computer scien­ tists. Although there is a common core to all such books,
they will be very different in emphasis, methods, and even appearance. This book is intended for
computer scientists. But even this is not precise. Within computer science formal logic turns up in
a number of areas, from pro­ gram verification to logic programming to artificial intelligence.
This book is intended for computer scientists interested in automated theo­ rem proving in
classical logic. To be more precise yet, it is essentially a theoretical treatment, not a how-to
book, although how-to issues are not neglected. This does not mean, of course, that the book will
be of no interest to philosophers or mathematicians. It does contain a thorough presentation of
formal logic and many proof techniques, and as such it contains all the material one would expect
to find in a course in formal logic covering completeness but, not incompleteness issues. The first
item to be addressed is, What are we talking about and why are we interested in it? We are
primarily talking about truth as used in mathematical discourse, and our interest in it is, or
should be, self­ evident. Truth is a semantic concept, so we begin with models and their
properties. These are used to define our subject.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781461275152},
	doi = {10.1007/978-1-4612-2360-3},
	pagetotal = {326},
	publisher = Springer,
	series = Springer_Computer_Science,
	edition = {2},
	language = {english},
	date = {1996},
	title = {First–Order Logic and Automated Theorem Proving},
	author = {Fitting, Melvin}
}

@Book{flach:machine_learning,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2563364},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.cambridge.org/9781107422223},
	language = {english},
	subtitle = {The Art and Science of Algorithms that Make Sense of Data},
	title = {Machine Learning},
	isbn = {9781107422223},
	abstract = {As one of the most comprehensive machine learning texts around, this book does justice to the
field's incredible richness, but without losing sight of the unifying principles. Peter Flach's
clear, example-based approach begins by discussing how a spam filter works, which gives an
immediate introduction to machine learning in action, with a minimum of technical fuss. Flach
provides case studies of increasing complexity and variety with well-chosen examples and
illustrations throughout. He covers a wide range of logical, geometric and statistical models and
state-of-the-art topics such as matrix factorisation and {ROC} analysis. Particular attention is
paid to the central role played by features. The use of established terminology is balanced with
the introduction of new and useful concepts, and summaries of relevant background material are
provided with pointers for revision if necessary. These features ensure Machine Learning will set a
new standard as an introductory textbook.},
	pagetotal = {409},
	publisher = Cambridge,
	author = {Flach, Peter A.},
	date = {2012},
	keywords = {Aprendizaje automático}
}

@Article{friedman_et_al:bayesian_network_classifiers,
	file = {Friedman et al - 1997 - Bayesian Network Classifiers.pdf},
	keywords = {Aprendizaje automático, Inteligencia artificial, Redes bayesianas},
	abstract = {Recent work in supervised learning has shown that a surprisingly simple
Bayesian classifier with strong assumptions of independence among features,
called naive Bayes, is competitive with state-of-the-art classifiers such as
C4.5. This fact raises the question of whether a classifier with less
restrictive assumptions can perform even better. In this paper we evaluate
approaches for inducing classifiers from data, based on the theory of learning
Bayesian networks. These networks are factored representations of probability
distributions that generalize the naive Bayesian classifier and explicitly
represent statements about independence. Among these approaches we single out a
method we call Tree Augmented Naive Bayes (TAN), which outperforms naive Bayes,
yet at the same time maintains the computational simplicity (no search
involved) and robustness that characterize naive Bayes. We experimentally
tested these approaches, using problems from the University of California at
Irvine repository, and compared them to C4.5, naive Bayes, and wrapper methods
for feature selection.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1023/A:1007465528199},
	pages = {131-163},
	number = {2-3},
	volume = {29},
	language = {english},
	date = {1997},
	xdata = {machine_learning},
	title = {Bayesian Network Classifiers},
	author = {Friedman, Nir and Geiger, Dan and Goldszmidt, Moises}
}

@Book{friendly_meyer:discrete_data_analysis_r,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2715358},
	keywords = {Lenguaje de programación R, Visualización de datos},
	abstract = {__Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count
Data__ presents an applied treatment of modern methods for the analysis of categorical data, both
discrete response data and frequency data. It explains how to use graphical methods for exploring
data, spotting unusual features, visualizing fitted models, and presenting results.

The book is designed for advanced undergraduate and graduate students in the social and health
sciences, epidemiology, economics, business, statistics, and biostatistics as well as researchers,
methodologists, and consultants who can use the methods with their own data and analyses. Along
with describing the necessary statistical theory, the authors illustrate the practical application
of the techniques to a large number of substantive problems, including how to organize data,
conduct an analysis, produce informative graphs, and evaluate what the graphs reveal about the
data.

The first part of the book contains introductory material on graphical methods for discrete data,
basic R skills, and methods for fitting and visualizing one-way discrete distributions. The second
part focuses on simple, traditional nonparametric tests and exploratory methods for visualizing
patterns of association in two-way and larger frequency tables. The final part of the text
discusses model-based methods for the analysis of discrete data.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.crcpress.com/9781498725835},
	pagetotal = {544},
	isbn = {9781498725835},
	publisher = CRC,
	series = CRC_Statistical_Science,
	language = {english},
	date = {2015},
	subtitle = {Visualization and Modeling Techniques for Categorical and Count Data},
	title = {Discrete Data Analysis with R},
	author = {Friendly, Michael and Meyer, David}
}

@Book{gamerman_lopes:markov_chain_monte_carlo,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2152028
},
	keywords = {Modelos de Markov, Métodos de Monte Carlo},
	abstract = {While there have been few theoretical contributions on the Markov Chain Monte
Carlo (MCMC) methods in the past decade, current understanding and application
of MCMC to the solution of inference problems has increased by leaps and
bounds. Incorporating changes in theory and highlighting new applications,
**Markov Chain Monte Carlo: Stochastic Simulation for Bayesian Inference,
Second Edition** presents a concise, accessible, and comprehensive introduction
to the methods of this valuable simulation technique. The second edition
includes access to an internet site that provides the code, written in R and
WinBUGS, used in many of the previously existing and new examples and
exercises. More importantly, the self-explanatory nature of the codes will
enable modification of the inputs to the codes and variation on many directions
will be available for further exploration.

Major changes from the previous edition:

* More examples with discussion of computational details in chapters on Gibbs
  sampling and Metropolis-Hastings algorithms
* Recent developments in MCMC, including reversible jump, slice sampling,
  bridge sampling, path sampling, multiple-try, and delayed rejection
* Discussion of computation using both R and WinBUGS
* Additional exercises and selected solutions within the text, with all data
  sets and software available for download from the Web
* Sections on spatial models and model adequacy

The self-contained text units make MCMC accessible to scientists in other
disciplines as well as statisticians. The book will appeal to everyone working
with MCMC techniques, especially research and graduate statisticians and
biostatisticians, and scientists handling data and formulating models. The book
has been substantially reinforced as a first reading of material on MCMC and,
consequently, as a textbook for modern Bayesian computation and Bayesian
inference courses.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.crcpress.com/Markov-Chain-Monte-Carlo-Stochastic-Simulation-for-Bayesian-Inference/Gamerman-Lopes/p/book/9781584885870},
	pagetotal = {342},
	isbn = {9781584885870},
	publisher = CRC,
	series = CRC_Statistical_Science,
	edition = {2},
	language = {english},
	subtitle = {Stochastic Simulation for Bayesian Inference},
	date = {2006},
	title = {Markov Chain Monte Carlo},
	author = {Gamerman, Dani and Lopes, Hedibert F.}
}

@Proceedings{gamez_puerta:sistemas_expertos_probabilísticos,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1408263},
	file = {Gámez-Martín _ Puerta-Callejón - 1998 - Sistemas expertos probabilísticos.pdf},
	keywords = {Inteligencia artificial, Redes bayesianas},
	abstract = {Un Sistema Experto es una herramienta informática que es capaz de simular el comportamiento de un
experto humano en una materia especializada. Un problema clave en el desarrollo de sistemas
expertos es encontrar la forma de representar y usar el conocimiento que los expertos humanos en
esa materia poseen y utilizan. Este problema se hace más difícil por el hecho de que. En muchos
campos, el conocimiento de los expertos es a menudo impreciso o incierto y. sin embargo, los
expertos son capaces de llegar a conclusiones útiles. Por tanto, todo sistema experto que pretenda
razonar 'como si' lo hiciese un ser humano debe ser capaz de trabajar con este tipo de información.
Uno de los formalismos mas potentes y mejor desarrollados para el tratamiento del conocimiento
incierto es la Teoría de la Probabilidad, que nos permite medir la creencia que tenemos en la
ocurrencia de un determinado suceso. Este libro recoge los trabajos presentados en el VIII Curso de
Verano de Informática: Sistemas Expertos Probabilísticos. Por parte de un grupo de relevantes
investigadores nacionales en el tema.},
	langid = {spanish},
	url = {https://ruidera.uclm.es/xmlui/handle/10578/6096},
	pagetotal = {318},
	isbn = {9788489958351},
	publisher = {Servicio de Publicaciones de la Universidad de Castilla-La Mancha},
	organization = {Departamento de Informática de la Escuela Universitaria Politécnica de Albacete},
	language = {spanish},
	date = {1998},
	title = {Sistemas expertos probabilísticos},
	editor = {Gámez Martín, José Antonio and Puerta Callejón, José Miguel}
}

@book{gandrud:reproducible_research_r_r_studio,
	langidopts = {variant=british},
	langid = {english},
	url = {http://christophergandrud.github.io/RepResR-RStudio/},
	language = {english},
	edition = {2},
	title = {Reproducible Research with R and R Studio},
	isbn = {9781498715379},
	series = CRC_R_Series,
	abstract = {*All the Tools for Gathering and Analyzing Data and Presenting Results*

**Reproducible Research with R and RStudio, Second Edition** brings together the skills and tools
needed for doing and presenting computational research. Using straightforward examples, the book
takes you through an entire reproducible research workflow. This practical workflow enables you to
gather and analyze data as well as dynamically present results in print and on the web.

*New to the Second Edition*

* The rmarkdown package that allows you to create reproducible research documents in PDF, HTML, and
  Microsoft Word formats using the simple and intuitive Markdown syntax
* Improvements to RStudio’s interface and capabilities, such as its new tools for handling R
  Markdown documents
* Expanded knitr R code chunk capabilities
* The kable function in the knitr package and the texreg package for dynamically creating tables to
  present your data and statistical results
* An improved discussion of file organization, enabling you to take full advantage of relative file
  paths so that your documents are more easily reproducible across computers and systems
* The dplyr, magrittr, and tidyr packages for fast data manipulation
* Numerous modifications to R syntax in user-created packages
* Changes to GitHub’s and Dropbox’s interfaces

*Create Dynamic and Highly Reproducible Research*

This updated book provides all the tools to combine your research with the presentation of your
findings. It saves you time searching for information so that you can spend more time actually
addressing your research questions. Supplementary files used for the examples and a reproducible
research project are available on the author’s website.},
	pagetotal = {323},
	publisher = {CRC},
	author = {Gandrud, Christopher},
	date = {2015},
	keywords = {Investigación reproducible, Lenguaje de programación R, No disponible en la BUS},
	file = {Gandrud - 2015 - Reproducible Research with R and R Studio.pdf}
}

@Book{gendreau_potvin:handbook_metaheuristics,
	series = Springer_Operations_Management,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-1-4419-1665-5},
	file = {Gendreau _ Potvin - 2010 - Handbook of Metaheuristics.pdf},
	keywords = {Inteligencia artificial, Metaheurísticas},
	abstract = {“… an excellent book if you want to learn about a number of individual metaheuristics." (U.
Aickelin, Journal of the Operational Research Society, Issue 56, 2005, on the First Edition) The
first edition of the Handbook of Metaheuristics was published in 2003 under the editorship of Fred
Glover and Gary A. Kochenberger. Given the numerous developments observed in the field of
metaheuristics in recent years, it appeared that the time was ripe for a second edition of the
Handbook. When Glover and Kochenberger were unable to prepare this second edition, they suggested
that Michel Gendreau and Jean-Yves Potvin should take over the editorship, and so this important
new edition is now available. Through its 21 chapters, this second edition is designed to provide a
broad coverage of the concepts, implementations and applications in this important field of
optimization. Original contributors either revised or updated their work, or provided entirely new
chapters. The Handbook now includes updated chapters on the best known metaheuristics, including
simulated annealing, tabu search, variable neighborhood search, scatter search and path relinking,
genetic algorithms, memetic algorithms, genetic programming, ant colony optimization, multi-start
methods, greedy randomized adaptive search procedure, guided local search, hyper-heuristics and
parallel metaheuristics. It also contains three new chapters on large neighborhood search,
artificial immune systems and hybrid metaheuristics. The last four chapters are devoted to more
general issues related to the field of metaheuristics, namely reactive search, stochastic search,
fitness landscape analysis and performance comparison.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781441916631},
	doi = {10.1007/978-1-4419-1665-5},
	pagetotal = {648},
	isbn = {9781441916631},
	publisher = Springer,
	number = {146},
	edition = {2},
	language = {english},
	editor = {Gendreau, Michel and Potvin, Jean-Yves},
	date = {2010},
	title = {Handbook of Metaheuristics}
}

@book{gentle:computational_statistics,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-0-387-98144-4},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780387981437},
	doi = {10.1007/978-0-387-98144-4},
	language = {english},
	title = {Computational Statistics},
	isbn = {9780387981437},
	series = Springer_Statistics_Computing,
	abstract = {Computational inference has taken its place alongside asymptotic inference and exact techniques in
the standard collection of statistical methods. Computational inference is based on an approach to
statistical methods that uses modern computational power to simulate distributional properties of
estimators and test statistics. This book describes computationally-intensive statistical methods
in a unified presentation, emphasizing techniques, such as the {PDF} decomposition, that arise in a
wide range of methods.

The book assumes an intermediate background in mathematics, computing, and applied and theoretical
statistics. The first part of the book, consisting of a single long chapter, reviews this
background material while introducing computationally-intensive exploratory data analysis and
computational inference.

The six chapters in the second part of the book are on statistical computing. This part describes
arithmetic in digital computers and how the nature of digital computations affects algorithms used
in statistical methods. Building on the first chapters on numerical computations and algorithm
design, the following chapters cover the main areas of statistical numerical analysis, that is,
approximation of functions, numerical quadrature, numerical linear algebra, solution of nonlinear
equations, optimization, and random number generation.

The third and fourth parts of the book cover methods of computational statistics, including Monte
Carlo methods, randomization and cross validation, the bootstrap, probability density estimation,
and statistical learning.

The book includes a large number of exercises with some solutions provided in an appendix.},
	pagetotal = {728},
	publisher = Springer,
	author = {Gentle, James E.},
	date = {2009},
	keywords = {Álgebra lineal, Estadística computacional, Estadística no paramétrica, Estimación de densidades, Métodos de Monte Carlo, Métodos de regresión, Métodos de remuestreo, Minería de datos, Optimización matemática},
	file = {Gentle - 2009 - Computational Statistics.pdf}
}

@Book{gentle_et_al:handbook_computational_statistics,
	series = Springer_Computational_Statistics,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-3-642-21551-3
},
	file = {Gentle et al - 2012 - Handbook of Computational Statistics.pdf},
	keywords = {Estadística computacional},
	abstract = {The Handbook of Computational Statistics - Concepts and Methods (second
edition) is a revision of the first edition published in 2004, and contains
additional comments and updated information on the existing chapters, as well
as three new chapters addressing recent work in the field of computational
statistics. This new edition is divided into 4 parts in the same way as the
first edition. It begins with "How Computational Statistics became the backbone
of modern data science" (Ch.1): an overview of the field of Computational
Statistics, how it emerged as a separate discipline, and how its own
development mirrored that of hardware and software, including a discussion of
current active research. The second part (Chs. 2 - 15) presents several topics
in the supporting field of statistical computing. Emphasis is placed on the
need for fast and accurate numerical algorithms, and some of the basic
methodologies for transformation, database handling, high-dimensional data and
graphics treatment are discussed. The third part (Chs. 16 - 33) focuses on
statistical methodology. Special attention is given to smoothing, iterative
procedures, simulation and visualization of multivariate data. Lastly, a set of
selected applications (Chs. 34 - 38) like Bioinformatics, Medical Imaging,
Finance, Econometrics and Network Intrusion Detection highlight the usefulness
of computational statistics in real-world applications.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9783642215506},
	doi = {10.1007/978-3-642-21551-3},
	pagetotal = {1192},
	isbn = {9783642215506},
	publisher = Springer,
	edition = {2},
	language = {english},
	subtitle = {Concepts and Methods},
	date = {2012},
	title = {Handbook of Computational Statistics},
	editor = {Gentle, James E. and Härdle, Wolfgang Karl and Mori, Yuichi}
}

@Book{ghallab_et_al:automated_planning,
	subtitle = {Theory and Practice},
	file = {Ghallab et al - 2004 - Automated Planning.pdf; Ghallab et al - 2004 - Automated Planning - Errata.pdf},
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1633381
Recurso electrónico (ScienceDirect): http://0-www.sciencedirect.com.fama.us.es/science/book/9781558608566
Recurso electrónico (E-Libro): http://0-site.ebrary.com.fama.us.es/lib/unisev/Doc?id=10226616
},
	abstract = {Automated planning technology now plays a significant role in a variety of demanding applications,
ranging from controlling space vehicles and robots to playing the game of bridge. These real-world
applications create new opportunities for synergy between theory and practice: observing what works
well in practice leads to better theories of planning, and better theories lead to better
performance of practical applications. Automated Planning mirrors this dialogue by offering a
comprehensive, up-to-date resource on both the theory and practice of automated planning. The book
goes well beyond classical planning, to include temporal planning, resource scheduling, planning
under uncertainty, and modern techniques for plan generation, such as task decomposition,
propositional satisfiability, constraint satisfaction, and model checking. The authors combine over
30 years experience in planning research and development to offer an invaluable text to
researchers, professionals, and graduate students.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://projects.laas.fr/planning/},
	author = {Ghallab, Malik and Nau, Dana and Traverso, Paolo},
	date = {2004},
	isbn = {9781558608566},
	keywords = {Inteligencia artificial, Planificación automática},
	language = {english},
	pagetotal = {635},
	publisher = Morgan-Kaufmann,
	title = {Automated Planning}
}

@Book{ghallab_et_al:automated_planning_acting,
	file = {Ghallab et al - 2016 - Automated Planning and Acting.pdf},
	keywords = {Inteligencia artificial, Planificación automática},
	abstract = {Autonomous AI systems need complex computational techniques for planning and performing actions.
Planning and acting require significant deliberation because an intelligent system must coordinate
and integrate these activities in order to act effectively in the real world. This book presents a
comprehensive paradigm of planning and acting using the most recent and advanced automated-planning
techniques. It explains the computational deliberation capabilities that allow an actor, whether
physical or virtual, to reason about its actions, choose them, organize them purposefully, and act
deliberately to achieve an objective. Useful for students, practitioners, and researchers, this
book covers state-of-the-art planning techniques, acting techniques, and their integration which
will allow readers to design intelligent systems that are able to act effectively in the real
world.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.cambridge.org/us/academic/subjects/computer-science/artificial-intelligence-and-natural-language-processing/automated-planning-and-acting},
	isbn = {9781107037274},
	publisher = Cambridge,
	language = {english},
	date = {2016},
	title = {Automated Planning and Acting},
	author = {Ghallab, Malik and Nau, Dana and Traverso, Paolo}
}

@Collection{gheorghe_et_al:multidisciplinary_creativity,
	keywords = {Ciencias de la computación, Computación bioinspirada, Computación con membranas},
	langidopts = {variant=british},
	langid = {english},
	pagetotal = {334},
	isbn = {9786068401638},
	publisher = {Spandugino},
	language = {english},
	subtitle = {Homage to Gheorghe Păun on His 65th Birthday},
	editor = {Gheorghe, Marian and Petre, Ion and Pérez-Jiménez, Mario J. and Rozenberg, Grzegorz and Salomaa, Arto},
	date = {2015},
	title = {Multidisciplinary Creativity}
}

@Proceedings{gong_et_al:bio_inspired_computing_theories_applications,
	enlaces = {Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-3-662-49014-3
},
	venue = {Hefei, China},
	eventtitleaddon = {BIC-TA 2015},
	eventdate = {2015-09-25/2015-09-28},
	eventtitle = {10th International Conference on Bio-Inspired Computing: Theories and Applications},
	file = {Gong et al - 2015 - Bio-Inspired Computing - Theories and Applications.pdf},
	keywords = {Computación bioinspirada},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/gp/book/9783662490136},
	doi = {10.1007/978-3-662-49014-3},
	pagetotal = {727},
	isbn = {9783662490136},
	publisher = Springer,
	series = {Communications in Computer and Information Science},
	volume = {562},
	language = {english},
	date = {2015},
	title = {Bio-Inspired Computing – Theories and Applications},
	editor = {Gong, Maoguo and Pan, Linqiang and Song, Tao and Tang, Ke and Zhang, Xingyi}
}

@Book{goodrich_tamassia:algorithm_design_applications,
	file = {Goodrich _ Tamassia - 2015 - Algorithm Design and Applications.pdf},
	keywords = {Algoritmia, No disponible en la BUS},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.wiley.com/en-es/Algorithm+Design+and+Applications-p-x000595611},
	pagetotal = {804},
	isbn = {9781118335918},
	publisher = Wiley,
	language = {english},
	date = {2015},
	title = {Algorithm Design and Applications},
	author = {Goodrich, Michael T. and Tamassia, Roberto}
}

@Book{grolemund:hands-on_programming_r,
	file = {Grolemund - 2014 - Hands-On Programming with R.pdf},
	keywords = {Lenguaje de programación R, No disponible en la BUS},
	abstract = {Learn how to program by diving into the R language, and then use your newfound skills to solve
practical data science problems. With this book, you’ll learn how to load data, assemble and
disassemble data objects, navigate R’s environment system, write your own functions, and use all of
R’s programming tools.

RStudio Master Instructor Garrett Grolemund not only teaches you how to program, but also shows you
how to get more from R than just visualizing and modeling data. You’ll gain valuable programming
skills and support your work as a data scientist at the same time.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://shop.oreilly.com/product/0636920028574.do},
	pagetotal = {250},
	isbn = {9781449359010},
	publisher = OReilly,
	language = {english},
	date = {2014},
	subtitle = {Write Your Own Functions and Simulations},
	title = {Hands-On Programming with R},
	author = {Grolemund, Garret}
}

@Collection{gutin_punnen:traveling_salesman_problem_variations,
	series = Springer_Combinatorial_Optimization,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1924759
Recurso electrónico (SpringerLink): http://www.us.debiblio.com/login?url=https://doi.org/10.1007/b101971
Recurso electrónico (E-Libro): http://www.us.debiblio.com/login?url=http://site.ebrary.com/lib/unisev/Doc?id=10067445
},
	file = {Gutin _ Punnen - 2007 - The Traveling Salesman Problem and its Variations.pdf},
	keywords = {NP-completitud},
	abstract = {This volume, which contains chapters written by reputable researchers, provides
the state of the art in theory and algorithms for the traveling salesman
problem (TSP). The book covers all important areas of study on TSP, including
polyhedral theory for symmetric and asymmetric TSP, branch and bound, and
branch and cut algorithms, probabilistic aspects of TSP, thorough computational
analysis of heuristic and metaheuristic algorithms, theoretical analysis of
approximation algorithms, including the emerging area of domination analysis of
algorithms, discussion of TSP software and variations of TSP such as bottleneck
TSP, generalized TSP, prize collecting TSP, maximizing TSP, orienteering
problem, etc.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9781402006647},
	doi = {10.1007/b101971},
	pagetotal = {830},
	isbn = {9781402006647},
	publisher = Springer,
	number = {12},
	language = {english},
	date = {2007},
	title = {The Traveling Salesman Problem and Its Variations},
	editor = {Gutin, Gregory and Punnen, Abraham P.}
}

@Book{hackeling:mastering_machine_learning,
	enlaces = {Recurso electrónico (Safari Books Online): http://0-proquest.safaribooksonline.com.fama.us.es/?uiCode=sevil&xmlId=9781783988365},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.packtpub.com/big-data-and-business-intelligence/mastering-machine-learning-scikit-learn},
	language = {english},
	subtitle = {Apply effective learning algorithms to real-world problems using scikit-learn},
	title = {Mastering Machine Learning With scikit-learn},
	isbn = {9781783988365},
	abstract = {This book examines machine learning models including logistic regression, decision trees, and
support vector machines, and applies them to common problems such as categorizing documents and
classifying images. It begins with the fundamentals of machine learning, introducing you to the
supervised-unsupervised spectrum, the uses of training and test data, and evaluating models. You
will learn how to use generalized linear models in regression problems, as well as solve problems
with text and categorical features.

You will be acquainted with the use of logistic regression, regularization, and the various loss
functions that are used by generalized linear models. The book will also walk you through an
example project that prompts you to label the most uncertain training examples. You will also use
an unsupervised Hidden Markov Model to predict stock prices.

By the end of the book, you will be an expert in scikit-learn and will be well versed in machine
learning.},
	pagetotal = {238},
	publisher = Packt,
	author = {Hackeling, Gavin},
	date = {2014},
	keywords = {Aprendizaje automático, Lenguaje de programación Python}
}

@Book{hall_stacey:python_3_absolute_beginners,
	file = {Hall _ Stacey - 2009 - Python 3 for Absolute Beginners.pdf},
	publisher = Apress,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-1-4302-1633-9},
	keywords = {Lenguaje de programación Python},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.apress.com/9781430216322},
	doi = {10.1007/978-1-4302-1633-9},
	pagetotal = {295},
	isbn = {9781430216322},
	language = {english},
	date = {2009},
	title = {Python 3 for Absolute Beginners},
	author = {Hall, Tim and Stacey, J-P}
}

@Book{hampton-smith:pro_css3_layout_techniques,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2715365},
	keywords = {Desarrollo web},
	abstract = {This books demonstrates the freshest cutting-edge layout tools found within CSS3, teaching you the
skills you’ll need to create advanced design patterns for websites and apps.

_Pro CSS3 Layout Techniques_ teaches you how to make the most of CSS3’s existing specification,
including those parts of the specification already widely implemented, as well as the upcoming
modules that are still being developed by the W3C. After reading this book you’ll be able to
confidently develop sophisticated, flexible layouts that aren't possible with CSS2.1.

CSS1 allowed designers to separate content from presentation for the first time and CSS2 cemented
support for advanced typographical control, but neither specification provided more than
rudimentary layout control. CSS3’s latest additions allow designers to craft fully responsive,
sophisticated layouts without the need for complex scripts or smoke-and-mirror workarounds.

CSS3 is still in active development, with browser vendors racing against each other to implement
the latest recommendations from the W3C. _Pro CSS3 Layout Techniques_ will help you cut through the
waffle and get straight to the heart of what works now, while showing you how to be ready for the
future of CSS!},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.apress.com/9781430265023},
	doi = {10.1007/978-1-4302-6503-0},
	pagetotal = {183},
	isbn = {9781430265023},
	publisher = Apress,
	language = {english},
	date = {2016},
	title = {Pro CSS3 Layout Techniques},
	author = {Hampton-Smith, Sam}
}

@Book{hastie_et_al:elements_statistical_learning,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2016560
Recurso electrónico: http://0-link.springer.com.fama.us.es/book/10.1007/978-0-387-84858-7},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/gp/book/9780387848570},
	doi = {10.1007/978-0-387-84858-7},
	language = {english},
	subtitle = {Data Mining, Inference, and Prediction},
	edition = {2},
	title = {The Elements of Statistical Learning},
	isbn = {9780387848570},
	series = Springer_Statistics,
	abstract = {During the past decade there has been an explosion in computation and information technology. With
it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and
marketing. The challenge of understanding these data has led to the development of new tools in the
field of statistics, and spawned new areas such as data mining, machine learning, and
bioinformatics. Many of these tools have common underpinnings but are often expressed with
different terminology. This book describes the important ideas in these areas in a common
conceptual framework. While the approach is statistical, the emphasis is on concepts rather than
mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable
resource for statisticians and anyone interested in data mining in science or industry. The book's
coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics
include neural networks, support vector machines, classification trees and boosting---the first
comprehensive treatment of this topic in any book.

This major new edition features many topics not covered in the original, including graphical
models, random forests, ensemble methods, least angle regression and path algorithms for the lasso,
non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for
"wide" data ($p$ bigger than $n$), including multiple testing and false discovery rates.},
	pagetotal = {745},
	publisher = Springer,
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	date = {2009},
	keywords = {Aprendizaje automático, Inteligencia artificial},
	file = {Hastie et al - 2009 - The Elements of Statistical Learning.pdf}
}

@Book{hofer:uncertainty_analysis_model_results,
	enlaces = {Recurso electrónico (SpringerLink): http://www.us.debiblio.com/login?url=http://dx.doi.org/10.1007/978-3-319-76297-5
},
	file = {Hofer - 2018 - The Uncertainty Analysis of Model Results.pdf},
	keywords = {Simulación por ordenador},
	abstract = {This book is a practical guide to the uncertainty analysis of computer model
applications. Used in many areas, such as engineering, ecology and economics,
computer models are subject to various uncertainties at the level of model
formulations, parameter values and input data. Naturally, it would be
advantageous to know the combined effect of these uncertainties on the model
results as well as whether the state of knowledge should be improved in order
to reduce the uncertainty of the results most effectively. The book supports
decision-makers, model developers and users in their argumentation for an
uncertainty analysis and assists them in the interpretation of the analysis
results.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9783319762968},
	doi = {10.1007/978-3-319-76297-5},
	pagetotal = {346},
	isbn = {978-3-319-76296-8},
	publisher = Springer,
	language = {english},
	subtitle = {A Practical Guide},
	date = {2018},
	title = {The Uncertainty Analysis of Model Results},
	author = {Hofer, Eduard}
}

@Book{holden_piene:abel_prize_2008-2012,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-3-642-39449-2
},
	file = {Holden _ Piene - 2014 - The Abel Prize 2008-2012.pdf},
	keywords = {Historia de las Matemáticas},
	abstract = {Covering the years 2008-2012, this book profiles the life and work of recent
winners of the Abel Prize:

* John G. Thompson and Jacques Tits, 2008
* Mikhail Gromov, 2009
* John T. Tate Jr., 2010
* John W. Milnor, 2011
* Endre Szemerédi, 2012.

The profiles feature autobiographical information as well as a description of
each mathematician's work. In addition, each profile contains a complete
bibliography, a curriculum vitae, as well as photos — old and new. As an added
feature, interviews with the Laureates are presented on an accompanying web
site (http://extras.springer.com/).

The book also presents a history of the Abel Prize written by the historian Kim
Helsvig, and includes a facsimile of a letter from Niels Henrik Abel, which is
transcribed, translated into English, and placed into historical perspective by
Christian Skau.

This book follows on The Abel Prize: 2003-2007, The First Five Years (Springer,
2010), which profiles the work of the first Abel Prize winners.
},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783642394485},
	doi = {10.1007/978-3-642-39449-2},
	pagetotal = {571},
	isbn = {9783642394485},
	publisher = Springer,
	language = {english},
	date = {2014},
	title = {The Abel Prize 2008-2012},
	editor = {Holden, Helge and Piene, Ragni}
}

@Book{holmes_jain:innovations_bayesian_networks,
	series = Springer_Computational_Intelligence,
	enlaces = {Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-3-540-85066-3},
	file = {Holmes _ Jain - 2008 - Innovations in Bayesian Networks.pdf},
	keywords = {Inteligencia artificial, Redes bayesianas},
	abstract = {Bayesian networks currently provide one of the most rapidly growing areas of research in computer
science and statistics. In compiling this volume we have brought together contributions from some
of the most prestigious researchers in this field. Each of the twelve chapters is self-contained.

Both theoreticians and application scientists/engineers in the broad area of artificial
intelligence will find this volume valuable. It also provides a useful sourcebook for Graduate
students since it shows the direction of current research.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783540850656},
	doi = {10.1007/978-3-540-85066-3},
	pagetotal = {322},
	isbn = {9783540850656},
	publisher = Springer,
	number = {156},
	language = {english},
	subtitle = {Theory and Applications},
	editor = {Holmes, Dawn E. and Jain, Lakhmi C.},
	date = {2008},
	title = {Innovations in Bayesian Networks}
}

@Article{hu_et_al:closer_look_gpgpu,
	doi = {10.1145/2873053},
	number = {4},
	volume = {48},
	xdata = {acm_computing_surveys},
	pagetotal = {20},
	file = {Hu et al - 2016 - A Closer Look at GPGPU.pdf},
	keywords = {Computación paralela, GPGPU},
	abstract = {The lack of detailed white box illustration leaves a gap in the field of GPGPU (General-Purpose
Computing on the Graphic Processing Unit), thus hindering users and researchers from exploring
hardware potential while improving application performance. This article bridges the gap by
demystifying the micro-architecture and operating mechanism of GPGPU. We propose a descriptive
model that addresses key issues of most concerns, including task organization, hardware structure,
scheduling mechanism, execution mechanism, and memory access. We also validate the effectiveness of
our model by interpreting the software/hardware cooperation of CUDA.},
	langidopts = {variant=british},
	langid = {english},
	language = {english},
	date = {2016},
	title = {A Closer Look at GPGPU},
	author = {Hu, Liang and Che, Xilong and Zheng, Si-Qing}
}

@Book{huth_ryan:logic_computer_science,
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.cambridge.org/us/academic/subjects/computer-science/programming-languages-and-applied-logic/logic-computer-science-modelling-and-reasoning-about-systems-2nd-edition},
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1604277
},
	abstract = {The second edition of this successful textbook continues to provide a clear introduction to formal
reasoning relevant to the needs of modern computer science and sufficiently exacting for practical
applications. Improvements have been made throughout with many new and expanded text sections. The
coverage of model-checking has been substantially updated and additional exercises are included.
Internet support includes worked solutions for teacher exercises and model solutions to some
student exercises.},
	author = {Huth, Michael and Ryan, Mark},
	date = {2004-08},
	edition = {2},
	hyphenation = {english},
	isbn = {9780521543101},
	keywords = {Lógica matemática},
	language = {english},
	pagetotal = {440},
	publisher = Cambridge,
	title = {Logic in Computer Science: Modelling and Reasoning about Systems}
}

@Book{inselberg:parallel_coordinates,
	enlaces = {Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-0-387-68628-8},
	file = {Inselberg - 2009 - Parallel Coordinates.pdf},
	keywords = {Geometría, Visualización de datos},
	abstract = {This book is about visualization, systematically incorporating the fantastic human pattern
recognition into the problem-solving process, and focusing on parallel coordinates. The barrier,
imposed by our three-dimensional habitation and perceptual experience, has been breached by this
innovative and versatile methodology. The accurate visualization of multidimensional problems and
multivariate data unlocks insights into the role of dimensionality.

Beginning with an introductory chapter on geometry, the mathematical foundations are intuitively
developed, interlaced with applications to data mining, information visualization, computer vision,
geometric modeling, collision avoidance for air traffic and process-control. Many results appear
for the first time. Multidimensional lines, planes, proximities, surfaces and their properties are
unambiguously recognized (i.e. convexity viewed in any dimension) enabling powerful construction
algorithms (for intersections, interior-points, linear-programming).

Key features of Parallel Coordinates:
* An easy-to-read self-contained chapter on data mining and information visualization
* Numerous exercises with solutions, from basic to advanced topics, course projects and research
  directions
* "Fast Track" markers throughout provide a quick grasp of essential material.
* Extensive bibliography, index, and a chapter containing a collection of recent results (i.e.
  visualizing large networks, complex-valued functions and more)

Parallel Coordinates requires only an elementary knowledge of linear algebra. It is well-suited for
self-study and as a textbook (or companion) for courses on information visualization, data mining,
mathematics, statistics, computer science, engineering, finance, management, manufacturing, in
scientific disciplines and even the arts.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/gp/book/9780387215075},
	doi = {10.1007/978-0-387-68628-8},
	pagetotal = {554},
	isbn = {9780387215075},
	publisher = Springer,
	subtitle = {Visual Multidimensional Geometry and Its Applications},
	language = {english},
	date = {2009},
	title = {Parallel Coordinates},
	author = {Inselberg, Alfred}
}

@Book{izenman:modern_multivariate_statistical_techniques,
	subtitle = {Regression, Classification, and Manifold Learning},
	enlaces = {Recurso electrónico (SpringerLink): http://www.us.debiblio.com/login?url=http://dx.doi.org/10.1007/978-0-387-78189-1
},
	file = {Izenman - 2008 - Modern Multivariate Statistical Techniques.pdf},
	keywords = {Aprendizaje automático, Estadística},
	abstract = {Remarkable advances in computation and data storage and the ready availability
of huge data sets have been the keys to the growth of the new disciplines of
data mining and machine learning, while the enormous success of the Human
Genome Project has opened up the field of bioinformatics.

These exciting developments, which led to the introduction of many innovative
statistical tools for high-dimensional data analysis, are described here in
detail. The author takes a broad perspective; for the first time in a book on
multivariate analysis, nonlinear methods are discussed in detail as well as
linear methods. Techniques covered range from traditional multivariate methods,
such as multiple regression, principal components, canonical variates, linear
discriminant analysis, factor analysis, clustering, multidimensional scaling,
and correspondence analysis, to the newer methods of density estimation,
projection pursuit, neural networks, multivariate reduced-rank regression,
nonlinear manifold learning, bagging, boosting, random forests, independent
component analysis, support vector machines, and classification and regression
trees. Another unique feature of this book is the discussion of database
management systems.

This book is appropriate for advanced undergraduate students, graduate
students, and researchers in statistics, computer science, artificial
intelligence, psychology, cognitive sciences, business, medicine,
bioinformatics, and engineering. Familiarity with multivariable calculus,
linear algebra, and probability and statistics is required. The book presents a
carefully-integrated mixture of theory and applications, and of classical and
modern multivariate statistical techniques, including Bayesian methods. There
are over 60 interesting data sets used as examples in the book, over 200
exercises, and many color illustrations and photographs.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780387781884},
	doi = {10.1007/978-0-387-78189-1},
	pagetotal = {733},
	isbn = {9780387781884},
	publisher = Springer,
	series = Springer_Text_Statistics,
	language = {english},
	date = {2008},
	title = {Modern Multivariate Statistical Techniques},
	author = {Izenman, Alan Julian}
}

@Article{jain:data_clustering_50_years_beyond_K-means,
	abstract = {Organizing data into sensible groupings is one of the most fundamental modes of
understanding and learning. As an example, a common scheme of scientific
classification puts organisms into a system of ranked taxa: domain, kingdom,
phylum, class, etc. Cluster analysis is the formal study of methods and
algorithms for grouping, or clustering, objects according to measured or
perceived intrinsic characteristics or similarity. Cluster analysis does not
use category labels that tag objects with prior identifiers, i.e., class
labels. The absence of category information distinguishes data clustering
(unsupervised learning) from classification or discriminant analysis
(supervised learning). The aim of clustering is to find structure in data and
is therefore exploratory in nature. Clustering has a long and rich history in a
variety of scientific fields. One of the most popular and simple clustering
algorithms, K-means, was first published in 1955. In spite of the fact that
K-means was proposed over 50 years ago and thousands of clustering algorithms
have been published since then, K-means is still widely used. This speaks to
the difficulty in designing a general purpose clustering algorithm and the
ill-posed problem of clustering. We provide a brief overview of clustering,
summarize well known clustering methods, discuss the major challenges and key
issues in designing clustering algorithms, and point out some of the emerging
and useful research directions, including semi-supervised clustering, ensemble
clustering, simultaneous feature selection during data clustering, and large
scale data clustering.},
	file = {Jain - 2010 - Data clustering: 50 years beyond K-means.pdf},
	keywords = {Análisis de grupos, Aprendizaje automático},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1016/j.patrec.2009.09.011},
	pages = {651-666},
	number = {8},
	volume = {31},
	language = {english},
	xdata = {pattern_recognition_letters},
	date = {2010},
	title = {Data clustering: 50 years beyond K-means},
	author = {Jain, Anil K.}
}

@Book{japkowicz_shah:evaluating_learning_algorithms,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2331551},
	keywords = {Aprendizaje automático, Inteligencia artificial},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.mohakshah.com/books/ELA},
	pagetotal = {424},
	isbn = {9780521196000},
	publisher = Cambridge,
	language = {english},
	date = {2011},
	title = {Evaluating Learning Algorithms},
	author = {Japkowicz, Nathalie and Shah, Mohak}
}

@Book{jensen_nielsen:bayesian_networks_decision_graphs,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2015603
Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-0-387-68282-2},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/978-0-387-68281-5},
	doi = {10.1007/978-0-387-68282-2},
	language = {english},
	edition = {2},
	title = {Bayesian Networks and Decision Graphs},
	isbn = {9780387682815},
	series = {Information Science and Statistics},
	abstract = {Probabilistic graphical models and decision graphs are powerful modeling tools for reasoning and
decision making under uncertainty. As modeling languages they allow a natural specification of
problem domains with inherent uncertainty, and from a computational perspective they support
efficient algorithms for automatic construction and query answering. This includes belief updating,
finding the most probable explanation for the observed evidence, detecting conflicts in the
evidence entered into the network, determining optimal strategies, analyzing for relevance, and
performing sensitivity analysis.

The book introduces probabilistic graphical models and decision graphs, including Bayesian networks
and influence diagrams. The reader is introduced to the two types of frameworks through examples
and exercises, which also instruct the reader on how to build these models.

The book is a new edition of _Bayesian Networks and Decision Graphs_ by _Finn V. Jensen_. The new
edition is structured into two parts. The first part focuses on probabilistic graphical models.
Compared with the previous book, the new edition also includes a thorough description of recent
extensions to the Bayesian network modeling language, advances in exact and approximate belief
updating algorithms, and methods for learning both the structure and the parameters of a Bayesian
network. The second part deals with decision graphs, and in addition to the frameworks described in
the previous edition, it also introduces Markov decision processes and partially ordered decision
problems. The authors also provide a well-founded practical introduction to Bayesian networks,
object-oriented Bayesian networks, decision trees, influence diagrams (and variants hereof), and
Markov decision processes.},
	pagetotal = {448},
	publisher = Springer,
	author = {Jensen, Finn Verner and Nielsen, Thomas Dyhre},
	date = {2007},
	keywords = {Modelos gráficos probabilísticos, Redes bayesianas},
	file = {Jensen _ Nielsen - 2007 - Bayesian Networks and Decision Graphs.pdf}
}

@XData{journal_cloud_computing,
	journaltitle = {Journal of Cloud Computing},
	journalsubtitle = {Advances, Systems and Applications},
	issn = {2192-113X},
	publisher = Springer
}

@XData{journal_computer_system_sciences,
	journaltitle = {Journal of Computer and System Sciences},
	issn = {0022-0000},
	publisher = Elsevier
}

@XData{journal_software,
	journaltitle = {Journal of Software},
	issn = {1796-217X}
}

@Article{juan_et_al:review_simheuristics,
	file = {Juan et al - 2015 - A review of simheuristics: Extending metaheuristics to deal with stochastic combinatorial optimization problems.pdf},
	keywords = {Metaheurísticas, Problemas de optimización},
	abstract = {Many combinatorial optimization problems (COPs) encountered in real-world
logistics, transportation, production, healthcare, financial,
telecommunication, and computing applications are NP-hard in nature. These
real-life COPs are frequently characterized by their large-scale sizes and the
need for obtaining high-quality solutions in short computing times, thus
requiring the use of metaheuristic algorithms. Metaheuristics benefit from
different random-search and parallelization paradigms, but they frequently
assume that the problem inputs, the underlying objective function, and the set
of optimization constraints are deterministic. However, uncertainty is all
around us, which often makes deterministic models oversimplified versions of
real-life systems. After completing an extensive review of related work, this
paper describes a general methodology that allows for extending metaheuristics
through simulation to solve stochastic COPs. ‘Simheuristics’ allow modelers for
dealing with real-life uncertainty in a natural way by integrating simulation
(in any of its variants) into a metaheuristic-driven framework. These
optimization-driven algorithms rely on the fact that efficient metaheuristics
already exist for the deterministic version of the corresponding COP.
Simheuristics also facilitate the introduction of risk and/or reliability
analysis criteria during the assessment of alternative high-quality solutions
to stochastic COPs. Several examples of applications in different fields
illustrate the potential of the proposed methodology.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1016/j.orp.2015.03.001},
	pages = {62-72},
	volume = {2},
	language = {english},
	date = {2015},
	xdata = {operations_research_perspectives},
	title = {A review of simheuristics: Extending metaheuristics to deal with stochastic combinatorial optimization problems},
	author = {Juan, Ángel A. and Faulin, Javier and Grasman, Scott E. and Rabe, Markus and Figueira, Gonçalo}
}

@book{karkera:building_probabilistic_graphical_models_python,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2612388
Recurso electrónico (E-Libro): http://0-site.ebrary.com.fama.us.es/lib/unisev/Doc?id=10887716},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.packtpub.com/big-data-and-business-intelligence/building-probabilistic-graphical-models-python},
	language = {english},
	title = {Building Probabilistic Graphical Models with Python},
	isbn = {9781783289004},
	abstract = {With the increasing prominence in machine learning and data science applications, probabilistic
graphical models are a new tool that machine learning users can use to discover and analyze
structures in complex problems. The variety of tools and algorithms under the PGM framework extend
to many domains such as natural language processing, speech processing, image processing, and
disease diagnosis.

You've probably heard of graphical models before, and you're keen to try out new landscapes in the
machine learning area. This book gives you enough background information to get started on
graphical models, while keeping the math to a minimum.
},
	pagetotal = {172},
	publisher = Packt,
	author = {Karkera, Kiran R.},
	date = {2014},
	keywords = {Inteligencia artificial, Lenguaje de programación Python, Redes bayesianas}
}

@Book{kjærulff_madsen:bayesian_networks_influence_diagrams,
	number = {22},
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-0-387-74101-7},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/978-1-4614-5103-7},
	doi = {10.1007/978-1-4614-5104-4},
	language = {english},
	edition = {2},
	title = {Bayesian Networks and Influence Diagrams: A Guide to Construction and Analysis},
	isbn = {9781461451037},
	series = {Information Science and Statistics},
	abstract = {_Bayesian Networks and Influence Diagrams: A Guide to Construction and Analysis, Second Edition_,
provides a comprehensive guide for practitioners who wish to understand, construct, and analyze
intelligent systems for decision support based on probabilistic networks. This new edition contains
six new sections, in addition to fully-updated examples, tables, figures, and a revised appendix.
Intended primarily for practitioners, this book does not require sophisticated mathematical skills
or deep understanding of the underlying theory and methods nor does it discuss alternative
technologies for reasoning under uncertainty. The theory and methods presented are illustrated
through more than 140 examples, and exercises are included for the reader to check his or her level
of understanding. The techniques and methods presented on model construction and verification,
modeling techniques and tricks, learning models from data, and analyses of models have all been
developed and refined based on numerous courses the authors have held for practitioners worldwide.},
	pagetotal = {382},
	publisher = Springer,
	author = {Kjærulff, Uffe B. and Madsen, Anders L.},
	date = {2013},
	keywords = {Modelos gráficos probabilísticos, Redes bayesianas},
	file = {Kjærulff _ Madsen - 2013 - Bayesian Networks and Influence Diagrams.pdf; Kjærulff _ Madsen - 2013 - Bayesian Networks and Influence Diagrams - Errata.pdf}
}

@Book{kneusel:numbers_computers,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2705265},
	keywords = {Matemática computacional},
	abstract = {This is a book about numbers and how those numbers are represented in and operated on by computers.
It is crucial that developers understand this area because the numerical operations allowed by
computers, and the limitations of those operations, especially in the area of floating point math,
affect virtually everything people try to do with computers. This book aims to fill this gap by
exploring, in sufficient but not overwhelming detail, just what it is that computers do with
numbers.

Divided into two parts, the first deals with standard representations of integers and floating
point numbers, while the second details several other number representations. Each chapter ends
with exercises to review the key points. Topics covered include interval arithmetic, fixed-point
numbers, floating point numbers, big integers and rational arithmetic.

This book is for anyone who develops software including software engineerings, scientists, computer
science students, engineering students and anyone who programs for fun.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/978-3-319-17259-0},
	doi = {10.1007/978-3-319-17260-6},
	pagetotal = {231},
	isbn = {9783319172590},
	publisher = Springer,
	language = {english},
	date = {2015},
	title = {Numbers and Computers},
	author = {Kneusel, Ronald T.}
}

@XData{knowledge-based_systems,
	journaltitle = {Knowledge-Based Systems},
	issn = {0950-7051},
	publisher = Elsevier
}

@XData{knowledge_engineering_review,
	journaltitle = {The Knowledge Engineering Review},
	issn = {1469-8005},
	publisher = Cambridge
}

@Book{koller_friedman:probabilistic_graphical_models,
	series = Adaptive_Computation,
	publisher = MIT_Press,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2200769},
	file = {Koller _ Friedman - 2009 - Probabilistic Graphical Models - Principles and Techniques.pdf},
	keywords = {Inteligencia artificial, Redes bayesianas},
	abstract = {Most tasks require a person or an automated system to reason—to reach conclusions based on
available information. The framework of probabilistic graphical models, presented in this book,
provides a general approach for this task. The approach is model-based, allowing interpretable
models to be constructed and then manipulated by reasoning algorithms. These models can also be
learned automatically from data, allowing the approach to be used in cases where manually
constructing a model is difficult or even impossible. Because uncertainty is an inescapable aspect
of most real-world applications, the book focuses on probabilistic models, which make the
uncertainty explicit and provide models that are more faithful to reality.

_Probabilistic Graphical Models_ discusses a variety of models, spanning Bayesian networks,
undirected Markov networks, discrete and continuous models, and extensions to deal with dynamical
systems and relational data. For each class of models, the text describes the three fundamental
cornerstones: representation, inference, and learning, presenting both basic concepts and advanced
techniques. Finally, the book considers the use of the proposed framework for causal reasoning and
decision making under uncertainty. The main text in each chapter provides the detailed technical
development of the key ideas. Most chapters also include boxes with additional material: skill
boxes, which describe techniques; case study boxes, which discuss empirical cases related to the
approach described in the text, including applications in computer vision, robotics, natural
language understanding, and computational biology; and concept boxes, which present significant
concepts drawn from the material in the chapter. Instructors (and readers) can group chapters in
various combinations, from core topics to more technically advanced material, to suit their
particular needs.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://mitpress.mit.edu/books/probabilistic-graphical-models},
	pagetotal = {1280},
	isbn = {9780262013192},
	language = {english},
	date = {2009},
	title = {Probabilistic Graphical Models},
	author = {Koller, Daphne and Friedman, Nir}
}

@Article{konak_et_al:multiobjective_optimization_genetic_algorithms,
	xdata = {reliability_engineering_system_safety},
	file = {Konak et al - 2006 - Multi-objective optimization using genetic algorithms: A tutorial.pdf},
	keywords = {Algoritmos genéticos, Metaheurísticas},
	abstract = {Multi-objective formulations are realistic models for many complex engineering optimization
problems. In many real-life problems, objectives under consideration conflict with each other, and
optimizing a particular solution with respect to a single objective can result in unacceptable
results with respect to the other objectives. A reasonable solution to a multi-objective problem is
to investigate a set of solutions, each of which satisfies the objectives at an acceptable level
without being dominated by any other solution. In this paper, an overview and tutorial is presented
describing genetic algorithms (GA) developed specifically for problems with multiple objectives.
They differ primarily from traditional GA by using specialized fitness functions and introducing
methods to promote solution diversity.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1016/j.ress.2005.11.018},
	pages = {992-1007},
	number = {9},
	volume = {91},
	language = {english},
	date = {2006},
	title = {Multi-objective optimization using genetic algorithms: A tutorial},
	author = {Konak, Abdullah and Coit, David W. and Smith, Alice E.}
}

@book{korb_nicholson:bayesian_artificial_intelligence,
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.csse.monash.edu.au/bai/book},
	language = {english},
	edition = {2},
	title = {Bayesian Artificial Intelligence},
	isbn = {9781439815915},
	series = CRC_Computer_Science,
	abstract = {Updated and expanded, **Bayesian Artificial Intelligence, Second Edition** provides a practical and
accessible introduction to the main concepts, foundation, and applications of Bayesian networks. It
focuses on both the causal discovery of networks and Bayesian inference procedures. Adopting a
causal interpretation of Bayesian networks, the authors discuss the use of Bayesian networks for
causal modeling. They also draw on their own applied research to illustrate various applications of
the technology.

**New to the Second Edition**

* New chapter on Bayesian network classifiers
* New section on object-oriented Bayesian networks
* New section that addresses foundational problems with causal discovery and Markov blanket
  discovery
* New section that covers methods of evaluating causal discovery programs
* Discussions of many common modeling errors
* New applications and case studies
* More coverage on the uses of causal interventions to understand and reason with causal Bayesian
  networks

Illustrated with real case studies, the second edition of this bestseller continues to cover the
groundwork of Bayesian networks. It presents the elements of Bayesian network technology, automated
causal discovery, and learning probabilities from data and shows how to employ these technologies
to develop probabilistic expert systems.},
	pagetotal = {491},
	publisher = CRC,
	author = {Korb, Kevin B. and Nicholson, Ann E.},
	date = {2010},
	keywords = {Inteligencia artificial, Redes bayesianas}
}

@Book{koubaa_et_al:robot_path_planning_cooperation,
	enlaces = {Recurso electrónico (SpringerLink): http://www.us.debiblio.com/login?url=https://doi.org/10.1007/978-3-319-77042-0
},
	file = {Koubaa et al -2018 - Robot Path Planning and Cooperation.pdf},
	keywords = {Planificación automática, Robótica},
	abstract = {This book presents extensive research on two main problems in robotics: the
path planning problem and the multi-robot task allocation problem. It is the
first book to provide a comprehensive solution for using these techniques in
large-scale environments containing randomly scattered obstacles. The research
conducted resulted in tangible results both in theory and in practice. For path
planning, new algorithms for large-scale problems are devised and implemented
and integrated into the Robot Operating System (ROS). The book also discusses
the parallelism advantage of cloud computing techniques to solve the path
planning problem, and, for multi-robot task allocation, it addresses the task
assignment problem and the multiple traveling salesman problem for mobile
robots applications. In addition, four new algorithms have been devised to
investigate the cooperation issues with extensive simulations and comparative
performance evaluation. The algorithms are implemented and simulated in MATLAB
and Webots.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9783319770406},
	doi = {10.1007/978-3-319-77042-0},
	pagetotal = {190},
	isbn = {9783319770406},
	publisher = Springer,
	number = {772},
	series = Springer_Computational_Intelligence,
	language = {english},
	subtitle = {Foundations, Algorithms and Experimentations},
	date = {2018},
	title = {Robot Path Planning and Cooperation},
	author = {Koubaa, Anis and Bennaceur, Hachemi and Chaari, Imen and Trigui, Sahar and Ammar, Adel and Sriti, Mohamed-Foued and Alajlan, Maram and Cheikhrouhou, Omar and Javed, Yasir}
}

@Book{kramer:genetic_algorithm_essentials,
	file = {Kramer - 2017 Genetic Algorithm Essentials.pdf},
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2748658},
	keywords = {Algoritmos genéticos, Inteligencia artificial},
	abstract = {This book introduces readers to genetic algorithms (GAs) with an emphasis on
making the concepts, algorithms, and applications discussed as easy to
understand as possible. Further, it avoids a great deal of formalisms and thus
opens the subject to a broader audience in comparison to manuscripts overloaded
by notations and equations. The book is divided into three parts, the first of
which provides an introduction to GAs, starting with basic concepts like
evolutionary operators and continuing with an overview of strategies for tuning
and controlling parameters. In turn, the second part focuses on solution space
variants like multimodal, constrained, and multi-objective solution spaces.
Lastly, the third part briefly introduces theoretical tools for GAs, the
intersections and hybridizations with machine learning, and highlights selected
promising applications.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783319521558},
	doi = {10.1007/978-3-319-52156-5},
	pagetotal = {92},
	isbn = {9783319521558},
	publisher = Springer,
	number = {679},
	series = Springer_Computational_Intelligence,
	language = {english},
	date = {2017},
	title = {Genetic Algorithm Essentials},
	author = {Kramer, Oliver}
}

@Article{krentel:complexity_optimization_problems,
	file = {Krentel - 1988 - The complexity of optimization problems.pdf},
	keywords = {Complejidad computacional, Problemas de optimización},
	abstract = {We consider **NP**-complete optimization problems at the level of computing
their optimal value, and define a class of functions called **OptP** to capture
this level of structure. We show that TRAVELING SALESPERSON and KNAPSACK are
complete for **OptP**, and that CLIQUE and COLORING are complete for a subclass
of **OptP**. These results show a deeper level of structure in these problems
than was previously known. We also show that **OptP** is closely related to
**FP**^{SAT}, the class of functions computable in polynomial time with an
oracle for **NP**. This allows us to quantify exactly “how much”
**NP**-completeness is in these problems. In particular, in this measure, we
show that TRAVELING SALESPERSON is strictly harder than CLIQUE and that CLIQUE
is strictly harder than BIN PACKING. A further result is that an
**OptP**-completeness result implies **NP**-, D^{p}-, and
Δ_{2}^{P}-completeness results, thus tying these four classes closely together.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1016/0022-0000(88)90039-6},
	pages = {490-509},
	number = {3},
	volume = {36},
	language = {english},
	date = {1988},
	xdata = {journal_computer_system_sciences},
	title = {The complexity of optimization problems},
	author = {Krentel, Mark W.}
}

@book{kroese_et_al:handbook_monte_carlo_methods,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2197566},
	langidopts = {variant=british},
	langid = {english},
	url = {https://people.smp.uq.edu.au/DirkKroese/montecarlohandbook/},
	language = {english},
	title = {Handbook of Monte Carlo Methods},
	isbn = {9780470177938},
	series = Wiley_Probability_Statistics,
	abstract = {A comprehensive overview of Monte Carlo simulation that explores the latest topics, techniques, and
real-world applications

More and more of today’s numerical problems found in engineering and finance are solved through
Monte Carlo methods. The heightened popularity of these methods and their continuing development
makes it important for researchers to have a comprehensive understanding of the Monte Carlo
approach. Handbook of Monte Carlo Methods provides the theory, algorithms, and applications that
helps provide a thorough understanding of the emerging dynamics of this rapidly-growing field.

The authors begin with a discussion of fundamentals such as how to generate random numbers on a
computer. Subsequent chapters discuss key Monte Carlo topics and methods, including:

* Random variable and stochastic process generation
* Markov chain Monte Carlo, featuring key algorithms such as the Metropolis-Hastings method, the
  Gibbs sampler, and hit-and-run
* Discrete-event simulation
* Techniques for the statistical analysis of simulation data including the delta method,
  steady-state estimation, and kernel density estimation
* Variance reduction, including importance sampling, latin hypercube sampling, and conditional
  Monte Carlo
* Estimation of derivatives and sensitivity analysis
* Advanced topics including cross-entropy, rare events, kernel density estimation, quasi Monte
  Carlo, particle systems, and randomized optimization

The presented theoretical concepts are illustrated with worked examples that use MATLAB, a related
Web site houses the MATLAB code, allowing readers to work hands-on with the material and also
features the author's own lecture notes on Monte Carlo methods. Detailed appendices provide
background material on probability theory, stochastic processes, and mathematical statistics as
well as the key optimization concepts and techniques that are relevant to Monte Carlo simulation.

Handbook of Monte Carlo Methods is an excellent reference for applied statisticians and
practitioners working in the fields of engineering and finance who use or would like to learn how
to use Monte Carlo in their research. It is also a suitable supplement for courses on Monte Carlo
methods and computational statistics at the upper-undergraduate and graduate levels.},
	pagetotal = {772},
	publisher = Wiley,
	author = {Kroese, Dirk P. and Taimre, Thomas and Botev, Zdravko I.},
	date = {2011},
	keywords = {Estadística computacional, Métodos de Monte Carlo}
}

@Book{kubat:introduction_machine_learning,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2714855},
	keywords = {Aprendizaje automático},
	abstract = {This book presents basic ideas of machine learning in a way that is easy to understand, by
providing hands-on practical advice, using simple examples, and motivating students with
discussions of interesting applications. The main topics include Bayesian classifiers,
nearest-neighbor classifiers, linear and polynomial classifiers, decision trees, neural networks,
and support vector machines. Later chapters show how to combine these simple tools by way of
“boosting,” how to exploit them in more complicated domains, and how to deal with diverse advanced
practical issues. One chapter is dedicated to the popular genetic algorithms.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/gp/book/9783319200095},
	doi = {10.1007/978-3-319-20010-1},
	pagetotal = {291},
	isbn = {9783319200095},
	publisher = Springer,
	language = {english},
	date = {2015},
	title = {An Introduction to Machine Learning},
	author = {Kubat, Miroslav}
}

@Book{kuhn_johnson:applied_predictive_modeling,
	abstract = {_Applied Predictive Modeling_ covers the overall predictive modeling process, beginning with the
crucial steps of data preprocessing, data splitting and foundations of model tuning. The text then
provides intuitive explanations of numerous common and modern regression and classification
techniques, always with an emphasis on illustrating and solving real data problems. Addressing
practical concerns extends beyond model fitting to topics such as handling class imbalance,
selecting predictors, and pinpointing causes of poor model performance—all of which are problems
that occur frequently in practice.
 
The text illustrates all parts of the modeling process through many hands-on, real-life examples.
And every chapter contains extensive R code for each step of the process. The data sets and
corresponding code are available in the book’s companion AppliedPredictiveModeling R package, which
is freely available on the CRAN archive.
 
This multi-purpose text can be used as an introduction to predictive models and the overall
modeling process, a practitioner’s reference handbook, or as a text for advanced undergraduate or
graduate level predictive modeling courses. To that end, each chapter contains problem sets to help
solidify the covered concepts and uses data available in the book’s R package.
 
Readers and students interested in implementing the methods should have some basic knowledge of R.
And a handful of the more advanced topics require some mathematical knowledge.},
	file = {Kuhn _ Johnson - 2013 - Applied Predictive Modeling.pdf},
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-1-4614-6849-3},
	keywords = {Aprendizaje automático, Lenguaje de programación R},
	langidopts = {variant=british},
	langid = {english},
	url = {http://appliedpredictivemodeling.com/},
	doi = {10.1007/978-1-4614-6849-3},
	pagetotal = {600},
	isbn = {9781461468486},
	publisher = Springer,
	language = {english},
	date = {2013},
	title = {Applied Predictive Modeling},
	author = {Kuhn, Max and Johnson, Kjell}
}

@book{lemieux:monte_carlo_quasi_monte_carlo_sampling,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2094239
Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-0-387-78165-5},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780387781648},
	doi = {10.1007/978-0-387-78165-5},
	language = {english},
	title = {Monte Carlo and Quasi-Monte Carlo Sampling},
	isbn = {9780387781648},
	series = Springer_Statistics,
	abstract = {Quasi–Monte Carlo methods have become an increasingly popular alternative to Monte Carlo methods
over the last two decades. Their successful implementation on practical problems, especially in
finance, has motivated the development of several new research areas within this field to which
practitioners and researchers from various disciplines currently contribute.

This book presents essential tools for using quasi–Monte Carlo sampling in practice. The first part
of the book focuses on issues related to Monte Carlo methods—uniform and non-uniform random number
generation, variance reduction techniques—but the material is presented to prepare the readers for
the next step, which is to replace the random sampling inherent to Monte Carlo by quasi–random
sampling. The second part of the book deals with this next step. Several aspects of quasi-Monte
Carlo methods are covered, including constructions, randomizations, the use of {ANOVA}
decompositions, and the concept of effective dimension. The third part of the book is devoted to
applications in finance and more advanced statistical tools like Markov chain Monte Carlo and
sequential Monte Carlo, with a discussion of their quasi–Monte Carlo counterpart.

The prerequisites for reading this book are a basic knowledge of statistics and enough mathematical
maturity to follow through the various techniques used throughout the book. This text is aimed at
graduate students in statistics, management science, operations research, engineering, and applied
mathematics. It should also be useful to practitioners who want to learn more about Monte Carlo and
quasi–Monte Carlo methods and researchers interested in an up-to-date guide to these methods.},
	pagetotal = {373},
	publisher = Springer,
	author = {Lemieux, Christiane},
	date = {2009},
	keywords = {Estadística computacional, Métodos de Monte Carlo},
	file = {Lemieux - 2009 - Monte Carlo and Quasi-Monte Carlo Sampling.pdf}
}

@Article{li_et_al:many_objective_evolutionary_algorithms,
	xdata = {acm_computing_surveys},
	file = {Li et al - 2015 - Many-Objective Evolutionary Algorithms: A Survey.pdf; Li et al - 2015 - Many-Objective Evolutionary Algorithms: A Survey - Appendix.pdf},
	keywords = {Algoritmos evolutivos},
	abstract = {Multiobjective evolutionary algorithms (MOEAs) have been widely used in real-world applications.
However, most MOEAs based on Pareto-dominance handle many-objective problems (MaOPs) poorly due to
a high proportion of incomparable and thus mutually nondominated solutions. Recently, a number of
many-objective evolutionary algorithms (MaOEAs) have been proposed to deal with this scalability
issue. In this article, a survey of MaOEAs is reported. According to the key ideas used, MaOEAs are
categorized into seven classes: relaxed dominance based, diversity-based, aggregation-based,
indicator-based, reference set based, preference-based, and dimensionality reduction approaches.
Several future research directions in this field are also discussed.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1145/2792984},
	pagetotal = {35},
	number = {1},
	volume = {48},
	language = {english},
	date = {2015},
	title = {Many-Objective Evolutionary Algorithms: A Survey},
	author = {Li, Bingdong and Li, Jinlong and Tang, Ke and Yao, Xin}
}

@Article{liang:survey_heuristics_domain_independent_planning,
	xdata = {journal_software},
	file = {Liang - 2012 - A Survey of Heuristics for Domain-Independent Planning.pdf},
	keywords = {Inteligencia artificial, Planificación automática},
	abstract = {Increasing interest has been devoted to Planning as Heuristic Search over the years. Intense
research has focused on deriving accurate heuristics in polynomial computational time for
domain-independent planning. This paper reports on an extensive survey and analysis of research
work related to heuristic derivation techniques for state space search planning, as well as other
planning paradigms. Survey results reveal that heuristic techniques have been extensively applied
in many efficient planners and result in impressive performances. We extend the survey analysis to
suggest promising avenues for future research in heuristic derivation and heuristic search
techniques.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.4304/jsw.7.9.2099-2106},
	pages = {2099-2106},
	number = {9},
	volume = {7},
	language = {english},
	date = {2012},
	title = {A Survey of Heuristics for Domain-Independent Planning},
	author = {Liang, Ruishi}
}

@Article{loh:classification_regression_trees,
	xdata = {wires_data_mining_knowledge_discovery},
	file = {Loh - 2011 - Classification and regression trees.pdf},
	keywords = {Aprendizaje automático, Inteligencia artificial},
	abstract = {Classification and regression trees are machine-learning methods for constructing prediction models
from data. The models are obtained by recursively partitioning the data space and fitting a simple
prediction model within each partition. As a result, the partitioning can be represented
graphically as a decision tree. Classification trees are designed for dependent variables that take
a finite number of unordered values, with prediction error measured in terms of misclassification
cost. Regression trees are for dependent variables that take continuous or ordered discrete values,
with prediction error typically measured by the squared difference between the observed and
predicted values. This article gives an introduction to the subject by reviewing some widely
available algorithms and comparing their capabilities, strengths, and weakness in two examples.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1002/widm.8},
	pages = {14-23},
	number = {1},
	volume = {1},
	language = {english},
	date = {2011},
	title = {Classification and regression trees},
	author = {Loh, Wei-Yin}
}

@Book{lovász_plummer:matching_theory,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2091091
Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1013909
Recurso electrónico (ScienceDirect): http://www.us.debiblio.com/login?url=http://www.sciencedirect.com/science/publication?issn=03040208&volume=121
},
	file = {Lovász _ Plummer - 1986 -Matching_Theory.pdf},
	keywords = {Matemática discreta, Teoría de grafos},
	abstract = {This study of matching theory deals with bipartite matching, network flows, and
presents fundamental results for the non-bipartite case. It goes on to study
elementary bipartite graphs and elementary graphs in general. Further discussed
are 2-matchings, general matching problems as linear programs, the Edmonds
Matching Algorithm (and other algorithmic approaches), f-factors and vertex
packing.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.elsevier.com/books/matching-theory/plummer/978-0-444-87916-5},
	pagetotal = {544},
	isbn = {9780444879165},
	publisher = Elsevier,
	number = {29},
	series = Elsevier_Annals_Discrete_Mathematics,
	language = {english},
	date = {1986},
	title = {Matching Theory},
	author = {Lovász, László and Plummer, Michael David}
}

@XData{machine_learning,
	journaltitle = {Machine Learning},
	issn = {0885-6125},
	publisher = Springer
}

@Thesis{macias-ramos:developing_efficient_simulators_cell_machines,
	type = {phdthesis},
	file = {Macías-Ramos - 2015 - Developing efficient simulators for cell machines.pdf},
	keywords = {Computación bioinspirada, Computación con membranas},
	langidopts = {variant=british},
	langid = {english},
	url = {http://hdl.handle.net/11441/36828},
	pagetotal = {305},
	language = {english},
	date = {2015},
	institution = {Universidad de Sevilla},
	title = {Developing efficient simulators for cell machines},
	author = {Macías Ramos, Luis Felipe}
}

@Article{madden:classification_performance_TAN_Bayesian_networks,
	file = {Madden - 2009 - On the classification performance of TAN and general Bayesian networks.pdf},
	keywords = {Aprendizaje automático, Redes bayesianas},
	abstract = {Over a decade ago, Friedman et al. introduced the Tree Augmented Naïve Bayes
(TAN) classifier, with experiments indicating that it significantly
outperformed Naïve Bayes (NB) in terms of classification accuracy, whereas
general Bayesian network (GBN) classifiers performed no better than NB. This
paper challenges those claims, using a careful experimental analysis to show
that GBN classifiers significantly outperform NB on datasets analyzed, and are
comparable to TAN performance. It is found that the poor performance reported
by Friedman et al. are not attributable to the GBN per se, but rather to their
use of simple empirical frequencies to estimate GBN parameters, whereas basic
parameter smoothing (used in their TAN analyses but not their GBN analyses)
improves GBN performance significantly. It is concluded that, while GBN
classifiers may have some limitations, they deserve greater attention,
particularly in domains where insight into classification decisions, as well as
good accuracy, is required.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1016/j.knosys.2008.10.006},
	pages = {489-495},
	number = {7},
	volume = {22},
	language = {english},
	date = {2009},
	xdata = {knowledge-based_systems},
	title = {On the classification performance of TAN and general Bayesian networks},
	author = {Madden, Michael G.}
}

@Book{manzano_huertas:logica_principiantes,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2519398},
	keywords = {Lógica matemática},
	langid = {spanish},
	pagetotal = {422},
	isbn = {9788420645704},
	publisher = Alianza,
	language = {spanish},
	date = {2011},
	title = {Lógica para principiantes},
	author = {Manzano, María and Huertas, Antonia}
}

@Book{matloff:art_r_programming,
	enlaces = {Recurso electrónico (E-Libro): http://0-site.ebrary.com.fama.us.es/lib/unisev/Doc?id=105135501},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.nostarch.com/artofr.htm},
	language = {english},
	subtitle = {A Tour of Statistical Software Design},
	title = {The Art of R Programming},
	isbn = {9781593273842},
	abstract = {R is the world's most popular language for developing statistical software: Archaeologists use it
to track the spread of ancient civilizations, drug companies use it to discover which medications
are safe and effective, and actuaries use it to assess financial risks and keep economies running
smoothly.

The Art of R Programming takes you on a guided tour of software development with R, from basic
types and data structures to advanced topics like closures, recursion, and anonymous functions. No
statistical knowledge is required, and your programming skills can range from hobbyist to pro.

Along the way, you'll learn about functional and object-oriented programming, running mathematical
simulations, and rearranging complex data into simpler, more useful formats.},
	pagetotal = {400},
	publisher = No_Starch,
	author = {Matloff, Norman},
	date = {2011},
	keywords = {Lenguaje de programación R}
}

@Book{mohanty_et_al:big_data,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2714880},
	keywords = {Macrodatos},
	abstract = {This book is a collection of chapters written by experts on various aspects of big data. The book
aims to explain what big data is and how it is stored and used. The book starts from the
fundamentals and builds up from there. It is intended to serve as a review of the
state-of-the-practice in the field of big data handling. The traditional framework of relational
databases can no longer provide appropriate solutions for handling big data and making it available
and useful to users scattered around the globe. The study of big data covers a wide range of issues
including management of heterogeneous data, big data frameworks, change management, finding
patterns in data usage and evolution, data as a service, service-generated data, service
management, privacy and security. All of these aspects are touched upon in this book. It also
discusses big data applications in different domains. The book will prove useful to students,
researchers, and practicing database and networking engineers.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/gp/book/9788132224938},
	doi = {10.1007/978-81-322-2494-5},
	pagetotal = {184},
	isbn = {9788132224938},
	publisher = Springer,
	number = {11},
	series = Springer_Studies_Big_Data,
	language = {english},
	date = {2015},
	subtitle = {A Primer},
	title = {Big Data},
	editor = {Mohanty, Hrushikesha and Bhuyan, Prachet and Chenthati, Deepak}
}

@Book{moore_mertens:nature_computation,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2715384},
	publisher = Oxford,
	keywords = {Complejidad computacional},
	abstract = {Computational complexity is one of the most beautiful fields of modern mathematics, and it is
increasingly relevant to other sciences ranging from physics to biology. But this beauty is often
buried underneath layers of unnecessary formalism, and exciting recent results like interactive
proofs, phase transitions, and quantum computing are usually considered too advanced for the
typical student. This book bridges these gaps by explaining the deep ideas of theoretical computer
science in a clear and enjoyable fashion, making them accessible to non-computer scientists and to
computer scientists who finally want to appreciate their field from a new point of view. The
authors start with a lucid and playful explanation of the P vs. NP problem, explaining why it is so
fundamental, and so hard to resolve. They then lead the reader through the complexity of mazes and
games; optimization in theory and practice; randomized algorithms, interactive proofs, and
pseudorandomness; Markov chains and phase transitions; and the outer reaches of quantum computing.
At every turn, they use a minimum of formalism, providing explanations that are both deep and
accessible. The book is intended for graduate and undergraduate students, scientists from other
areas who have long wanted to understand this subject, and experts who want to fall in love with
this field all over again.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://global.oup.com/academic/product/the-nature-of-computation-9780199233212},
	pagetotal = {1004},
	isbn = {9780199233212},
	language = {english},
	date = {2011},
	title = {The Nature of Computation},
	author = {Moore, Cristopher and Mertens, Stephan}
}

@Book{muller_et_al:handbook_floating_point_arithmetic,
	enlaces = {Recurso electrónico (SpringerLink): http://www.us.debiblio.com/login?url=http://dx.doi.org/10.1007/978-3-319-76526-6
},
	file = {Muller et al - 2018 - Handbook of Floating-Point Arithmetic.pdf},
	keywords = {Ciencias de la computación},
	abstract = {This handbook is a definitive guide to the effective use of modern
floating-point arithmetic, which has considerably evolved, from the frequently
inconsistent floating-point number systems of early computing to the recent
IEEE 754-2008 standard. Most of computational mathematics depends on
floating-point numbers, and understanding their various implementations will
allow readers to develop programs specifically tailored for the standard’s
technical features. Algorithms for floating-point arithmetic are presented
throughout the book and illustrated where possible by example programs which
show how these techniques appear in actual coding and design.

The volume itself breaks its core topic into four parts: the basic concepts and
history of floating-point arithmetic; methods of analyzing floating-point
algorithms and optimizing them; implementations of IEEE 754-2008 in hardware
and software; and useful extensions to the standard floating-point system, such
as interval arithmetic, double- and triple-word arithmetic, operations on
complex numbers, and formal verification of floating-point algorithms. This new
edition updates chapters to reflect recent changes to programming languages and
compilers and the new prevalence of GPUs in recent years. The revisions also
add material on fused multiply-add instruction, and methods of extending the
floating-point precision.

As supercomputing becomes more common, more numerical engineers will need to
use number representation to account for trade-offs between various parameters,
such as speed, accuracy, and energy consumption. The _Handbook of
Floating-Point Arithmetic_ is designed for students and researchers in
numerical analysis, programmers of numerical algorithms, compiler designers,
and designers of arithmetic operators.
},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9783319765259},
	doi = {10.1007/978-3-319-76526-6},
	pagetotal = {627},
	isbn = {978-3-319-76525-9},
	publisher = Birkhäuser,
	edition = {2},
	language = {english},
	date = {2018},
	title = {Handbook of Floating-Point Arithmetic},
	author = {Muller, Jean-Michel and Brunie, Nicolas and de Dinechin, Florent and Jeannerod, Claude-Pierre and Joldes, Mioara and Lefèvre, Vincent and Melquiond, Guillaume and Revol, Nathalie and Torres, Serge}
}

@thesis{murphy:dynamic_bayesian_networks,
	type = {phdthesis},
	langidopts = {variant=british},
	langid = {english},
	language = {english},
	location = {California, Estados Unidos},
	title = {Dynamic Bayesian Networks: Representation, Inference and Learning},
	abstract = {Modelling sequential data is important in many areas of science and engineering. Hidden Markov
models (HMMs) and Kalman filter models (KFMs) are popular for this because they are simple and
flexible. For example, HMMs have been used for speech recognition and bio-sequence analysis, and
KFMs have been used for problems ranging from tracking planes and missiles to predicting the
economy. However, HMMs and KFMs are limited in their “expressive power”. Dynamic Bayesian Networks
(DBNs) generalize HMMs by allowing the state space to be represented in factored form, instead of
as a single discrete random variable. DBNs generalize KFMs by allowing arbitrary probability
distributions, not just (unimodal) linear-Gaussian. In this thesis, I will discuss how to represent
many different kinds of models as DBNs, how to perform exact and approximate inference in DBNs, and
how to learn DBN models from sequential data.

In particular, the main novel technical contributions of this thesis are as follows: a way of
representing Hierarchical HMMs as DBNs, which enables inference to be done in O(T) time instead of
O(T³), where T is the length of the sequence; an exact smoothing algorithm that takes O(logT) space
instead of O(T); a simple way of using the junction tree algorithm for online inference in DBNs;
new complexity bounds on exact online inference in DBNs; a new deterministic approximate inference
algorithm called factored frontier; an analysis of the relationship between the BK algorithm and
loopy belief propagation; a way of applying Rao-Blackwellised particle filtering to DBNs in
general, and the SLAM (simultaneous localization and mapping) problem in particular; a way of
extending the structural EM algorithm to DBNs; and a variety of different applications of DBNs.
However, perhaps the main value of the thesis is its catholic presentation of the field of
sequential data modelling.},
	pagetotal = {212},
	institution = {University of California, Berkeley},
	author = {Murphy, Kevin Patrick},
	date = {2002},
	keywords = {Inteligencia artificial, Redes bayesianas},
	file = {Murphy - 2002 - Dynamic Bayesian Networks: Representation, Inference and Learning.pdf}
}

@Book{murray-smith:testing_validation_computer_simulation_models,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2714879},
	series = Springer_Simulation_Foundations,
	keywords = {Ciencias de la computación, Simulación por ordenador},
	abstract = {This must-read text/reference provides a practical guide to processes involved in the development
and application of dynamic simulation models, covering a wide range of issues relating to testing,
verification and validation. Illustrative example problems in continuous system simulation are
presented throughout the book, supported by extended case studies from a number of
interdisciplinary applications. Topics and features: provides an emphasis on practical issues of
model quality and validation, along with questions concerning the management of simulation models,
the use of model libraries, and generic models; contains numerous step-by-step examples; presents
detailed case studies, often with accompanying datasets; includes discussion of hybrid models,
which involve a combination of continuous system and discrete-event descriptions; examines
experimental modeling approaches that involve system identification and parameter estimation;
offers supplementary material at an associated website.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/gp/book/9783319150987},
	doi = {10.1007/978-3-319-15099-4},
	pagetotal = {252},
	isbn = {9783319150987},
	publisher = Springer,
	language = {english},
	date = {2015},
	subtitle = {Principles, Methods and Applications},
	title = {Testing and Validation of Computer Simulation Models},
	author = {Murray-Smith, David J.}
}

@Book{murrel:r_graphics,
	series = CRC_Computer_Science,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1735085},
	keywords = {Lenguaje de programación R, Visualización de datos},
	langidopts = {variant=british},
	langid = {english},
	pagetotal = {301},
	isbn = {9781584884866},
	publisher = CRC,
	language = {english},
	date = {2006},
	title = {R Graphics},
	author = {Murrel, Paul}
}

@Book{murrel:r_graphics_2_ed,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2714850},
	series = CRC_R_Series,
	abstract = {Extensively updated to reflect the evolution of statistics and computing, the second edition of the
bestselling __R Graphics__ comes complete with new packages and new examples. Paul Murrell, widely
known as the leading expert on R graphics, has developed an in-depth resource that helps both
neophyte and seasoned users master the intricacies of R graphics.

__New in the Second Edition__

* Updated information on the core graphics engine, the traditional graphics system, the grid
  graphics system, and the lattice package
* A new chapter on the ggplot2 package
* New chapters on applications and extensions of R Graphics, including geographic maps, dynamic and
  interactive graphics, and node-and-edge graphs

Organized into five parts, __R Graphics__ covers both "traditional" and newer, R-specific graphics
systems. The book reviews the graphics facilities of the R language and describes R’s powerful grid
graphics system. It then covers the graphics engine, which represents a common set of fundamental
graphics facilities, and provides a series of brief overviews of the major areas of application for
R graphics and the major extensions of R graphics.},
	keywords = {Lenguaje de programación R, Visualización de datos},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.crcpress.com/R-Graphics-Second-Edition/Murrell/p/book/9781439831762},
	pagetotal = {546},
	isbn = {9781439831762},
	publisher = CRC,
	edition = {2},
	language = {english},
	date = {2011},
	title = {R Graphics},
	author = {Murrel, Paul}
}

@Book{murtaza:getting_started_data_science,
	enlaces = {Biblioteca de la Universidad de Sevilla: https://fama.us.es/discovery/fulldisplay?docid=alma991013090791604987&context=L&vid=34CBUA_US:VU1&search_scope=all_libraries_profile&tab=LibrariesSearch&lang=es
},
	publisher = IBM_Press,
	keywords = {Ciencia del dato},
	abstract = {**Master Data Analytics Hands-On by Solving Fascinating Problems You’ll
Actually Enjoy!**

*Harvard Business Review* recently called data science “The Sexiest Job of the
21st Century.” It’s not just sexy: For millions of managers, analysts, and
students who need to solve real business problems, it’s indispensable.
Unfortunately, there’s been nothing easy about learning data science–until now.

**Getting Started with Data Science** takes its inspiration from worldwide
best-sellers like Freakonomics and Malcolm Gladwell’s Outliers: It teaches
through a powerful narrative packed with unforgettable stories.

Murtaza Haider offers informative, jargon-free coverage of basic theory and
technique, backed with plenty of vivid examples and hands-on practice
opportunities. Everything’s software and platform agnostic, so you can learn
data science whether you work with R, Stata, SPSS, or SAS. Best of all, Haider
teaches a crucial skillset most data science books ignore: how to tell powerful
stories using graphics and tables. Every chapter is built around real research
challenges, so you’ll always know why you’re doing what you’re doing.

You’ll master data science by answering fascinating questions, such as:

* Are religious individuals more or less likely to have extramarital affairs?
* Do attractive professors get better teaching evaluations?
* Does the higher price of cigarettes deter smoking?
* What determines housing prices more: lot size or the number of bedrooms?
* How do teenagers and older people differ in the way they use social media?
* Who is more likely to use online dating services?
* Why do some purchase iPhones and others Blackberry devices?
* Does the presence of children influence a family’s spending on alcohol?

For each problem, you’ll walk through defining your question and the answers
you’ll need; exploring how others have approached similar challenges; selecting
your data and methods; generating your statistics; organizing your report; and
telling your story. Throughout, the focus is squarely on what matters most:
transforming data into insights that are clear, accurate, and can be acted
upon.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.informit.com/store/getting-started-with-data-science-making-sense-of-data-9780133991024},
	pagetotal = {608},
	isbn = {9780133991024},
	language = {english},
	subtitle = {Making Sense of Data with Analytics},
	date = {2015},
	title = {Getting Started with Data Science},
	author = {Haider Murtaza}
}

@Book{nagarajan_et_al:bayesian_networks_r,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-1-4614-6446-4},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/978-1-4614-6445-7},
	doi = {10.1007/978-1-4614-6446-4},
	language = {english},
	subtitle = {With Applications in Systems Biology},
	title = {Bayesian Networks in R},
	isbn = {9781461464457},
	series = {Use R!},
	abstract = {_Bayesian Networks in R with Applications in Systems Biology_ is unique as it introduces the reader
to the essential concepts in Bayesian network modeling and inference in conjunction with examples
in the open-source statistical environment R. The level of sophistication is also gradually
increased across the chapters with exercises and solutions for enhanced understanding for hands-on
experimentation of the theory and concepts. The application focuses on systems biology with
emphasis on modeling pathways and signaling mechanisms from high-throughput molecular data.
Bayesian networks have proven to be especially useful abstractions in this regard. Their usefulness
is especially exemplified by their ability to discover new associations in addition to validating
known ones across the molecules of interest. It is also expected that the prevalence of publicly
available high-throughput biological data sets may encourage the audience to explore investigating
novel paradigms using the approaches presented in the book.},
	pagetotal = {157},
	number = {48},
	publisher = Springer,
	author = {Nagarajan, Radhakrishnan and Scutari, Marco and Lèbre, Sophie},
	date = {2013},
	keywords = {Lenguaje de programación R, Modelos gráficos probabilísticos, Redes bayesianas},
	file = {Nagarajan et al - 2013 - Bayesian Networks in R.pdf}
}

@XData{natural_computing,
	journaltitle = {Natural Computing},
	issn = {1567-7818},
	publisher = Springer
}

@Book{neapolitan:learning_bayesian_networks,
	series = Prentice_Hall_Artificial_Intelligence,
	publisher = Prentice_Hall,
	file = {Neapolitan - 2004 - Learning Bayesian Networks.pdf},
	keywords = {Inteligencia artificial, Redes bayesianas},
	abstract = {For courses in Bayesian Networks or Advanced Networking focusing on Bayesian networks found in
departments of Computer Science, Computer Engineering and Electrical Engineering. Also appropriate
as a supplementary text in courses on Expert Systems, Machine Learning, and Artificial Intelligence
where the topic of Bayesian Networks is covered.

This book provides an accessible and unified discussion of Bayesian networks. It includes
discussions of topics related to the areas of artificial intelligence, expert systems and decision
analysis, the fields in which Bayesian networks are frequently applied. The author discusses both
methods for doing inference in Bayesian networks and influence diagrams. The book also covers the
Bayesian method for learning the values of discrete and continuous parameters. Both the Bayesian
and constraint-based methods for learning structure are discussed in detail.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.pearsonhighered.com/program/Neapolitan-Learning-Bayesian-Networks/PGM134910.html},
	pagetotal = {693},
	isbn = {9780130125347},
	language = {english},
	date = {2004},
	title = {Learning Bayesian Networks},
	author = {Neapolitan, Richard E.}
}

@Article{neil_et_al:building_large-scale_bayesian_networks,
	xdata = {knowledge_engineering_review},
	enlaces = {Recurso electrónico: http://0-journals.cambridge.org.fama.us.es/article_S0269888900003039},
	file = {Neil et al - 2000 - Building large-scale Bayesian networks.pdf},
	keywords = {Inteligencia artificial, Redes bayesianas},
	abstract = {Bayesian networks (BNs) model problems that involve uncertainty. A BN is a directed graph, whose
nodes are the uncertain variables and whose edges are the causal or influential links between the
variables. Associated with each node is a set of conditional probability functions that model the
uncertain relationship between the node and its parents. The benefits of using BNs to model
uncertain domains are well known, especially since the recent breakthroughs in algorithms and tools
to implement them. However, there have been serious problems for practitioners trying to use BNs to
solve realistic problems. This is because, although the tools make it possible to _execute_
large-scale BNs efficiently, there have been no guidelines on _building_ BNs. Specifically,
practitioners face two significant barriers. The first barrier is that of specifying the graph
structure such that it is a sensible model of the types of reasoning being applied. The second
barrier is that of eliciting the conditional probability values. In this paper we concentrate on
this first problem. Our solution is based on the notion of generally applicable “building blocks”,
called _idioms_, which serve solution patterns. These can then in turn be combined into larger BNs,
using simple combination rules and by exploiting recent ideas on modular and object oriented BNs
(OOBNs). This approach, which has been implemented in a BN tool, can be applied in many problem
domains. We use examples to illustrate how it has been applied to build large-scale BNs for
predicting software safety. In the paper we review related research from the knowledge and software
engineering literature. This provides some context to the work and supports our argument that BN
knowledge engineers require the same types of processes, methods and strategies enjoyed by systems
and software engineers if they are to succeed in producing timely, quality and cost-effective BN
decision support solutions.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://journals.cambridge.org/article_S0269888900003039},
	pages = {257-284},
	number = {03},
	volume = {15},
	language = {english},
	date = {2000-09},
	title = {Building large-scale Bayesian networks},
	author = {Neil, Martin and Fenton, Norman and Nielson, Lars}
}

@Book{nelli:python_data_analytics,
	enlaces = {Recurso electrónico: http://encore.fama.us.es/iii/encore/record/C__Rb2693011},
	keywords = {Lenguaje de programación Python},
	abstract = {_Python Data Analytics_ will help you tackle the world of data acquisition and analysis using the
power of the Python language. At the heart of this book lies the coverage of pandas, an open
source, BSD-licensed library providing high-performance, easy-to-use data structures and data
analysis tools for the Python programming language.

Author Fabio Nelli expertly shows the strength of the Python programming language when applied to
processing, managing and retrieving information. Inside, you will see how intuitive and flexible it
is to discover and communicate meaningful patterns of data using Python scripts, reporting systems,
and data export. This book examines how to go about obtaining, processing, storing, managing and
analyzing data using the Python programming language.

You will use Python and other open source tools to wrangle data and tease out interesting and
important trends in that data that will allow you to predict future patterns. Whether you are
dealing with sales data, investment data (stocks, bonds, etc.), medical data, web page usage, or
any other type of data set, Python can be used to interpret, analyze, and glean information from a
pile of numbers and statistics.

This book is an invaluable reference with its examples of storing and accessing data in a database;
it walks you through the process of report generation; it provides three real world case studies or
examples that you can take with you for your everyday analysis needs.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.apress.com/9781484209592},
	pagetotal = {364},
	isbn = {9781484209592},
	publisher = Apress,
	language = {english},
	date = {2015},
	subtitle = {Data Analysis and Science using {PANDAs}, {matplotlib} and the Python Programming Language},
	title = {Python Data Analytics},
	author = {Nelli, Fabio}
}

@Book{ohagan_et_al:uncertain_judgements,
	subtitle = {Eliciting Experts' Probabilities},
	keywords = {Inteligencia artificial, Redes bayesianas},
	abstract = {Elicitation is the process of extracting expert knowledge about some unknown quantity or
quantities, and formulating that information as a probability distribution. Elicitation is
important in situations, such as modelling the safety of nuclear installations or assessing the
risk of terrorist attacks, where expert knowledge is essentially the only source of good
information. It also plays a major role in other contexts by augmenting scarce observational data,
through the use of Bayesian statistical methods. However, elicitation is not a simple task, and
practitioners need to be aware of a wide range of research findings in order to elicit expert
judgements accurately and reliably. _Uncertain Judgements_ introduces the area, before guiding the
reader through the study of appropriate elicitation methods, illustrated by a variety of
multi-disciplinary examples.

This is achieved by:

* Presenting a methodological framework for the elicitation of expert knowledge incorporating
  findings from both statistical and psychological research.
* Detailing techniques for the elicitation of a wide range of standard distributions, appropriate
  to the most common types of quantities.
* Providing a comprehensive review of the available literature and pointing to the best practice
  methods and future research needs.
* Using examples from many disciplines, including statistics, psychology, engineering and health
  sciences.
* Including an extensive glossary of statistical and psychological terms.

An ideal source and guide for statisticians and psychologists with interests in expert judgement or
practical applications of Bayesian analysis, _Uncertain Judgements_ will also benefit
decision-makers, risk analysts, engineers and researchers in the medical and social sciences.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470029994.html},
	pagetotal = {338},
	isbn = {9780470029992},
	publisher = Wiley,
	series = Statistics_Practice,
	language = {english},
	date = {2006},
	title = {Uncertain Judgements},
	author = {O'Hagan, Anthony and Buck, Caitlin E. and Daneshkhah, Alireza and Eiser, J. Richard and Garthwaite, Paul H. and Jenkinson, David J. and Oakley, Jeremy E. and Rakow, Tim}
}

@XData{operations_research_perspectives,
	journaltitle = {Operations Research Perspectives},
	issn = {2214-7160},
	publisher = Elsevier
}

@Book{orr_muller:neural_networks_tricks_trade,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/3-540-49430-8},
	file = {Orr _ Müller - 1998 - Neural Networks: Tricks of the Trade.pdf},
	keywords = {Inteligencia artificial, Redes neuronales},
	abstract = {It is our belief that researchers and practitioners acquire, through experience and word-of-mouth,
techniques and heuristics that help them successfully apply neural networks to di cult real world
problems. Often these "tricks" are theoretically well motivated. Sometimes they are the result of
trial and error. However, their most common link is that they are usually hidden in people’s heads
or in the back pages of space-constrained conference papers. As a result newcomers to the eld waste
much time wondering why their networks train so slowly and perform so poorly. This book is an
outgrowth of a 1996 NIPS workshop called Tricks of the Trade whose goal was to begin the process of
gathering and documenting these tricks. The interest that the workshop generated motivated us to
expand our collection and compile it into this book. Although we have no doubt that there are many
tricks we have missed, we hope that what we have included will prove to be useful, particularly to
those who are relatively new to the eld. Each chapter contains one or more tricks presented by a
given author (or authors). We have attempted to group related chapters into sections, though we
recognize that the di erent sections are far from disjoint. Some of the chapters (e.g., 1, 13, 17)
contain entire systems of tricks that are far more general than the category they have been placed
in.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783540494300},
	doi = {10.1007/3-540-49430-8},
	pagetotal = {432},
	isbn = {9783540653110},
	publisher = Springer,
	number = {1524},
	language = {english},
	editor = {Orr, Genevieve B. and Müller, Klaus-Robert},
	date = {1998},
	title = {Neural Networks: Tricks of the Trade}
}

@Book{parr:definitive_antlr_reference,
	publisher = Pragmatic_Bookshelf,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2495711
},
	file = {Parr - 2012 - The Definitive ANTLR 4 Reference.pdf},
	keywords = {Análisis de lenguajes},
	abstract = {Build your own languages with ANTLR v4, using ANTLR’s new advanced parsing
technology. In this book, you’ll learn how ANTLR automatically builds a data
structure representing the input (parse tree) and generates code that can walk
the tree (visitor). You can use that combination to implement data readers,
language interpreters, and translators.

You’ll start by learning how to identify grammar patterns in language reference
manuals and then slowly start building increasingly complex grammars. Next,
you’ll build applications based upon those grammars by walking the
automatically generated parse trees. Then you’ll tackle some nasty language
problems by parsing files containing more than one language (such as XML, Java,
and Javadoc). You’ll also see how to take absolute control over parsing by
embedding Java actions into the grammar.

You’ll learn directly from well-known parsing expert Terence Parr, the ANTLR
creator and project lead. You’ll master ANTLR grammar construction and learn
how to build language tools using the built-in parse tree visitor mechanism.
The book teaches using real-world examples and shows you how to use ANTLR to
build such things as a data file reader, a JSON to XML translator, an R parser,
and a Java class->interface extractor. This book is your ticket to becoming a
parsing guru!
},
	langidopts = {variant=british},
	langid = {english},
	url = {https://pragprog.com/book/tpantlr2/the-definitive-antlr-4-reference},
	pagetotal = {305},
	isbn = {9781934356999},
	language = {english},
	date = {2012},
	title = {The Definitive ANTLR 4 Reference},
	author = {Parr, Terence}
}

@XData{pattern_recognition,
	journaltitle = {Pattern Recognition},
	issn = {0031-3203},
	publisher = Elsevier
}

@XData{pattern_recognition_letters,
	journaltitle = {Pattern Recognition Letters},
	issn = {0167-8655},
	publisher = Elsevier
}

@Book{pearl:heuristics,
	file = {Pearl - 1985 - Heuristics.pdf},
	keywords = {Búsqueda heurística, Inteligencia artificial},
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1056962
},
	langidopts = {variant=british},
	langid = {english},
	pagetotal = {382},
	publisher = Addison-Wesley,
	isbn = {9780201055948},
	series = {Addison-Wesley Series in Artificial Intelligence},
	language = {english},
	subtitle = {Intelligent Search Strategies for Computer Problem Solving},
	date = {1985},
	title = {Heuristics},
	author = {Pearl, Judea}
}

@Article{perez-jimenez_et_al:FRSN_P_systems_revisited,
	xdata = {theoretical_computer_science},
	file = {Pérez-Jiménez et al - 2017 - Fuzzy reasoning spiking neural P systems revisited: A formalization.pdf},
	keywords = {Computación con membranas, Lógica difusa},
	abstract = {Research interest within membrane computing is becoming increasingly
interdisciplinary. In particular, one of the latest applications is fault
diagnosis. The underlying mechanism was conceived by bridging spiking neural P
systems with fuzzy rule-based reasoning systems. Despite having a number of
publications associated with it, this research line still lacks a proper
formalization of the foundations.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1016/j.tcs.2017.04.014},
	language = {english},
	date = {2017},
	title = {Fuzzy reasoning spiking neural P systems revisited: A formalization},
	author = {Pérez-Jiménez, Mario J. and Graciani, Carmen and Orellana-Martín, David and Riscos-Núñez, Agustín and Romero-Jiménez, Álvaro and Valencia-Cabrera, Luis}
}

@Book{peters:foundations_computer_vision,
	file = {Peters - 2017 - Foundations of Computer Vision.pdf},
	keywords = {Visión por ordenador},
	abstract = {This book introduces the fundamentals of computer vision (CV), with a focus on
extracting useful information from digital images and videos. Including a
wealth of methods used in detecting and classifying image objects and their
shapes, it is the first book to apply a trio of tools (computational geometry,
topology and algorithms) in solving CV problems, shape tracking in image object
recognition and detecting the repetition of shapes in single images and video
frames. Computational geometry provides a visualization of topological
structures such as neighborhoods of points embedded in images, while image
topology supplies us with structures useful in the analysis and classiﬁcation
of image regions. Algorithms provide a practical, step-by-step means of viewing
image structures.

The implementations of CV methods in Matlab and Mathematica, classiﬁcation of
chapter problems with the symbols (easily solved) and (challenging) and its
extensive glossary of key words, examples and connections with the fabric of CV
make the book an invaluable resource for advanced undergraduate and ﬁrst year
graduate students in Engineering, Computer Science or Applied Mathematics.

It offers insights into the design of CV experiments, inclusion of image
processing methods in CV projects, as well as the reconstruction and
interpretation of recorded natural scenes.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9783319524818},
	doi = {10.1007/978-3-319-52483-2},
	pagetotal = {431},
	isbn = {9783319524818},
	publisher = Springer,
	number = {124},
	series = Intelligent_Systems_Library,
	language = {english},
	subtitle = {Computational Geometry, Visual Image Structures and Object Shape Detection},
	date = {2017},
	title = {Foundations of Computer Vision},
	author = {Peters, James F.}
}

@Book{poole_mackworth:artificial_intelligence,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2196688},
	keywords = {Inteligencia artificial},
	langidopts = {variant=british},
	langid = {english},
	language = {english},
	author = {Poole, David L. and Mackworth, Alan K.},
	title = {Artificial Intelligence},
	subtitle = {Foundations of Computational Agents},
	pagetotal = {662},
	publisher = Cambridge,
	date = {2010},
	isbn = {9780521519007},
	url = {http://artint.info/}
}

@Book{pourret_et_al:bayesian_networks,
	subtitle = {A Practical Guide to Applications},
	series = Statistics_Practice,
	file = {Pourret et al - 2008 - Bayesian Networks - A Practical Guide to Applications.pdf},
	keywords = {Inteligencia artificial, Redes bayesianas},
	abstract = {Bayesian Networks, the result of the convergence of artificial intelligence with statistics, are
growing in popularity. Their versatility and modelling power is now employed across a variety of
fields for the purposes of analysis, simulation, prediction and diagnosis.

This book provides a general introduction to Bayesian networks, defining and illustrating the basic
concepts with pedagogical examples and twenty real-life case studies drawn from a range of fields
including medicine, computing, natural sciences and engineering.

Designed to help analysts, engineers, scientists and professionals taking part in complex decision
processes to successfully implement Bayesian networks, this book equips readers with proven methods
to generate, calibrate, evaluate and validate Bayesian networks.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470060301.html},
	doi = {10.1002/9780470994559},
	pagetotal = {446},
	isbn = {9780470060308},
	publisher = Wiley,
	language = {english},
	editor = {Pourret, Olivier and Naïm, Patrick and Marcot, Bruce},
	date = {2008},
	title = {Bayesian Networks}
}

@Book{privault:understanding_markov_chains,
	series = Springer_Undergraduate_Mathematics,
	enlaces = {Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-981-4451-51-2},
	file = {Privault - 2013 - Understanding Markov Chains.pdf},
	keywords = {Estadística, Procesos de Markov},
	abstract = {This book provides an undergraduate introduction to discrete and continuous-time Markov chains and
their applications. A large focus is placed on the first step analysis technique and its
applications to average hitting times and ruin probabilities. Classical topics such as recurrence
and transience, stationary and limiting distributions, as well as branching processes, are also
covered. Two major examples (gambling processes and random walks) are treated in detail from the
beginning, before the general theory itself is presented in the subsequent chapters. An
introduction to discrete-time martingales and their relation to ruin probabilities and mean exit
times is also provided, and the book includes a chapter on spatial Poisson processes with some
recent results on moment identities and deviation inequalities for Poisson stochastic integrals.
The concepts presented are illustrated by examples and by 72 exercises and their complete
solutions.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9789814451505},
	doi = {10.1007/978-981-4451-51-2},
	pagetotal = {354},
	isbn = {9789814451505},
	publisher = Springer,
	language = {english},
	subtitle = {Examples and Applications},
	date = {2013},
	title = {Understanding Markov Chains},
	author = {Privault, Nicolas}
}

@Online{r_project_statistical_computing,
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.r-project.org/},
	title = {The R Project for Statistical Computing}
}

@Book{ramalho:fluent_python,
	enlaces = {Recurso electrónico: http://0-proquest.safaribooksonline.com.fama.us.es//?uiCode=sevil&xmlId=9781491946237},
	keywords = {Lenguaje de programación Python},
	abstract = {Python’s simplicity lets you become productive quickly, but this often means you aren’t using
everything it has to offer. With this hands-on guide, you’ll learn how to write effective,
idiomatic Python code by leveraging its best—and possibly most neglected—features. Author Luciano
Ramalho takes you through Python’s core language features and libraries, and shows you how to make
your code shorter, faster, and more readable at the same time.

Many experienced programmers try to bend Python to fit patterns they learned from other languages,
and never discover Python features outside of their experience. With this book, those Python
programmers will thoroughly learn how to become proficient in Python 3.

This book covers:
* __Python data model__: understand how special methods are the key to the consistent behavior of
  objects
* __Data structures__: take full advantage of built-in types, and understand the text vs bytes
  duality in the Unicode age
* __Functions as objects__: view Python functions as first-class objects, and understand how this
  affects popular design patterns
* __Object-oriented idioms__: build classes by learning about references, mutability, interfaces,
  operator overloading, and multiple inheritance
* __Control flow__: leverage context managers, generators, coroutines, and concurrency with the
  concurrent.futures and asyncio packages
* __Metaprogramming__: understand how properties, attribute descriptors, class decorators, and
  metaclasses work

},
	langidopts = {variant=british},
	langid = {english},
	url = {http://shop.oreilly.com/product/0636920032519.do},
	pagetotal = {792},
	isbn = {9781491946008},
	publisher = OReilly,
	language = {english},
	date = {2105},
	subtitle = {Clear, Concise, and Effective Programming},
	title = {Fluent Python},
	author = {Ramalho, Luciano}
}

@Book{ramasubramanian_singh:machine_learning_using_r,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2748659},
	keywords = {Aprendizaje automático, Inteligencia artificial, Lenguaje de programación R},
	abstract = {Examine the latest technological advancements in building a scalable machine
learning model with Big Data using R. This book shows you how to work with a
machine learning algorithm and use it to build a ML model from raw data.

All practical demonstrations will be explored in R, a powerful programming
language and software environment for statistical computing and graphics. The
various packages and methods available in R will be used to explain the topics.
For every machine learning algorithm covered in this book, a 3-D approach of
theory, case-study and practice will be given. And where appropriate, the
mathematics will be explained through visualization in R.

This new paradigm of teaching machine learning will bring about a radical
change in perception for many of those who think this subject is difficult to
learn. Though theory sometimes looks difficult, especially when there is heavy
mathematics involved, the seamless flow from the theoretical aspects to
example-driven learning provided in this book makes it easy for someone to
connect the dots.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781484223338},
	doi = {10.1007/978-1-4842-2334-5},
	pagetotal = {566},
	isbn = {9781484223338},
	publisher = Springer,
	language = {english},
	date = {2017},
	title = {Machine Learning Using R},
	author = {Ramasubramanian, Karthik and Singh, Abhishek}
}

@XData{reliability_engineering_system_safety,
	journaltitle = {Reliability Engineering and System Safety},
	issn = {0951-8320},
	publisher = Elsevier
}

@Book{robbins:creating_more_effective_graphs,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1735477
},
	keywords = {Visualización de datos},
	langidopts = {variant=british},
	langid = {english},
	pagetotal = {402},
	isbn = {9780471274025},
	publisher = Wiley,
	language = {english},
	date = {2005},
	title = {Creating More Effective Graphs},
	author = {Robbins, Naomi Bograd}
}

@book{robert_casella:introducing_monte_carlo_methods_r,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2118918
Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-1-4419-1576-4},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781441915757},
	doi = {10.1007/978-1-4419-1576-4},
	language = {english},
	title = {Introducing Monte Carlo Methods with R},
	isbn = {9781441915757},
	series = Springer_Use_R,
	abstract = {Computational techniques based on simulation have now become an essential part of the
statistician's toolbox. It is thus crucial to provide statisticians with a practical understanding
of those methods, and there is no better way to develop intuition and skills for simulation than to
use simulation to solve statistical problems. *Introducing Monte Carlo Methods with R* covers the
main tools used in statistical simulation from a programmer's point of view, explaining the R
implementation of each simulation technique and providing the output for better understanding and
comparison. While this book constitutes a comprehensive treatment of simulation methods, the
theoretical justification of those methods has been considerably reduced, compared with Robert and
Casella (2004). Similarly, the more exploratory and less stable solutions are not covered here.

This book does not require a preliminary exposure to the R programming language or to Monte Carlo
methods, nor an advanced mathematical background. While many examples are set within a Bayesian
framework, advanced expertise in Bayesian statistics is not required. The book covers basic random
generation algorithms, Monte Carlo techniques for integration and optimization, convergence
diagnoses, Markov chain Monte Carlo methods, including Metropolis-Hastings and Gibbs algorithms,
and adaptive algorithms. All chapters include exercises and all R programs are available as an R
package called mcsm. The book appeals to anyone with a practical interest in simulation methods but
no previous exposure. It is meant to be useful for students and practitioners in areas such as
statistics, signal processing, communications engineering, control theory, econometrics, finance
and more. The programming parts are introduced progressively to be accessible to any reader.},
	pagetotal = {284},
	publisher = Springer,
	author = {Robert, Christian P. and Casella, George},
	date = {2010},
	keywords = {Estadística computacional, Métodos de Monte Carlo},
	file = {Robert _ Casella - 2010 - Introducing Monte Carlo Methods with R.pdf}
}

@book{robert_casella:monte_carlo_statistical_methods,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1735497},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780387212395},
	doi = {10.1007/978-1-4757-4145-2},
	language = {english},
	edition = {2},
	title = {Monte Carlo Statistical Methods},
	isbn = {9780387212396},
	series = Springer_Text_Statistics,
	abstract = {Monte Carlo statistical methods, particularly those based on Markov chains, are now an essential
component of the standard set of techniques used by statisticians. This new edition has been
revised towards a coherent and flowing coverage of these simulation techniques, with incorporation
of the most recent developments in the field. In particular, the introductory coverage of random
variable generation has been totally revised, with many concepts being unified through a
fundamental theorem of simulation

There are five completely new chapters that cover Monte Carlo control, reversible jump, slice
sampling, sequential Monte Carlo, and perfect sampling. There is a more in-depth coverage of Gibbs
sampling, which is now contained in three consecutive chapters. The development of Gibbs sampling
starts with slice sampling and its connection with the fundamental theorem of simulation, and
builds up to two-stage Gibbs sampling and its theoretical properties. A third chapter covers the
multi-stage Gibbs sampler and its variety of applications. Lastly, chapters from the previous
edition have been revised towards easier access, with the examples getting more detailed coverage.

This textbook is intended for a second year graduate course, but will also be useful to someone who
either wants to apply simulation techniques for the resolution of practical problems or wishes to
grasp the fundamental principles behind those methods. The authors do not assume familiarity with
Monte Carlo techniques (such as random variable generation), with computer programming, or with any
Markov chain theory (the necessary concepts are developed in Chapter 6). A solutions manual, which
covers approximately 40\% of the problems, is available for instructors who require the book for a
course.},
	pagetotal = {649},
	publisher = Springer,
	author = {Robert, Christian P. and Casella, George},
	date = {2004},
	keywords = {Estadística computacional, Métodos de Monte Carlo}
}

@Book{rose:data_science,
	file = {Rose - 2016 - Data Science - Create Teams That Ask the Right Questions and Deliver Real Value.pdf},
	keywords = {Ciencia del dato, No disponible en la BUS},
	abstract = {Learn how to build a data science team within your organization rather than
hiring from the outside. Teach your team to ask the right questions to gain
actionable insights into your business.

Most organizations still focus on objectives and deliverables. Instead, a data
science team is exploratory. They use the scientific method to ask interesting
questions and run small experiments. Your team needs to see if the data
illuminate their questions. Then, they have to use critical thinking techniques
to justify their insights and reasoning. They should pivot their efforts to
keep their insights aligned with business value. Finally, your team needs to
deliver these insights as a compelling story.

_Insight!: How to Build Data Science Teams that Deliver Real Business Value_
shows that the most important thing you can do now is help your team think
about data. Management coach Doug Rose walks you through the process of
creating and managing effective data science teams. You will learn how to find
the right people inside your organization and equip them with the right
mindset. The book has three overarching concepts:

* You should mine your own company for talent. You can’t change your
  organization by hiring a few data science superheroes.
* You should form small, agile-like data teams that focus on delivering
  valuable insights early and often.
* You can make real changes to your organization by telling compelling data
  stories. These stories are the best way to communicate your insights about
  your customers, challenges, and industry.

What Your Will Learn:

* Create data science teams from existing talent in your organization to
  cost-efficiently extract maximum business value from your organization’s data
* Understand key data science terms and concepts
* Follow practical guidance to create and integrate an effective data science
  team with key roles and the responsibilities for each team member
* Utilize the data science life cycle (DSLC) to model essential processes and
  practices for delivering value
* Use sprints and storytelling to help your team stay on track and adapt to new
  knowledge
},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.apress.com/9781484222522},
	doi = {10.1007/978-1-4842-2253-9},
	pagetotal = {251},
	isbn = {9781484222522},
	publisher = Apress,
	language = {english},
	subtitle = {Create Teams That Ask the Right Questions and Deliver Real Value},
	date = {2016},
	title = {Data Science},
	author = {Rose, Doug}
}

@Book{rother:pro_python_best_practices,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2793835
Recurso electrónico (Safari Books Online): http://0-proquest.safaribooksonline.com.fama.us.es/?uiCode=sevil&xmlId=9781484222416
},
	keywords = {Lenguaje de programación Python},
	abstract = {Learn software engineering and coding best practices to write Python code right
and error free. In this book you’ll see how to properly debug, organize, test,
and maintain your code, all of which leads to better, more efficient coding.

Software engineering is difficult. Programs of any substantial length are
inherently prone to errors of all kinds. The development cycle is full of traps
unknown to the apprentice developer. Yet, in Python textbooks little attention
is paid to this aspect of getting your code to run. At most, there is a chapter
on debugging or unit testing in your average basic Python book. However, the
proportion of time spent on getting your code to run is much higher in the real
world. _Pro Python Best Practices_ aims to solve this problem.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781484222409},
	doi = {10.1007/978-1-4842-2241-6},
	pagetotal = {264},
	isbn = {9781484222409},
	publisher = Apress,
	language = {english},
	date = {2017},
	subtitle = {Debugging, Testing and Maintenance},
	title = {Pro Python Best Practices},
	author = {Rother, Kristian}
}

@Book{rothlauf:design_modern_heuristics,
	subtitle = {Principles and Application},
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-3-540-72962-4},
	file = {Rothlauf - 2011 - Design of Modern Heuristics.pdf},
	keywords = {Inteligencia artificial, Metaheurísticas},
	abstract = {Most textbooks on modern heuristics provide the reader with detailed descriptions of the
functionality of single examples like genetic algorithms, genetic programming, tabu search,
simulated annealing, and others, but fail to teach the underlying concepts behind these different
approaches.

The author takes a different approach in this textbook by focusing on the users' needs and
answering three fundamental questions: First, he tells us which problems modern heuristics are
expected to perform well on, and which should be left to traditional optimization methods. Second,
he teaches us to systematically design the "right" modern heuristic for a particular problem by
providing a coherent view on design elements and working principles. Third, he shows how we can
make use of problem-specific knowledge for the design of efficient and effective modern heuristics
that solve not only small toy problems but also perform well on large real-world problems.

This book is written in an easy-to-read style and it is aimed at students and practitioners in
computer science, operations research and information systems who want to understand modern
heuristics and are interested in a guide to their systematic design and use.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783540729617},
	doi = {10.1007/978-3-540-72962-4},
	pagetotal = {267},
	isbn = {9783540729617},
	publisher = Springer,
	series = Springer_Natural_Computing,
	language = {english},
	date = {2011},
	title = {Design of Modern Heuristics},
	author = {Rothlauf, Franz}
}

@Book{rothlauf:representations_genetic_evolutionary_algorithms,
	file = {Rothlauf - 2006 - Representations for Genetic and Evolutionary Algorithms.pdf},
	enlaces = {Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/3-540-32444-5},
	keywords = {Algoritmos evolutivos, Algoritmos genéticos},
	abstract = {In the field of genetic and evolutionary algorithms (GEAs), a large amount of theory and empirical
study has focused on operators and test problems, while problem representation has often been taken
as given. This book breaks away from this tradition and provides a comprehensive overview on the
influence of problem representations on GEA performance. The book summarizes existing knowledge
regarding problem representations and describes how basic properties of representations, such as
redundancy, scaling, or locality, influence the performance of GEAs and other heuristic
optimization methods. Using the developed theory, representations can be analyzed and designed in a
theory-guided matter. The theoretical concepts are used for solving integer optimization problems
and network design problems more efficiently. The book is written in an easy-to-read style and is
intended for researchers, practitioners, and students who want to learn about representations. This
second edition extends the analysis of the basic properties of representations and introduces a new
chapter on the analysis of direct representations.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/978-3-540-25059-3},
	doi = {10.1007/3-540-32444-5},
	pagetotal = {325},
	isbn = {9783540250593},
	publisher = Springer,
	edition = {2},
	language = {english},
	date = {2006},
	title = {Representations for Genetic and Evolutionary Algorithms},
	author = {Rothlauf, Franz}
}

@Proceedings{rozenberg_et_al:membrane_computing,
	language = {english},
	volume = {9504},
	series = LNCS,
	publisher = Springer,
	isbn = {9783319284743},
	pagetotal = {387},
	doi = {10.1007/978-3-319-28475-0},
	url = {http://www.springer.com/gp/book/9783319284743},
	langidopts = {variant=british},
	langid = {english},
	keywords = {Computación bioinspirada, Computación con membranas},
	file = {Rozenberg et al - 2015 - Membrane Computing.pdf},
	eventtitleaddon = {CMC 2015},
	venue = {Valencia, Spain},
	enlaces = {Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-3-319-28475-0},
	eventdate = {2015-08-17/2015-08-21},
	eventtitle = {16th International Conference on Membrane Computing},
	date = {2015},
	title = {Membrane Computing},
	editor = {Rozenberg, Grzegorz and Salomaa, Arto and Sempere, José. M and Zandron, Claudio }
}

@Book{russell_norvig:artificial_intelligence,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2147524
},
	abstract = {_Artificial Intelligence: A Modern Approach, 3e_ offers the most comprehensive, up-to-date
introduction to the theory and practice of artificial intelligence. Number one in its field, this
textbook is ideal for one or two-semester, undergraduate or graduate-level courses in Artificial
Intelligence.},
	keywords = {Inteligencia artificial},
	langidopts = {variant=british},
	langid = {english},
	url = {http://aima.cs.berkeley.edu/},
	language = {english},
	author = {Russell, Stuart J. and Norvig, Peter},
	title = {Artificial Intelligence: A Modern Approach},
	series = {Prentice Hall Series in Artificial Intelligence},
	pagetotal = {1132},
	publisher = {Pearson},
	edition = {3},
	date = {2009},
	isbn = {9780136042594}
}

@Book{schneider_kirkpatrick:stochastic_optimization,
	series = Springer_Scientific_Computation,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb1917994
Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-3-540-34560-2
},
	file = {Schneider _ Kirkpatrick - 2006 - Stochastic Optimization.pdf},
	keywords = {Optimización estocástica},
	abstract = {The search for optimal solutions pervades our daily lives. From the scientific
point of view, optimization procedures play an eminent role whenever exact
solutions to a given problem are not at hand or a compromise has to be sought,
e.g. to obtain a sufficiently accurate solution within a given amount of time.
This book addresses stochastic optimization procedures in a broad manner,
giving an overview of the most relevant optimization philosophies in the first
part. The second part deals with benchmark problems in depth, by applying in
sequence a selection of optimization procedures to them. While having primarily
scientists and students from the physical and engineering sciences in mind,
this book addresses the larger community of all those wishing to learn about
stochastic optimization techniques and how to use them.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9783540345596},
	doi = {10.1007/978-3-540-34560-2},
	pagetotal = {568},
	isbn = {9783540345596},
	publisher = Springer,
	language = {english},
	date = {2006},
	title = {Stochastic Optimization},
	author = {Schneider, Johannes Josef and Kirkpatrick, Scott}
}

@Book{schoning:logic_computer_scientists,
	enlaces = {Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-0-8176-4763-6},
	file = {Schöning - 2008 - Logic for computer scientists.pdf},
	keywords = {Lógica matemática},
	abstract = {This book introduces the notions and methods of formal logic from a computer science standpoint,
covering propositional logic, predicate logic, and foundations of logic programming. It presents
applications and themes of computer science research such as resolution, automated deduction, and
logic programming in a rigorous but readable way.

The style and scope of the work, rounded out by the inclusion of exercises, make this an excellent
textbook for an advanced undergraduate course in logic for computer scientists.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780817647629},
	doi = {10.1007/978-0-8176-4763-6},
	pagetotal = {168},
	isbn = {9780817647629},
	publisher = Birkhäuser,
	series = Modern_Birkhäuser_Classics,
	language = {english},
	date = {2008},
	title = {Logic for Computer Scientists},
	author = {Schöning, Uwe}
}

@Book{scutari_denis:bayesian_networks,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2667538},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.crcpress.com/9781482225587},
	language = {english},
	subtitle = {With Examples in R},
	title = {Bayesian Networks},
	isbn = {9781482225587},
	series = CRC_Statistical_Science,
	abstract = {_Bayesian Networks: With Examples in R_ introduces Bayesian networks using a hands-on approach.
Simple yet meaningful examples in R illustrate each step of the modeling process. The examples
start from the simplest notions and gradually increase in complexity. The authors also distinguish
the probabilistic models from their estimation with data sets.

The first three chapters explain the whole process of Bayesian network modeling, from structure
learning to parameter learning to inference. These chapters cover discrete Bayesian, Gaussian
Bayesian, and hybrid networks, including arbitrary random variables.

The book then gives a concise but rigorous treatment of the fundamentals of Bayesian networks and
offers an introduction to causal Bayesian networks. It also presents an overview of R and other
software packages appropriate for Bayesian networks. The final chapter evaluates two real-world
examples: a landmark causal protein signaling network paper and graphical modeling approaches for
predicting the composition of different body parts.

Suitable for graduate students and non-statisticians, this text provides an introductory overview
of Bayesian networks. It gives readers a clear, practical understanding of the general approach and
steps involved.},
	pagetotal = {241},
	publisher = CRC,
	author = {Scutari, Marco and Denis, Jean-Baptiste},
	date = {2014},
	keywords = {Lenguaje de programación R, Modelos gráficos probabilísticos, Redes bayesianas}
}

@Book{siarry:metaheuristics,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2748661},
	keywords = {Inteligencia artificial, Metaheurísticas},
	abstract = {Metaheuristics exhibit desirable properties like simplicity, easy
parallelizability, and ready applicability to different types of optimization
problems. After a comprehensive introduction to the field, the contributed
chapters in this book include explanations of the main metaheuristics
techniques, including simulated annealing, tabu search, evolutionary
algorithms, artificial ants, and particle swarms, followed by chapters that
demonstrate their applications to problems such as multiobjective optimization,
logistics, vehicle routing, and air traffic management.

The authors are leading researchers in this domain, with considerable teaching
and applications experience, and the book will be of value to industrial
practitioners, graduate students, and research academics.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783319454016},
	doi = {10.1007/978-3-319-45403-0},
	pagetotal = {489},
	isbn = {9783319454016},
	publisher = Springer,
	language = {english},
	editor = {Siarry, Patrick},
	date = {2016},
	title = {Metaheuristics}
}

@Collection{sigaud_buffet:markov_decision_processes_artificial_intelligence,
	subtitle = {MDPs, Beyond MDPs and Applications},
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2659949},
	url = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-1848211678.html},
	langidopts = {variant=british},
	langid = {english},
	publisher = Wiley,
	language = {english},
	title = {Markov Decision Processes in Artificial Intelligence},
	isbn = {9781848211674},
	abstract = {Markov Decision Processes (MDPs) are a mathematical framework for modeling sequential decision
problems under uncertainty as well as Reinforcement Learning problems. Written by experts in the
field, this book provides a global view of current research using MDPs in Artificial Intelligence.
It starts with an introductory presentation of the fundamental aspects of MDPs (planning in MDPs,
Reinforcement Learning, Partially Observable MDPs, Markov games and the use of non-classical
criteria). Then it presents more advanced research trends in the domain and gives some concrete
examples using illustrative applications.},
	pagetotal = {480},
	editor = {Sigaud, Olivier and Buffet, Olivier},
	date = {2010},
	keywords = {Modelos de Markov}
}

@Book{sipser:introduction_theory_computation,
	publisher = Cengage,
	file = {Sipser - 2013 - Introduction to the Theory of Computation.pdf},
	keywords = {Ciencias de la computación},
	abstract = {Now you can clearly present even the most complex computational theory topics
to your students with Sipser's distinct, market-leading INTRODUCTION TO THE
THEORY OF COMPUTATION, 3E. The number one choice for today's computational
theory course, this highly anticipated revision retains the unmatched clarity
and thorough coverage that make it a leading text for upper-level undergraduate
and introductory graduate students. This edition continues author Michael
Sipser's well-known, approachable style with timely revisions, additional
exercises, and more memorable examples in key areas. A new first-of-its-kind
theoretical treatment of deterministic context-free languages is ideal for a
better understanding of parsing and LR(k) grammars. This edition's refined
presentation ensures a trusted accuracy and clarity that make the challenging
study of computational theory accessible and intuitive to students while
maintaining the subject's rigor and formalism. Readers gain a solid
understanding of the fundamental mathematical properties of computer hardware,
software, and applications with a blend of practical and philosophical coverage
and mathematical treatments, including advanced theorems and proofs.
INTRODUCTION TO THE THEORY OF COMPUTATION, 3E's comprehensive coverage makes
this an ideal ongoing reference tool for those studying theoretical computing.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.cengage.co.uk/books/9781133187790/},
	pagetotal = {504},
	isbn = {9781133187790},
	edition = {3},
	language = {english},
	date = {2013},
	title = {Introduction to the Theory of Computation},
	author = {Sipser, Michael}
}

@Book{sivanandam_deepa:introduction_genetic_algorithms,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2007252
Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-3-540-73190-0},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/978-3-540-73189-4},
	doi = {10.1007/978-3-540-73190-0},
	language = {english},
	title = {Introduction to Genetic Algorithms},
	isbn = {9783540731894},
	abstract = {Genetic Algorithms are adaptive heuristic search algorithm premised on the evolutionary ideas of
natural selection and genetic. The basic concept of Genetic Algorithms is designed to simulate
processes in natural system necessary for evolution, specifically those that follow the principles
first laid down by Charles Darwin of survival of the fittest. This book is designed to provide an
in-depth knowledge on the basic operational features and characteristics of Genetic Algorithms. The
various operators and techniques given in the book are pertinent to carry out Genetic Algorithm
Research Projects. The book also explores the different types are Genetic Algorithms available with
their importance. Implementation of Genetic Algorithm concept has been performed using the
universal language C/C++ and the discussion also extends to Genetic Algorithm MATLAB Toolbox. Few
Genetic Algorithm problems are programmed using MATLAB and the simulated results are given for the
ready reference of the reader. The applications of Genetic Algorithms in Machine learning,
Mechanical Engineering, Electrical Engineering, Civil Engineering, Data Mining, Image Processing,
and VLSI are dealt to make the readers understand where the concept can be applied.},
	pagetotal = {442},
	publisher = Springer,
	author = {Sivanandam, S. N. and Deepa, S. N.},
	date = {2008},
	keywords = {Algoritmos genéticos, Metaheurísticas},
	file = {Sivanandam _ Deepa - 2008 - Introduction to Genetic Algorithms.pdf}
}

@Book{stephenson:python_workbook,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-3-319-14240-1},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/978-3-319-14239-5},
	doi = {10.1007/978-3-319-14240-1},
	language = {english},
	subtitle = {A Brief Introduction with Exercises and Solutions},
	title = {The Python Workbook},
	isbn = {9783319142395},
	abstract = {While other textbooks devote their pages to explaining introductory programming concepts, The
Python Workbook focuses exclusively on exercises, following the philosophy that computer
programming is a skill best learned through experience and practice.

Designed to support and encourage hands-on learning about programming, this student-friendly work
contains 174 exercises, spanning a variety of academic disciplines and everyday situations.
Solutions to selected exercises are also provided, supported by brief annotations that explain the
technique used to solve the problem, or highlight specific points of Python syntax. No background
knowledge is required to solve the exercises, beyond the material covered in a typical introductory
Python programming course.},
	pagetotal = {165},
	publisher = Springer,
	author = {Stephenson, Ben},
	date = {2014},
	keywords = {Lenguaje de programación Python},
	file = {Stephenson - 2014 - The Python Workbook.pdf}
}

@book{sucar:probabilistic_graphical_models,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2672827},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781447166986},
	doi = {10.1007/978-1-4471-6699-3},
	language = {english},
	subtitle = {Principles and Applications},
	title = {Probabilistic Graphical Models},
	isbn = {9781447166986},
	series = Springer_Computer_Vision,
	abstract = {This accessible text/reference provides a general introduction to probabilistic graphical models
(PGMs) from an engineering perspective. The book covers the fundamentals for each of the main
classes of PGMs, including representation, inference and learning principles, and reviews
real-world applications for each type of model. These applications are drawn from a broad range of
disciplines, highlighting the many uses of Bayesian classifiers, hidden Markov models, Bayesian
networks, dynamic and temporal Bayesian networks, Markov random fields, influence diagrams, and
Markov decision processes. Features: presents a unified framework encompassing all of the main
classes of PGMs; describes the practical application of the different techniques; examines the
latest developments in the field, covering multidimensional Bayesian classifiers, relational
graphical models and causal models; provides exercises, suggestions for further reading, and ideas
for research or programming projects at the end of each chapter.},
	pagetotal = {253},
	publisher = Springer,
	author = {Sucar, Luis Enrique},
	date = {2015},
	keywords = {Inteligencia artificial, Redes bayesianas}
}

@Book{suess_trumbo:introduction_probability_simulation_gibbs_sampling_r,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-0-387-68765-0
},
	file = {Suess _ Trumbo - 2010 - Introduction to Probability Simulation and Gibbs Sampling with R.pdf},
	keywords = {Lenguaje de programación R, Simulación estocástica},
	abstract = {The first seven chapters use R for probability simulation and computation,
including random number generation, numerical and Monte Carlo integration, and
finding limiting distributions of Markov Chains with both discrete and
continuous states. Applications include coverage probabilities of binomial
confidence intervals, estimation of disease prevalence from screening tests,
parallel redundancy for improved reliability of systems, and various kinds of
genetic modeling. These initial chapters can be used for a non-Bayesian course
in the simulation of applied probability models and Markov Chains. Chapters 8
through 10 give a brief introduction to Bayesian estimation and illustrate the
use of Gibbs samplers to find posterior distributions and interval estimates,
including some examples in which traditional methods do not give satisfactory
results. WinBUGS software is introduced with a detailed explanation of its
interface and examples of its use for Gibbs sampling for Bayesian estimation.
No previous experience using R is required. An appendix introduces R, and
complete R code is included for almost all computational examples and problems
(along with comments and explanations). Noteworthy features of the book are its
intuitive approach, presenting ideas with examples from biostatistics,
reliability, and other fields; its large number of figures; and its
extraordinarily large number of problems (about a third of the pages), ranging
from simple drill to presentation of additional topics. Hints and answers are
provided for many of the problems. These features make the book ideal for
students of statistics at the senior undergraduate and at the beginning
graduate levels.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780387402734},
	doi = {10.1007/978-0-387-68765-0},
	pagetotal = {307},
	isbn = {9780387402734},
	publisher = Springer,
	series = Springer_Use_R,
	language = {english},
	date = {2010},
	title = {Introduction to Probability Simulation and Gibbs Sampling with R},
	author = {Suess, Eric A. and Trumbo, Bruce E.}
}

@Book{suthaharan:machine_learning_big_data,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2715367},
	series = Springer_Information_Systems,
	keywords = {Aprendizaje automático, Macrodatos},
	abstract = {This book presents machine learning models and algorithms to address big data classification
problems. Existing machine learning techniques like the decision tree (a hierarchical approach),
random forest (an ensemble hierarchical approach), and deep learning (a layered approach) are
highly suitable for the system that can handle such problems. This book helps readers, especially
students and newcomers to the field of big data and machine learning, to gain a quick understanding
of the techniques and technologies; therefore, the theory, examples, and programs (Matlab and R)
presented in this book have been simplified, hardcoded, repeated, or spaced for improvements. They
provide vehicles to test and understand the complicated concepts of various topics in the field. It
is expected that the readers adopt these programs to experiment with the examples, and then modify
or write their own programs toward advancing their knowledge for solving more complex and
challenging problems.

The presentation format of this book focuses on simplicity, readability, and dependability so that
both undergraduate and graduate students as well as new researchers, developers, and practitioners
in this field can easily trust and grasp the concepts, and learn them effectively. It has been
written to reduce the mathematical complexity and help the vast majority of readers to understand
the topics and get interested in the field. This book consists of four parts, with the total of 14
chapters. The first part mainly focuses on the topics that are needed to help analyze and
understand data and big data. The second part covers the topics that can explain the systems
required for processing big data. The third part presents the topics required to understand and
select machine learning techniques to classify big data. Finally, the fourth part concentrates on
the topics that explain the scaling-up machine learning, an important solution for modern big data
problems.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/978-1-4899-7640-6},
	doi = {10.1007/978-1-4899-7641-3},
	pagetotal = {359},
	isbn = {9781489976406},
	publisher = Springer,
	number = {36},
	language = {english},
	date = {2016},
	subtitle = {Thinking with Examples for Effective Learning},
	title = {Machine Learning Models and Algorithms for Big Data Classification},
	author = {Suthaharan, Shan}
}

@Book{tadeusiewicz_et_al:exploring_neural_networks_c,
	enlaces = {Recurso electrónico (Safari Books Online): http://0-proquest.safaribooksonline.com.fama.us.es//?uiCode=sevil&xmlId=9781482233391},
	keywords = {Inteligencia artificial, Redes neuronales},
	abstract = {The utility of artificial neural network models lies in the fact that they can be used to infer
functions from observations—making them especially useful in applications where the complexity of
data or tasks makes the design of such functions by hand impractical.

**Exploring Neural Networks with C#** presents the important properties of neural networks—while
keeping the complex mathematics to a minimum. Explaining how to build and use neural networks, it
presents complicated information about neural networks structure, functioning, and learning in a
manner that is easy to understand.

Taking a "learn by doing" approach, the book is filled with illustrations to guide you through the
mystery of neural networks. Examples of experiments are provided in the text to encourage
individual research. Online access to C# programs is also provided to help you discover the
properties of neural networks.

Following the procedures and using the programs included with the book will allow you to learn how
to work with neural networks and evaluate your progress. You can download the programs as both
executable applications and C# source code from
http://home.agh.edu.pl/~tad//index.php?page=programy&lang=en},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.crcpress.com/Exploring-Neural-Networks-with-C/Tadeusiewicz-Chaki-Chaki/p/book/9781482233391},
	pagetotal = {298},
	isbn = {9781482233391},
	publisher = CRC,
	language = {english},
	date = {2014},
	title = {Exploring Neural Networks with C#},
	author = {Tadeusiewicz, Ryszard and Chaki, Rituparna and Chaki, Nabendu}
}

@Book{tang_et_al:neural_networks_computational_models,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-3-540-69226-3},
	file = {Tang et al - 2007 - Neural Networks: Computational Models and Applications.pdf},
	keywords = {Inteligencia artificial, Redes neuronales},
	abstract = {Neural Networks: Computational Models and Applications covers a wealth of important theoretical and
practical issues in neural networks, including the learning algorithms of feed-forward neural
networks, various dynamical properties of recurrent neural networks, winner-take-all networks and
their applications in broad manifolds of computational intelligence: pattern recognition, uniform
approximation, constrained optimization, NP-hard problems, and image segmentation. By presenting
various computational models, this book is developed to provide readers with a quick but insightful
understanding of the broad and rapidly growing areas in the neural networks domain.

Besides laying down fundamentals on artificial neural networks, this book also studies biologically
inspired neural networks. Some typical computational models are discussed, and subsequently applied
to objection recognition, scene analysis and associative memory. The studies of bio-inspired models
have important implications in computer vision and robotic navigation, as well as new efficient
algorithms for image analysis. Another significant feature of the book is that it begins with
fundamental dynamical problems in presenting the mathematical techniques extensively used in
analyzing neurodynamics, thus allowing non-mathematicians to develop and apply these analytical
techniques easily.

Written for a wide readership, engineers, computer scientists and mathematicians interested in
machine learning, data mining and neural networks modeling will find this book of value. This book
will also act as a helpful reference for graduate students studying neural networks and complex
dynamical systems.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783540692256},
	doi = {10.1007/978-3-540-69226-3},
	pagetotal = {300},
	isbn = {9783540692256},
	publisher = Springer,
	number = {53},
	series = Springer_Computational_Intelligence,
	language = {english},
	date = {2007},
	title = {Neural Networks: Computational Models and Applications},
	author = {Tang, Huajin and Tan, Kay Chen and Yi, Zhang}
}

@XData{theoretical_computer_science,
	journaltitle = {Theoretical Computer Science},
	issn = {0304-3975},
	publisher = Elsevier
}

@Book{theus_urbanek:interactive_graphics_data_analysis,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2640878
},
	keywords = {Gráficos interactivos, Visualización de datos},
	abstract = {__Interactive Graphics for Data Analysis: Principles and Examples__ discusses
exploratory data analysis (EDA) and how interactive graphical methods can help
gain insights as well as generate new questions and hypotheses from datasets.

_Fundamentals of Interactive Statistical Graphics_
The first part of the book summarizes principles and methodology, demonstrating
how the different graphical representations of variables of a dataset are
effectively used in an interactive setting. The authors introduce the most
important plots and their interactive controls. They also examine various types
of data, relations between variables, and plot ensembles.

_Case Studies Illustrate the Principles_
The second section focuses on nine case studies. Each case study describes the
background, lists the main goals of the analysis and the variables in the
dataset, shows what further numerical procedures can add to the graphical
analysis, and summarizes important findings. Wherever applicable, the authors
also provide the numerical analysis for datasets found in Cox and Snell’s
landmark book.

_Understand How to Analyze Data through Graphical Means_
This full-color text shows that interactive graphical methods complement the
traditional statistical toolbox to achieve more complete, easier to understand,
and easier to interpret analyses.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.crcpress.com/Interactive-Graphics-for-Data-Analysis-Principles-and-Examples/Theus-Urbanek/p/book/9781584885948},
	pagetotal = {290},
	isbn = {9781584885948},
	publisher = CRC,
	series = CRC_Computer_Science,
	language = {english},
	subtitle = {Principles and Examples},
	date = {2008},
	title = {Interactive Graphics for Data Analysis},
	author = {Theus, Martin and Urbanek, Simon}
}

@Book{thomopoulos:essentials_monte_carlo_simulation,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/978-1-4614-6022-0
},
	file = {Thomopoulos - 2013 - Essentials of Monte Carlo Simulation.pdf},
	keywords = {Métodos de Monte Carlo, Simulación estocástica},
	abstract = {**Essentials of Monte Carlo Simulation** focuses on the fundamentals of Monte
Carlo methods using basic computer simulation techniques. The theories
presented in this text deal with systems that are too complex to solve
analytically. As a result, readers are given a system of interest and
constructs using computer code, as well as algorithmic models to emulate how
the system works internally. After the models are run several times, in a
random sample way, the data for each output variable(s) of interest is analyzed
by ordinary statistical methods. This book features 11 comprehensive chapters,
and discusses such key topics as random number generators, multivariate random
variates, and continuous random variates. Over 100 numerical examples are
presented as part of the appendix to illustrate useful real world applications.
The text also contains an easy to read presentation with minimal use of
difficult mathematical concepts. Very little has been published in the area of
computer Monte Carlo simulation methods, and this book will appeal to students
and researchers in the fields of Mathematics and Statistics.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781461460213},
	doi = {10.1007/978-1-4614-6022-0},
	pagetotal = {174},
	isbn = {9781461460213},
	publisher = Springer,
	language = {english},
	subtitle = {Statistical Methods for Building Simulation Models},
	date = {2013},
	title = {Essentials of Monte Carlo Simulation},
	author = {Thomopoulos, Nick T.}
}

@book{unwin:graphical_data_analysis_r,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2672806},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.gradaanwr.net/},
	language = {english},
	title = {Graphical Data Analysis with R},
	isbn = {9781498715232},
	series = CRC_R_Series,
	abstract = {*See How Graphics Reveal Information*

**Graphical Data Analysis with R** shows you what information you can gain from graphical displays.
The book focuses on why you draw graphics to display data and which graphics to draw (and uses R to
do so). All the datasets are available in R or one of its packages and the R code is available at
rosuda.org/GDA.

Graphical data analysis is useful for data cleaning, exploring data structure, detecting outliers
and unusual groups, identifying trends and clusters, spotting local patterns, evaluating modelling
output, and presenting results. This book guides you in choosing graphics and understanding what
information you can glean from them. It can be used as a primary text in a graphical data analysis
course or as a supplement in a statistics course. Colour graphics are used throughout.},
	pagetotal = {310},
	publisher = CRC,
	author = {Unwin, Antony},
	date = {2015},
	keywords = {Lenguaje de programación R, Visualización de datos}
}

@book{unwin_et_al:graphics_large_datasets,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/0-387-37977-0},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780387329062},
	doi = {10.1007/0-387-37977-0},
	language = {english},
	subtitle = {Visualizing a Million},
	title = {Graphics of Large Datasets},
	isbn = {9780387329062},
	series = Springer_Statistics_Computing,
	abstract = {Graphics are great for exploring data, but how can they be used for looking at the large datasets
that are commonplace to-day? This book shows how to look at ways of visualizing large datasets,
whether large in numbers of cases or large in numbers of variables or large in both. Data
visualization is useful for data cleaning, exploring data, identifying trends and clusters,
spotting local patterns, evaluating modeling output, and presenting results. It is essential for
exploratory data analysis and data mining. Data analysts, statisticians, computer scientists-indeed
anyone who has to explore a large dataset of their own-should benefit from reading this book.

New approaches to graphics are needed to visualize the information in large datasets and most of
the innovations described in this book are developments of standard graphics. There are
considerable advantages in extending displays which are well-known and well-tried, both in
understanding how best to make use of them in your work and in presenting results to others. It
should also make the book readily accessible for readers who already have a little experience of
drawing statistical graphics. All ideas are illustrated with displays from analyses of real
datasets and the authors emphasize the importance of interpreting displays effectively. Graphics
should be drawn to convey information and the book includes many insightful examples.},
	pagetotal = {271},
	publisher = Springer,
	author = {Unwin, Antony and Theus, Martin and Hofmann, Heike},
	date = {2006},
	keywords = {Macrodatos, Visualización de datos},
	file = {Unwin et al - 2006 - Graphics of Large Datasets.pdf}
}

@Article{vadlamudi_et_al:anytime_pack_search,
	file = {Vadlamudi et al - 2016 - Anytime pack search.pdf},
	keywords = {Búsqueda heurística, Inteligencia artificial},
	abstract = {Heuristic search is one of the fundamental problem solving techniques in artificial intelligence,
which is used in general to efficiently solve computationally hard problems in various domains,
especially in planning and optimization. In this paper, we present an anytime heuristic search
algorithm called anytime pack search (APS) which produces good quality solutions quickly and
improves upon them over time, by focusing the exploration on a limited set of most promising nodes
in each iteration. We discuss the theoretical properties of APS and show that it is complete. We
also present the complexity analysis of the proposed algorithm on a tree state-space model and show
that it is asymptotically of the same order as that of A*, which is a widely applied best-first
search method. Furthermore, we present a parallel formulation of the proposed algorithm, called
parallel anytime pack search (PAPS), which is applicable for searching tree state-spaces. We
theoretically prove the completeness of PAPS. Experimental results on the sliding-tile puzzle
problem, traveling salesperson problem, and single machine scheduling problem depict that the
proposed sequential algorithm produces much better anytime performance when compared to some of the
existing methods. Also, the proposed parallel formulation achieves super-linear speedups over the
sequential method.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1007/s11047-015-9490-9},
	pages = {395-414},
	number = {3},
	volume = {15},
	language = {english},
	date = {2016},
	xdata = {natural_computing},
	title = {Anytime pack search},
	author = {Vadlamudi, Satya Gautam and Aine, Sandip and Chakrabarti, Partha Pratim}
}

@Article{waddington_et_al:cloud_repositories_research_data,
	xdata = {journal_cloud_computing},
	file = {Waddington et al - 2013 - Cloud repositories for research data – addressing the needs of researchers.pdf},
	number = {13},
	keywords = {Investigación reproducible},
	abstract = {This paper describes the problems and explores potential solutions for providing long term storage
and access to research outputs, focusing mainly on research data. The ready availability of cloud
storage and compute services provides a potentially attractive option for curation and preservation
of research information. In contrast to deploying infrastructure within an organisation, which
normally requires long lead times and upfront capital investment, cloud infrastructure is available
on demand and is highly scalable. However, use of commercial cloud services in particular raises
issues of governance, cost-effectiveness, trust and quality of service. We describe a set of
in-depth case studies conducted with researchers across the sciences and humanities performing
data-intensive research, which demonstrate the issues that need to be considered when preserving
data in the cloud. We then describe the design of a repository framework that addresses these
requirements. The framework uses hybrid cloud, combining internal institutional storage, cloud
storage and cloud-based preservation services into a single integrated repository infrastructure.
Allocation of content to storage providers is performed using on a rules-based approach. The
results of an evaluation of the proof-of-concept system are described.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.1186/2192-113X-2-13},
	volume = {2},
	language = {english},
	date = {2013},
	title = {Cloud repositories for research data – addressing the needs of researchers},
	author = {Waddington, Simon and Zhang, Jun and Knight, Gareth and Jensen, Jens and Downing, Roger and Ketley, Cheney}
}

@Article{wang_et_al:fuzzy_membrane_computing,
	issuesubtitle = {Special Issue on Fuzzy Sets and Applications (Celebration of the 50th Anniversary of Fuzzy Sets)},
	xdata = {computers_communications_control},
	file = {Wang et al - 2015 - Fuzzy Membrane Computing: Theory and Applications.pdf},
	keywords = {Computación con membranas, Lógica difusa},
	abstract = {Fuzzy membrane computing is a newly developed and promising research direction
in the area of membrane computing that aims at exploring the complex
interaction between membrane computing and fuzzy theory. This paper provides a
comprehensive survey of theoretical developments and various applications of
fuzzy membrane computing, and sketches future research lines. The theoretical
developments are reviewed from the aspects of uncertainty processing in P
systems, fuzzification of P systems and fuzzy knowledge representation and
reasoning. The applications of fuzzy membrane computing are mainly focused on
fuzzy knowledge representation and fault diagnosis. An overview of different
types of fuzzy P systems, differences between spiking neural P systems and
fuzzy reasoning spiking neural P systems and newly obtained results on these P
systems are presented.},
	langidopts = {variant=british},
	langid = {english},
	doi = {10.15837/ijccc.2015.6.2080},
	pages = {904-935},
	number = {6},
	volume = {10},
	language = {english},
	date = {2015},
	title = {Fuzzy Membrane Computing: Theory and Applications},
	author = {Wang, Tao and Zhang, Gexiang and Pérez-Jiménez, Mario J.}
}

@Book{wexler_et_al:big_book_dashboards,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2835344
},
	keywords = {Visualización de datos},
	abstract = {**The definitive reference book with real-world solutions you won't find
anywhere else**

*The Big Book of Dashboards* presents a comprehensive reference for those
tasked with building or overseeing the development of business dashboards.

Comprising dozens of examples that address different industries and departments
(healthcare, transportation, finance, human resources, marketing, customer
service, sports, etc.) and different platforms (print, desktop, tablet,
smartphone, and conference room display) *The Big Book of Dashboards* is the
only book that matches great dashboards with real-world business scenarios.

By organizing the book based on these scenarios and offering practical and
effective visualization examples, *The Big Book of Dashboards* will be the
trusted resource that you open when you need to build an effective business
dashboard.

In addition to the scenarios there's an entire section of the book that is
devoted to addressing many practical and psychological factors you will
encounter in your work. It's great to have theory and evidenced-based research
at your disposal, but what will you do when somebody asks you to make your
dashboard 'cooler' by adding packed bubbles and donut charts?

The expert authors have a combined 30-plus years of hands-on experience helping
people in hundreds of organizations build effective visualizations. They have
fought many 'best practices' battles and having endured bring an uncommon
empathy to help you, the reader of this book, survive and thrive in the data
visualization world.

A well-designed dashboard can point out risks, opportunities, and more; but
common challenges and misconceptions can make your dashboard useless at best,
and misleading at worst. The Big Book of Dashboards gives you the tools,
guidance, and models you need to produce great dashboards that inform,
enlighten, and engage.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://bigbookofdashboards.com/
https://www.wiley.com/en-es/The+Big+Book+of+Dashboards:+Visualizing+Your+Data+Using+Real+World+Business+Scenarios-p-9781119282716
},
	pagetotal = {448},
	isbn = {9781119282716},
	publisher = Wiley,
	language = {english},
	subtitle = {Visualizing Your Data Using Real-World Business Scenarios},
	date = {2017},
	title = {The Big Book of Dashboards},
	author = {Wexler, Steve and Shaffer, Jeffrey and Cotgreave, Andy}
}

@Book{wickham:ggplot2,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2060400
Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-0-387-98141-3},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/gp/book/9780387981413},
	doi = {10.1007/978-0-387-98141-3},
	language = {english},
	subtitle = {Elegant Graphics for Data Analysis},
	title = {ggplot2},
	isbn = {9780387981406},
	series = Springer_Use_R,
	abstract = {This book describes ggplot2, a new data visualization package for R that uses the insights from
Leland Wilkison's _Grammar of Graphics_ to create a powerful and flexible system for creating data
graphics. With ggplot2, it's easy to:

* produce handsome, publication-quality plots, with automatic legends created from the plot
  specification
* superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different
  data sources, with automatically adjusted common scales
* add customisable smoothers that use the powerful modelling capabilities of R, such as loess,
  linear models, generalised additive models and robust regression
* save any ggplot2 plot (or part thereof) for later modification or reuse
* create custom themes that capture in-house or journal style requirements, and that can easily be
  applied to multiple plots
* approach your graph from a visual perspective, thinking about how each component of the data is
  represented on the final plot

This book will be useful to everyone who has struggled with displaying their data in an informative
and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your
data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and
you'll learn everything you need in the book. After reading this book you'll be able to produce
graphics customized precisely for your problems, and you'll find it easy to get graphics out of
your head and on to the screen or page.},
	pagetotal = {213},
	publisher = Springer,
	author = {Wickham, Hadley},
	date = {2009},
	keywords = {Lenguaje de programación R, Visualización de datos},
	file = {Wickham - 2009 - ggplot2 - Elegant Graphics for Data Analysis.pdf}
}

@Book{wickham:ggplot2_2_ed,
	file = {Wickham - 2016 - ggplot2 - Elegant Graphics for Data Analysis.pdf},
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2714853},
	edition = {2},
	subtitle = {Elegant Graphics for Data Analysis},
	keywords = {Lenguaje de programación R, Visualización de datos},
	abstract = {This new edition to the classic book by ggplot2 creator Hadley Wickham highlights compatibility
with knitr and RStudio. ggplot2 is a data visualization package for R that helps users create data
graphics, including those that are multi-layered, with ease. With ggplot2, it's easy to:

* produce handsome, publication-quality plots with automatic legends created from the plot
  specification
* superimpose multiple layers (points, lines, maps, tiles, box plots) from different data sources
  with automatically adjusted common scales
* add customizable smoothers that use powerful modeling capabilities of R, such as loess, linear
  models, generalized additive models, and robust regression
* save any ggplot2 plot (or part thereof) for later modification or reuse
* create custom themes that capture in-house or journal style requirements and that can easily be
  applied to multiple plots
* approach a graph from a visual perspective, thinking about how each component of the data is
  represented on the final plot

This book will be useful to everyone who has struggled with displaying data in an informative and
attractive way. Some basic knowledge of R is necessary (e.g., importing data into R). ggplot2 is a
mini-language specifically tailored for producing graphics, and you'll learn everything you need in
the book. After reading this book you'll be able to produce graphics customized precisely for your
problems, and you'll find it easy to get graphics out of your head and on to the screen or page.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9783319242750},
	doi = {10.1007/978-3-319-24277-4},
	pagetotal = {260},
	isbn = {9783319242750},
	publisher = Springer,
	series = Springer_Use_R,
	language = {english},
	date = {2016},
	title = {ggplot2},
	author = {Wickham, Hadley}
}

@Book{wickham:r_packages,
	enlaces = {Recurso electrónico (Safari Books Online): http://0-proquest.safaribooksonline.com.fama.us.es//?uiCode=sevil&xmlId=9781491910580},
	keywords = {Lenguaje de programación R},
	abstract = {Turn your R code into packages that others can easily download and use. This practical book shows
you how to bundle reusable R functions, sample data, and documentation together by applying author
Hadley Wickham’s package development philosophy. In the process, you’ll work with devtools,
roxygen, and testthat, a set of R packages that automate common development tasks. Devtools
encapsulates best practices that Hadley has learned from years of working with this programming
language.

Ideal for developers, data scientists, and programmers with various backgrounds, this book starts
you with the basics and shows you how to improve your package writing over time. You’ll learn to
focus on what you want your package to do, rather than think about package structure.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://shop.oreilly.com/product/0636920034421.do},
	pagetotal = {202},
	isbn = {9781491910597},
	publisher = OReilly,
	language = {english},
	date = {2015},
	subtitle = {Organize, Test, Document, and Share Your Code},
	title = {R Packages},
	author = {Wickham, Hadley}
}

@Book{wickham_grolemund:r_data_science,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2715355
Recurso electrónico (Safari Books Online): http://0-proquest.safaribooksonline.com.fama.us.es/?uiCode=sevil&xmlId=9781491910382},
	keywords = {Ciencia del dato, Lenguaje de programación R},
	abstract = {What exactly is data science? With this book, you’ll gain a clear understanding of this discipline
for discovering natural laws in the structure of data. Along the way, you’ll learn how to use the
versatile R programming language for data analysis.

Whenever you measure the same thing twice, you get two results—as long as you measure precisely
enough. This phenomenon creates uncertainty and opportunity. Author Garrett Grolemund, Master
Instructor at RStudio, shows you how data science can help you work with the uncertainty and
capture the opportunities. You’ll learn about:

* __Data Wrangling__—how to manipulate datasets to reveal new information
* __Data Visualization__—how to create graphs and other visualizations
* __Exploratory Data Analysis__—how to find evidence of relationships in your measurements
* __Modelling__—how to derive insights and predictions from your data
* __Inference__—how to avoid being fooled by data analyses that cannot provide foolproof results

Through the course of the book, you’ll also learn about the statistical worldview, a way of seeing
the world that permits understanding in the face of uncertainty, and simplicity in the face of
complexity.
},
	langidopts = {variant=british},
	langid = {english},
	url = {http://shop.oreilly.com/product/0636920034407.do},
	pagetotal = {250},
	isbn = {9781491910399},
	publisher = OReilly,
	language = {english},
	date = {2016},
	subtitle = {Visualize, Model, Transform, Tidy, and Import Data},
	title = {R for Data Science},
	author = {Wickham, Hadley and Grolemund, Garret}
}

@Book{wilkinson:grammar_graphics,
	enlaces = {Recurso electrónico (SpringerLink): http://0-dx.doi.org.fama.us.es/10.1007/0-387-28695-0
},
	file = {Wilkinson - 2005 - The Grammar of Graphics.pdf},
	keywords = {Visualización de datos},
	abstract = {This book was written for statisticians, computer scientists, geographers,
researchers, and others interested in visualizing data. It presents a unique
foundation for producing almost every quantitative graphic found in scientific
journals, newspapers, statistical packages, and data visualization systems.
While the tangible results of this work have been several visualization
software libraries, this book focuses on the deep structures involved in
producing quantitative graphics from data. What are the rules that underlie the
production of pie charts, bar charts, scatterplots, function plots, maps,
mosaics, and radar charts? Those less interested in the theoretical and
mathematical foundations can still get a sense of the richness and structure of
the system by examining the numerous and often unique color graphics it can
produce. The second edition is almost twice the size of the original, with six
new chapters and substantial revision. Much of the added material makes this
book suitable for survey courses in visualization and statistical graphics.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780387245447},
	doi = {10.1007/0-387-28695-0},
	pagetotal = {691},
	isbn = {9780387245447},
	publisher = Springer,
	series = Springer_Statistics_Computing,
	edition = {2},
	language = {english},
	date = {2005},
	title = {The Grammar of Graphics},
	author = {Wilkinson, Leland}
}

@Book{wills:visualizing_time,
	enlaces = {Recurso electrónico (SpringerLink): http://www.us.debiblio.com/login?url=http://dx.doi.org/10.1007/978-0-387-77907-2
},
	file = {Wills - 2012 - Visualizing Time.pdf},
	keywords = {Visualización de datos},
	abstract = {Art, or Science? Which of these is the right way to think of the field of
visualization? This is not an easy question to answer, even for those who have
many years experience in making graphical depictions of data with a view to
help people understand it and take action. In this book, Graham Wills bridges
the gap between the art and the science of visually representing data. He does
not simply give rules and advice, but bases these on general principles and
provide a clear path between them

This book is concerned with the graphical representation of time data and is
written to cover a range of different users. A visualization expert designing
tools for displaying time will find it valuable, but so also should a financier
assembling a report in a spreadsheet, or a medical researcher trying to display
gene sequences using a commercial statistical package.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9780387779065},
	doi = {10.1007/978-0-387-77907-2},
	pagetotal = {256},
	isbn = {9780387779065},
	publisher = Springer,
	series = Springer_Statistics_Computing,
	language = {english},
	subtitle = {Designing Graphical Representations for Statistical Data},
	date = {2012},
	title = {Visualizing Time},
	author = {Wills, Graham}
}

@XData{wires_data_mining_knowledge_discovery,
	journaltitle = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
	issn = {1942-4795},
	shortjournal = {WIREs DMKD},
	publisher = Wiley
}

@book{xie:dynamic_documents_r_knitr,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2672816},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.crcpress.com/Dynamic-Documents-with-R-and-knitr-Second-Edition/Xie/p/book/9781498716963},
	language = {english},
	edition = {2},
	title = {Dynamic Documents with R and knitr},
	isbn = {9781498716963},
	series = CRC_R_Series,
	abstract = {*Quickly and Easily Write Dynamic Documents*

Suitable for both beginners and advanced users, **Dynamic Documents with R and knitr, Second
Edition** makes writing statistical reports easier by integrating computing directly with
reporting. Reports range from homework, projects, exams, books, blogs, and web pages to virtually
any documents related to statistical graphics, computing, and data analysis. The book covers basic
applications for beginners while guiding power users in understanding the extensibility of the
knitr package.

*New to the Second Edition*

* A new chapter that introduces R Markdown v2
* Changes that reflect improvements in the knitr package
* New sections on generating tables, defining custom printing methods for objects in code chunks,
  the C/Fortran engines, the Stan engine, running engines in a persistent session, and starting a
  local server to serve dynamic documents

*Boost Your Productivity in Statistical Report Writing and Make Your Scientific Computing with R
 Reproducible*

Like its highly praised predecessor, this edition shows you how to improve your efficiency in
writing reports. The book takes you from program output to publication-quality reports, helping you
fine-tune every aspect of your report.},
	pagetotal = {294},
	publisher = CRC,
	author = {Xie, Yihui},
	date = {2015},
	keywords = {Investigación reproducible, Lenguaje de programación R}
}

@Book{yu_gen:introduction_evolutionary_algorithms,
	series = Springer_Decision_Engineering,
	enlaces = {Biblioteca de la Universidad de Sevilla: http://encore.fama.us.es/iii/encore/record/C__Rb2160176
Recurso electrónico: http://0-dx.doi.org.fama.us.es/10.1007/978-1-84996-129-5},
	file = {Yu _ Gen - 2010 - Introduction to Evolutionary Algorithms.pdf},
	keywords = {Algoritmos evolutivos, Computación bioinspirada, Inteligencia artificial},
	abstract = {Evolutionary algorithms are becoming increasingly attractive across various disciplines, such as
operations research, computer science, industrial engineering, electrical engineering, social
science and economics. Introduction to Evolutionary Algorithms presents an insightful,
comprehensive, and up-to-date treatment of evolutionary algorithms. It covers such hot topics as: •
genetic algorithms, • differential evolution, • swarm intelligence, and • artificial immune
systems. The reader is introduced to a range of applications, as Introduction to Evolutionary
Algorithms demonstrates how to model real world problems, how to encode and decode individuals, and
how to design effective search operators according to the chromosome structures with examples of
constraint optimization, multiobjective optimization, combinatorial optimization, and
supervised/unsupervised learning. This emphasis on practical applications will benefit all
students, whether they choose to continue their academic career or to enter a particular industry.
Introduction to Evolutionary Algorithms is intended as a textbook or self-study material for both
advanced undergraduates and graduate students. Additional features such as recommended further
reading and ideas for research projects combine to form an accessible and interesting pedagogical
approach to this widely used discipline.},
	langidopts = {variant=british},
	langid = {english},
	url = {http://www.springer.com/9781849961288},
	doi = {10.1007/978-1-84996-129-5},
	pagetotal = {422},
	isbn = {9781849961288},
	publisher = Springer,
	language = {english},
	date = {2010},
	title = {Introduction to Evolutionary Algorithms},
	author = {Yu, Xinjie and Gen, Mitsuo}
}

@Book{zobel:writing_computer_science,
	file = {Zobel - 2014 Writing for Computer Science.pdf},
	keywords = {Ciencias de la computación},
	abstract = {All researchers need to write or speak about their work, and to have research
that is worth presenting. Based on the author's decades of experience as a
researcher and advisor, this third edition provides detailed guidance on
writing and presentations and a comprehensive introduction to research methods,
the how-to of being a successful scientist.

Topics include:

  * Development of ideas into research questions;
  * How to find, read, evaluate and referee other research;
  * Design and evaluation of experiments and appropriate use of statistics;
  * Ethics, the principles of science and examples of science gone wrong.

Much of the book is a step-by-step guide to effective communication, with
advice on:

  * Writing style and editing;
  * Figures, graphs and tables;
  * Mathematics and algorithms;
  * Literature reviews and referees’ reports;
  * Structuring of arguments and results into papers and theses;
  * Writing of other professional documents;
  * Presentation of talks and posters.

Written in an accessible style and including handy checklists and exercises,
*Writing for Computer Science* is not only an introduction to the doing and
describing of research, but is a valuable reference for working scientists in
the computing and mathematical sciences.},
	langidopts = {variant=british},
	langid = {english},
	url = {https://www.springer.com/9781447166382},
	doi = {10.1007/978-1-4471-6639-9},
	pagetotal = {284},
	isbn = {978-1-4471-6638-2},
	publisher = Springer,
	edition = {3},
	language = {english},
	date = {2014},
	title = {Writing for Computer Science},
	author = {Zobel, Justin}
}

